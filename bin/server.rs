//! RWKV TTS HTTP Server
//! åŸºäºSalvoæ¡†æ¶çš„é«˜å¹¶å‘TTSæœåŠ¡å™¨ï¼Œæä¾›REST APIå’ŒWeb UIç•Œé¢

use anyhow::Result;
use base64::Engine;
use clap::{Arg, Command};
use rust_embed::RustEmbed;
use salvo::prelude::*;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::path::{Path, PathBuf};
use std::sync::Arc;
use tracing::{debug, error, info, warn};
use tracing_subscriber::EnvFilter;
use uuid::Uuid;

// æ·»åŠ æ¨¡å‹ä¸‹è½½ç›¸å…³å¯¼å…¥
// use hf_hub::api::tokio::Api; // Now using ApiBuilder::from_env().build()
use tokio::fs;

/// åµŒå…¥çš„é™æ€èµ„æº
#[derive(RustEmbed)]
#[folder = "static/"]
struct Assets;

// ç§»é™¤æœªä½¿ç”¨çš„å¯¼å…¥
// LoggeråŠŸèƒ½æš‚æ—¶ç¦ç”¨

use rwkv_tts_rs::lightweight_tts_pipeline::{LightweightTtsPipeline, LightweightTtsPipelineArgs};
use rwkv_tts_rs::ref_audio_utilities::RefAudioUtilities;
use rwkv_tts_rs::voice_feature_manager::{VoiceFeatureManager, VoiceMetadata};
use web_rwkv::runtime::model::Quant;

/// TTSè¯·æ±‚å‚æ•°
#[derive(Debug, Deserialize)]
struct TtsRequest {
    text: String,
    temperature: Option<f32>,
    top_p: Option<f32>,
    #[allow(dead_code)]
    speed: Option<f32>,
    #[allow(dead_code)]
    zero_shot: Option<bool>,
    voice_id: Option<String>, // éŸ³è‰²IDï¼Œç”¨äºéŸ³è‰²å…‹éš†
    seed: Option<u64>,
    // æ·»åŠ æ–°çš„é«˜çº§é€‰é¡¹
    age: Option<String>,
    gender: Option<String>,
    emotion: Option<String>,
    pitch: Option<String>,
    // æ·»åŠ æç¤ºè¯å­—æ®µ
    prompt_text: Option<String>,
}

// VoiceExtractRequestç»“æ„ä½“å·²ç§»é™¤ï¼Œå› ä¸ºä½¿ç”¨multipartè¡¨å•å¤„ç†

/// éŸ³è‰²ç‰¹å¾æå–å“åº”
#[derive(Debug, Serialize)]
struct VoiceExtractResponse {
    success: bool,
    message: String,
    voice_id: Option<String>,
}

/// éŸ³è‰²åˆ—è¡¨å“åº”
#[derive(Debug, Serialize)]
struct VoiceListResponse {
    success: bool,
    voices: Vec<VoiceMetadata>,
}

/// éŸ³è‰²åˆ é™¤è¯·æ±‚
#[derive(Debug, Deserialize)]
struct VoiceDeleteRequest {
    voice_id: String,
}

/// éŸ³è‰²åˆ é™¤å“åº”
#[derive(Debug, Serialize)]
struct VoiceDeleteResponse {
    success: bool,
    message: String,
}

/// TTSå“åº”
#[derive(Debug, Serialize)]
struct TtsResponse {
    success: bool,
    message: String,
    audio_base64: Option<String>,
    duration_ms: Option<u64>,
    rtf: Option<f64>,
}

/// é”™è¯¯å“åº”
#[derive(Debug, Serialize)]
struct ErrorResponse {
    success: bool,
    error: String,
}

/// å°†f32éŸ³é¢‘æ ·æœ¬è½¬æ¢ä¸ºWAVæ ¼å¼çš„å­—èŠ‚æ•°æ®
fn convert_samples_to_wav(samples: &[f32], sample_rate: u32) -> Vec<u8> {
    let mut wav_data = Vec::new();

    // åˆ†æéŸ³é¢‘æ•°æ®èŒƒå›´ä»¥ç¡®å®šåˆé€‚çš„ç¼©æ”¾å› å­
    let max_abs = samples.iter().map(|x| x.abs()).fold(0.0f32, f32::max);
    let scale_factor = if max_abs > 0.0 {
        // å¦‚æœæœ€å¤§å€¼è¶…è¿‡1.0ï¼Œéœ€è¦å½’ä¸€åŒ–ï¼›å¦‚æœå°äº1.0ï¼Œéœ€è¦æ”¾å¤§
        if max_abs > 1.0 {
            1.0 / max_abs
        } else {
            // å¯¹äºå°å¹…åº¦ä¿¡å·ï¼Œé€‚åº¦æ”¾å¤§ä½†ä¸è¶…è¿‡å®‰å…¨èŒƒå›´
            (0.8 / max_abs).min(10.0)
        }
    } else {
        1.0
    };

    info!(
        "éŸ³é¢‘æ•°æ®åˆ†æ: max_abs={:.6}, scale_factor={:.6}",
        max_abs, scale_factor
    );

    // WAVæ–‡ä»¶å¤´
    wav_data.extend_from_slice(b"RIFF");
    let file_size = 36 + samples.len() * 2; // 16ä½éŸ³é¢‘
    wav_data.extend_from_slice(&(file_size as u32).to_le_bytes());
    wav_data.extend_from_slice(b"WAVE");

    // fmt chunk
    wav_data.extend_from_slice(b"fmt ");
    wav_data.extend_from_slice(&16u32.to_le_bytes()); // chunk size
    wav_data.extend_from_slice(&1u16.to_le_bytes()); // audio format (PCM)
    wav_data.extend_from_slice(&1u16.to_le_bytes()); // num channels (mono)
    wav_data.extend_from_slice(&sample_rate.to_le_bytes()); // sample rate
    wav_data.extend_from_slice(&(sample_rate * 2).to_le_bytes()); // byte rate
    wav_data.extend_from_slice(&2u16.to_le_bytes()); // block align
    wav_data.extend_from_slice(&16u16.to_le_bytes()); // bits per sample

    // data chunk
    wav_data.extend_from_slice(b"data");
    wav_data.extend_from_slice(&(samples.len() * 2).to_le_bytes() as &[u8]);

    // éŸ³é¢‘æ•°æ® (è½¬æ¢f32åˆ°i16ï¼Œåº”ç”¨åŠ¨æ€ç¼©æ”¾)
    for sample in samples {
        let scaled_sample = sample * scale_factor;
        let sample_i16 = (scaled_sample.clamp(-1.0, 1.0) * 32767.0) as i16;
        wav_data.extend_from_slice(&sample_i16.to_le_bytes());
    }

    wav_data
}

/// è®¡ç®—å®æ—¶å› å­(RTF)
fn calculate_rtf(audio_data: &[f32], processing_time: std::time::Duration) -> f64 {
    let audio_duration = audio_data.len() as f64 / 16000.0; // å‡è®¾16kHzé‡‡æ ·ç‡
    let processing_seconds = processing_time.as_secs_f64();
    if audio_duration > 0.0 {
        processing_seconds / audio_duration
    } else {
        0.0
    }
}

/// åº”ç”¨çŠ¶æ€
#[derive(Debug, Clone)]
struct AppState {
    #[allow(dead_code)]
    start_time: std::time::Instant,
    #[allow(dead_code)]
    model_path: String,
    #[allow(dead_code)]
    vocab_path: String,
    tts_pipeline: Arc<LightweightTtsPipeline>,
    voice_manager: Arc<VoiceFeatureManager>,
}

/// å…¨å±€åº”ç”¨çŠ¶æ€
static GLOBAL_APP_STATE: std::sync::OnceLock<AppState> = std::sync::OnceLock::new();

/// åˆå§‹åŒ–å…¨å±€åº”ç”¨çŠ¶æ€
fn init_global_app_state(app_state: AppState) {
    GLOBAL_APP_STATE.set(app_state).expect("åº”ç”¨çŠ¶æ€å·²åˆå§‹åŒ–");
}

/// è·å–å…¨å±€åº”ç”¨çŠ¶æ€
fn get_global_app_state() -> AppState {
    GLOBAL_APP_STATE.get().expect("åº”ç”¨çŠ¶æ€æœªåˆå§‹åŒ–").clone()
}

/// å¤„ç†TTSè¯·æ±‚ï¼ˆæ”¯æŒæ–‡ä»¶ä¸Šä¼ ï¼‰
#[handler]
async fn handle_tts(req: &mut Request, res: &mut Response) -> Result<(), StatusError> {
    // æ£€æŸ¥æ˜¯å¦æ˜¯multipartè¯·æ±‚ï¼ˆæ–‡ä»¶ä¸Šä¼ ï¼‰
    if req
        .content_type()
        .map(|ct| ct.type_() == "multipart")
        .unwrap_or(false)
    {
        // å¤„ç†multipartè¡¨å•æ•°æ®ï¼ˆåŒ…å«æ–‡ä»¶ä¸Šä¼ ï¼‰
        handle_tts_with_file_upload(req, res).await
    } else {
        // å¤„ç†æ™®é€šçš„JSONè¯·æ±‚
        handle_tts_json(req, res).await
    }
}

/// å¤„ç†å¸¦æ–‡ä»¶ä¸Šä¼ çš„TTSè¯·æ±‚
async fn handle_tts_with_file_upload(
    req: &mut Request,
    res: &mut Response,
) -> Result<(), StatusError> {
    let total_start = std::time::Instant::now();

    // è§£æmultipartè¡¨å•æ•°æ®
    let parse_start = std::time::Instant::now();
    req.parse_form::<()>().await.map_err(|e| {
        error!("è¡¨å•æ•°æ®è§£æå¤±è´¥: {}", e);
        StatusError::bad_request()
    })?;
    let parse_time = parse_start.elapsed();

    // æå–æ–‡æœ¬å’Œå…¶ä»–å‚æ•°
    let text: String = req.form("text").await.unwrap_or_default();
    let temperature: f32 = req
        .form("temperature")
        .await
        .unwrap_or("1.0".to_string())
        .parse()
        .unwrap_or(1.0);
    let top_p: f32 = req
        .form("top_p")
        .await
        .unwrap_or("0.90".to_string())
        .parse()
        .unwrap_or(0.90);
    let _speed: f32 = req
        .form("speed")
        .await
        .unwrap_or("1.0".to_string())
        .parse()
        .unwrap_or(1.0);
    let zero_shot: bool = req
        .form("zero_shot")
        .await
        .unwrap_or("false".to_string())
        .parse()
        .unwrap_or(false);
    let ref_audio_path: String = req.form("ref_audio_path").await.unwrap_or_default();
    let voice_id: String = req.form("voice_id").await.unwrap_or_default();
    let seed_str: String = req.form("seed").await.unwrap_or_default();
    let seed: Option<u64> = if seed_str.is_empty() {
        None
    } else {
        seed_str.parse().ok()
    };
    let age: String = req.form("age").await.unwrap_or("youth-adult".to_string());
    let gender: String = req.form("gender").await.unwrap_or("male".to_string());
    let emotion: String = req.form("emotion").await.unwrap_or("NEUTRAL".to_string());
    let pitch: String = req
        .form("pitch")
        .await
        .unwrap_or("medium_pitch".to_string());
    let prompt_text: String = req.form("prompt_text").await.unwrap_or_default();

    info!(
        "ğŸ¯ æ”¶åˆ°TTSè¯·æ±‚(å¸¦æ–‡ä»¶ä¸Šä¼ ): text='{}', ref_audio_path='{:?}'",
        text, ref_audio_path
    );
    info!(
        "  â±ï¸  è¯·æ±‚è§£æè€—æ—¶: {:.2}ms",
        parse_time.as_secs_f64() * 1000.0
    );

    // å¤„ç†æ–‡ä»¶ä¸Šä¼ 
    let uploaded_file_path = if let Some(file) = req.file("refAudioFile").await {
        // è·å–åŸå§‹æ–‡ä»¶åå’Œæ‰©å±•å
        let original_filename = file.name().unwrap_or("audio");
        let extension = std::path::Path::new(original_filename)
            .extension()
            .and_then(|ext| ext.to_str())
            .unwrap_or("wav"); // é»˜è®¤ä¸ºwav

        // åˆ›å»ºä¸´æ—¶ç›®å½•
        let temp_dir = std::path::PathBuf::from("assets/raf/temp/upload_temp_files");
        if let Err(e) = tokio::fs::create_dir_all(&temp_dir).await {
            error!("åˆ›å»ºä¸´æ—¶ç›®å½•å¤±è´¥: {}", e);
            None
        } else {
            // ç”Ÿæˆä¸´æ—¶æ–‡ä»¶è·¯å¾„ï¼Œä¿æŒåŸå§‹æ‰©å±•å
            let temp_file_path = temp_dir.join(format!("{}.{}", Uuid::new_v4(), extension));

            // å¤åˆ¶ä¸Šä¼ æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
            match tokio::fs::copy(file.path(), &temp_file_path).await {
                Ok(_) => {
                    info!("  ğŸ“ æ–‡ä»¶ä¸Šä¼ å¤„ç†å®Œæˆ: {:?}", temp_file_path);
                    Some(temp_file_path.to_string_lossy().to_string())
                }
                Err(e) => {
                    error!("ä¿å­˜ä¸Šä¼ æ–‡ä»¶å¤±è´¥: {}", e);
                    None
                }
            }
        }
    } else {
        None
    };

    // ç¡®å®šæœ€ç»ˆä½¿ç”¨çš„å‚è€ƒéŸ³é¢‘è·¯å¾„
    let final_ref_audio_path = if let Some(ref uploaded_path) = uploaded_file_path {
        uploaded_path.clone()
    } else {
        ref_audio_path
    };

    // è·å–åº”ç”¨çŠ¶æ€å’Œåˆ›å»ºå‚æ•°
    let setup_start = std::time::Instant::now();
    let app_state = get_global_app_state();

    // å¤„ç†éŸ³è‰²IDå‚æ•°
    let (final_ref_audio_path, use_voice_clone) = if !voice_id.is_empty() {
        // ä½¿ç”¨éŸ³è‰²IDåŠ è½½é¢„å­˜çš„éŸ³è‰²ç‰¹å¾
        match app_state.voice_manager.load_voice_feature(&voice_id).await {
            Ok(voice_feature) => {
                info!(
                    "ğŸ­ ä½¿ç”¨éŸ³è‰²ID: {}, éŸ³è‰²åç§°: {}",
                    voice_id, voice_feature.name
                );
                // TODO: éœ€è¦å®ç°ä»éŸ³è‰²ç‰¹å¾ç”Ÿæˆä¸´æ—¶éŸ³é¢‘æ–‡ä»¶çš„é€»è¾‘
                (String::new(), true)
            }
            Err(e) => {
                error!("åŠ è½½éŸ³è‰²ç‰¹å¾å¤±è´¥: {}", e);
                res.status_code(StatusCode::BAD_REQUEST);
                res.render(Json(ErrorResponse {
                    success: false,
                    error: format!("éŸ³è‰²ID '{}' ä¸å­˜åœ¨æˆ–åŠ è½½å¤±è´¥: {}", voice_id, e),
                }));
                return Ok(());
            }
        }
    } else {
        (
            final_ref_audio_path.clone(),
            !final_ref_audio_path.is_empty() || zero_shot,
        )
    };

    let pipeline_args = LightweightTtsPipelineArgs {
        text: text.clone(),
        ref_audio_path: final_ref_audio_path.clone(),
        zero_shot: use_voice_clone,
        temperature,
        top_p,
        top_k: 100,
        max_tokens: 8000,
        seed,
        // æ·»åŠ æ–°çš„é«˜çº§é€‰é¡¹å¹¶è¿›è¡Œç±»å‹è½¬æ¢
        age,
        gender,
        emotion,
        // éŸ³è°ƒå’Œè¯­é€Ÿéœ€è¦è½¬æ¢ä¸ºæ•°å€¼
        pitch: match pitch.as_str() {
            "low_pitch" => 150.0,
            "medium_pitch" => 200.0,
            "high_pitch" => 250.0,
            "very_high_pitch" => 300.0,
            _ => 200.0, // é»˜è®¤ä¸­éŸ³è°ƒ
        },
        speed: 4.2, // é»˜è®¤è¯­é€Ÿ
        // æ·»åŠ æç¤ºè¯
        prompt_text,
        ..Default::default()
    };
    let setup_time = setup_start.elapsed();
    info!(
        "  â±ï¸  å‚æ•°è®¾ç½®è€—æ—¶: {:.2}ms",
        setup_time.as_secs_f64() * 1000.0
    );

    // TTSç”Ÿæˆï¼ˆä¸»è¦å¤„ç†æ—¶é—´ï¼‰
    let tts_start = std::time::Instant::now();
    let audio_data = match app_state.tts_pipeline.generate_speech(&pipeline_args).await {
        Ok(data) => data,
        Err(e) => {
            error!("ç”ŸæˆTTSéŸ³é¢‘å¤±è´¥: {}", e);
            res.status_code(StatusCode::INTERNAL_SERVER_ERROR);
            res.render(Json(ErrorResponse {
                success: false,
                error: format!("ç”ŸæˆTTSéŸ³é¢‘å¤±è´¥: {}", e),
            }));
            return Ok(());
        }
    };
    let tts_time = tts_start.elapsed();
    info!(
        "  â±ï¸  TTSç”Ÿæˆè€—æ—¶: {:.2}ms",
        tts_time.as_secs_f64() * 1000.0
    );

    // éŸ³é¢‘æ ¼å¼è½¬æ¢
    let convert_start = std::time::Instant::now();
    let wav_data = convert_samples_to_wav(&audio_data, 16000);
    let convert_time = convert_start.elapsed();
    info!(
        "  â±ï¸  WAVè½¬æ¢è€—æ—¶: {:.2}ms",
        convert_time.as_secs_f64() * 1000.0
    );

    // Base64ç¼–ç 
    let encode_start = std::time::Instant::now();
    let base64_audio = base64::engine::general_purpose::STANDARD.encode(&wav_data);
    let encode_time = encode_start.elapsed();
    info!(
        "  â±ï¸  Base64ç¼–ç è€—æ—¶: {:.2}ms",
        encode_time.as_secs_f64() * 1000.0
    );

    // è®¡ç®—æ€»ä½“æ€§èƒ½æŒ‡æ ‡
    let total_time = total_start.elapsed();
    let rtf = calculate_rtf(&audio_data, total_time);
    let audio_duration = audio_data.len() as f64 / 16000.0;

    info!("ğŸ“Š TTSè¯·æ±‚å®Œæˆç»Ÿè®¡:");
    info!("  â±ï¸  æ€»è€—æ—¶: {:.2}ms", total_time.as_secs_f64() * 1000.0);
    info!("  ğŸµ éŸ³é¢‘æ—¶é•¿: {:.2}s", audio_duration);
    info!("  ğŸ“ˆ RTF: {:.3}", rtf);
    info!("  ğŸ“¦ éŸ³é¢‘æ ·æœ¬æ•°: {}", audio_data.len());
    info!("  ğŸ’¾ WAVæ–‡ä»¶å¤§å°: {} bytes", wav_data.len());
    info!("  ğŸ“ Base64å¤§å°: {} chars", base64_audio.len());

    // æ€§èƒ½åˆ†æå’Œä¼˜åŒ–å»ºè®®
    let tts_percentage = tts_time.as_secs_f64() / total_time.as_secs_f64() * 100.0;
    let convert_percentage = convert_time.as_secs_f64() / total_time.as_secs_f64() * 100.0;
    let encode_percentage = encode_time.as_secs_f64() / total_time.as_secs_f64() * 100.0;

    info!("ğŸ” æ€§èƒ½åˆ†æ:");
    info!("  - TTSç”Ÿæˆ: {:.1}%", tts_percentage);
    info!("  - WAVè½¬æ¢: {:.1}%", convert_percentage);
    info!("  - Base64ç¼–ç : {:.1}%", encode_percentage);
    info!(
        "  - å…¶ä»–å¼€é”€: {:.1}%",
        100.0 - tts_percentage - convert_percentage - encode_percentage
    );

    if rtf > 0.3 {
        info!("âš ï¸  æœåŠ¡å™¨æ€§èƒ½æç¤º: RTF > 0.3ï¼Œå»ºè®®ä¼˜åŒ–:");
        if tts_percentage > 90.0 {
            info!(
                "   - TTSç”Ÿæˆå ç”¨{:.1}%æ—¶é—´ï¼Œä¸»è¦ç“¶é¢ˆåœ¨æ¨¡å‹æ¨ç†",
                tts_percentage
            );
        }
        if convert_percentage > 5.0 {
            info!(
                "   - WAVè½¬æ¢å ç”¨{:.1}%æ—¶é—´ï¼Œè€ƒè™‘ä¼˜åŒ–éŸ³é¢‘å¤„ç†",
                convert_percentage
            );
        }
        if encode_percentage > 5.0 {
            info!(
                "   - Base64ç¼–ç å ç”¨{:.1}%æ—¶é—´ï¼Œè€ƒè™‘æµå¼ä¼ è¾“",
                encode_percentage
            );
        }
    }

    // æ„å»ºå“åº”
    let response_start = std::time::Instant::now();
    res.render(Json(TtsResponse {
        success: true,
        message: "TTSç”ŸæˆæˆåŠŸ".to_string(),
        audio_base64: Some(base64_audio),
        duration_ms: Some(total_time.as_millis() as u64),
        rtf: Some(rtf),
    }));
    let response_time = response_start.elapsed();
    info!(
        "  â±ï¸  å“åº”æ„å»ºè€—æ—¶: {:.2}ms",
        response_time.as_secs_f64() * 1000.0
    );

    // æ¸…ç†ä¸Šä¼ çš„ä¸´æ—¶æ–‡ä»¶
    if let Some(uploaded_path) = uploaded_file_path {
        tokio::spawn(async move {
            // ç­‰å¾…ä¸€æ®µæ—¶é—´ååˆ é™¤ä¸´æ—¶æ–‡ä»¶
            tokio::time::sleep(tokio::time::Duration::from_secs(60)).await;
            if let Err(e) = tokio::fs::remove_file(&uploaded_path).await {
                warn!("åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {}: {}", uploaded_path, e);
            } else {
                info!("ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†: {}", uploaded_path);
            }
        });
    }

    Ok(())
}

/// æå–éŸ³é¢‘ç‰¹å¾
async fn extract_audio_features(
    audio_path: &str,
) -> Result<(Vec<i32>, Vec<i32>, f32, u32), anyhow::Error> {
    info!("å¼€å§‹æå–éŸ³é¢‘ç‰¹å¾: {}", audio_path);

    // æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if !std::path::Path::new(audio_path).exists() {
        let error_msg = format!("éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {}", audio_path);
        error!("{}", error_msg);
        return Err(anyhow::anyhow!(error_msg));
    }

    // éªŒè¯ONNXæ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    let onnx_files = [
        "assets/model/BiCodecTokenize.onnx",
        "assets/model/wav2vec2-large-xlsr-53.onnx",
        "assets/model/BiCodecDetokenize.onnx",
    ];

    for onnx_file in &onnx_files {
        if !std::path::Path::new(onnx_file).exists() {
            let error_msg = format!("ONNXæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {}", onnx_file);
            error!("{}", error_msg);
            return Err(anyhow::anyhow!(error_msg));
        }
    }

    // åˆ›å»ºRefAudioUtilitieså®ä¾‹
    let mut ref_audio_utils = match RefAudioUtilities::new(
        "assets/model/BiCodecTokenize.onnx",
        "assets/model/wav2vec2-large-xlsr-53.onnx",
        6.0, // ref_segment_duration
        320, // latent_hop_length
        Some("assets/model/BiCodecDetokenize.onnx"),
    ) {
        Ok(utils) => {
            info!("RefAudioUtilitiesåˆå§‹åŒ–æˆåŠŸ");
            utils
        }
        Err(e) => {
            let error_msg = format!("RefAudioUtilitiesåˆå§‹åŒ–å¤±è´¥: {}", e);
            error!("{}", error_msg);
            return Err(anyhow::anyhow!(error_msg));
        }
    };

    // æå–éŸ³é¢‘ç‰¹å¾tokens
    let (global_tokens, semantic_tokens) = match ref_audio_utils.tokenize(audio_path) {
        Ok(tokens) => {
            info!(
                "éŸ³é¢‘ç‰¹å¾æå–æˆåŠŸï¼Œglobal_tokensé•¿åº¦: {}, semantic_tokensé•¿åº¦: {}",
                tokens.0.len(),
                tokens.1.len()
            );
            tokens
        }
        Err(e) => {
            let error_msg = format!("éŸ³é¢‘ç‰¹å¾æå–å¤±è´¥: {}", e);
            error!("{}", error_msg);
            return Err(anyhow::anyhow!(error_msg));
        }
    };

    // è®¡ç®—éŸ³é¢‘æ—¶é•¿å’Œé‡‡æ ·ç‡
    let (audio_duration, sample_rate) = match calculate_audio_info(audio_path) {
        Ok(info) => {
            info!(
                "éŸ³é¢‘ä¿¡æ¯è®¡ç®—æˆåŠŸï¼Œæ—¶é•¿: {:.2}ç§’, é‡‡æ ·ç‡: {}Hz",
                info.0, info.1
            );
            info
        }
        Err(e) => {
            let error_msg = format!("éŸ³é¢‘ä¿¡æ¯è®¡ç®—å¤±è´¥: {}", e);
            error!("{}", error_msg);
            return Err(anyhow::anyhow!(error_msg));
        }
    };

    info!("éŸ³é¢‘ç‰¹å¾æå–å®Œæˆ");
    Ok((global_tokens, semantic_tokens, audio_duration, sample_rate))
}

/// è®¡ç®—éŸ³é¢‘ä¿¡æ¯ï¼ˆæ—¶é•¿å’Œé‡‡æ ·ç‡ï¼‰
fn calculate_audio_info(audio_path: &str) -> Result<(f32, u32), anyhow::Error> {
    debug!("å¼€å§‹è®¡ç®—éŸ³é¢‘ä¿¡æ¯: {}", audio_path);

    // æ£€æŸ¥æ–‡ä»¶æ‰©å±•ååˆ¤æ–­æ ¼å¼
    let path = std::path::Path::new(audio_path);
    let extension = path
        .extension()
        .and_then(|ext| ext.to_str())
        .unwrap_or("")
        .to_lowercase();

    match extension.as_str() {
        "wav" => {
            // ä½¿ç”¨houndåº“å¤„ç†WAVæ–‡ä»¶
            let reader = match hound::WavReader::open(audio_path) {
                Ok(reader) => reader,
                Err(e) => {
                    let error_msg = format!("æ— æ³•æ‰“å¼€WAVæ–‡ä»¶ {}: {}", audio_path, e);
                    error!("{}", error_msg);
                    return Err(anyhow::anyhow!(error_msg));
                }
            };

            let spec = reader.spec();
            let sample_rate = spec.sample_rate;
            let channels = spec.channels as u32;

            debug!(
                "WAVéŸ³é¢‘è§„æ ¼ - é‡‡æ ·ç‡: {}Hz, å£°é“æ•°: {}",
                sample_rate, channels
            );

            // éªŒè¯éŸ³é¢‘æ ¼å¼
            if channels == 0 {
                let error_msg = "æ— æ•ˆçš„WAVæ–‡ä»¶ï¼šå£°é“æ•°ä¸º0".to_string();
                error!("{}", error_msg);
                return Err(anyhow::anyhow!(error_msg));
            }

            if sample_rate == 0 {
                let error_msg = "æ— æ•ˆçš„WAVæ–‡ä»¶ï¼šé‡‡æ ·ç‡ä¸º0".to_string();
                error!("{}", error_msg);
                return Err(anyhow::anyhow!(error_msg));
            }

            let sample_count = reader.len();

            if sample_count == 0 {
                let error_msg = "WAVæ–‡ä»¶ä¸ºç©ºæˆ–æ— æ•ˆ".to_string();
                error!("{}", error_msg);
                return Err(anyhow::anyhow!(error_msg));
            }

            let duration = sample_count as f32 / spec.sample_rate as f32;

            debug!(
                "WAVéŸ³é¢‘ä¿¡æ¯è®¡ç®—å®Œæˆ - æ—¶é•¿: {:.2}ç§’, æ€»æ ·æœ¬æ•°: {}",
                duration, sample_count
            );

            Ok((duration, spec.sample_rate))
        }
        "mp3" => {
            // ä½¿ç”¨symphoniaåº“å¤„ç†MP3æ–‡ä»¶
            use std::fs::File;
            use symphonia::core::formats::FormatOptions;
            use symphonia::core::io::MediaSourceStream;
            use symphonia::core::meta::MetadataOptions;
            use symphonia::core::probe::Hint;

            let file = match File::open(audio_path) {
                Ok(file) => file,
                Err(e) => {
                    let error_msg = format!("æ— æ³•æ‰“å¼€MP3æ–‡ä»¶ {}: {}", audio_path, e);
                    error!("{}", error_msg);
                    return Err(anyhow::anyhow!(error_msg));
                }
            };

            let mss = MediaSourceStream::new(Box::new(file), Default::default());
            let mut hint = Hint::new();
            hint.with_extension("mp3");

            let meta_opts: MetadataOptions = Default::default();
            let fmt_opts: FormatOptions = Default::default();

            let probed =
                match symphonia::default::get_probe().format(&hint, mss, &fmt_opts, &meta_opts) {
                    Ok(probed) => probed,
                    Err(e) => {
                        let error_msg = format!("æ— æ³•è§£æMP3æ–‡ä»¶æ ¼å¼ {}: {}", audio_path, e);
                        error!("{}", error_msg);
                        return Err(anyhow::anyhow!(error_msg));
                    }
                };

            let format = probed.format;
            let track = match format
                .tracks()
                .iter()
                .find(|t| t.codec_params.codec != symphonia::core::codecs::CODEC_TYPE_NULL)
            {
                Some(track) => track,
                None => {
                    let error_msg = "MP3æ–‡ä»¶ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„éŸ³é¢‘è½¨é“".to_string();
                    error!("{}", error_msg);
                    return Err(anyhow::anyhow!(error_msg));
                }
            };

            let sample_rate = track.codec_params.sample_rate.unwrap_or(0);
            let channels = track
                .codec_params
                .channels
                .map(|ch| ch.count())
                .unwrap_or(0) as u32;

            debug!(
                "MP3éŸ³é¢‘è§„æ ¼ - é‡‡æ ·ç‡: {}Hz, å£°é“æ•°: {}",
                sample_rate, channels
            );

            // éªŒè¯éŸ³é¢‘æ ¼å¼
            if channels == 0 {
                let error_msg = "æ— æ•ˆçš„MP3æ–‡ä»¶ï¼šå£°é“æ•°ä¸º0".to_string();
                error!("{}", error_msg);
                return Err(anyhow::anyhow!(error_msg));
            }

            if sample_rate == 0 {
                let error_msg = "æ— æ•ˆçš„MP3æ–‡ä»¶ï¼šé‡‡æ ·ç‡ä¸º0".to_string();
                error!("{}", error_msg);
                return Err(anyhow::anyhow!(error_msg));
            }

            // è®¡ç®—æ—¶é•¿
            let duration = if let Some(n_frames) = track.codec_params.n_frames {
                n_frames as f32 / sample_rate as f32
            } else {
                // å¦‚æœæ— æ³•ç›´æ¥è·å–å¸§æ•°ï¼Œå°è¯•é€šè¿‡æ—¶é—´åŸºå‡†è®¡ç®—
                if let Some(time_base) = track.codec_params.time_base {
                    if let Some(n_frames) = track.codec_params.n_frames {
                        let duration_ts = n_frames;
                        time_base.calc_time(duration_ts).seconds as f32
                            + time_base.calc_time(duration_ts).frac as f32
                    } else {
                        // æ— æ³•ç¡®å®šæ—¶é•¿ï¼Œè¿”å›é”™è¯¯
                        let error_msg = "æ— æ³•ç¡®å®šMP3æ–‡ä»¶æ—¶é•¿".to_string();
                        error!("{}", error_msg);
                        return Err(anyhow::anyhow!(error_msg));
                    }
                } else {
                    let error_msg = "MP3æ–‡ä»¶ç¼ºå°‘æ—¶é—´åŸºå‡†ä¿¡æ¯".to_string();
                    error!("{}", error_msg);
                    return Err(anyhow::anyhow!(error_msg));
                }
            };

            debug!("MP3éŸ³é¢‘ä¿¡æ¯è®¡ç®—å®Œæˆ - æ—¶é•¿: {:.2}ç§’", duration);

            Ok((duration, sample_rate))
        }
        _ => {
            let error_msg = format!("ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼: {}", extension);
            error!("{}", error_msg);
            Err(anyhow::anyhow!(error_msg))
        }
    }
}

/// å¤„ç†JSONæ ¼å¼çš„TTSè¯·æ±‚ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
async fn handle_tts_json(req: &mut Request, res: &mut Response) -> Result<(), StatusError> {
    let total_start = std::time::Instant::now();

    // 1. è§£æJSONè¯·æ±‚
    let parse_start = std::time::Instant::now();
    let tts_request: TtsRequest = match req.parse_json().await {
        Ok(request) => request,
        Err(e) => {
            error!("JSONè§£æå¤±è´¥: {}", e);
            res.status_code(StatusCode::BAD_REQUEST);
            res.render(Json(ErrorResponse {
                success: false,
                error: format!("JSONè§£æå¤±è´¥: {}", e),
            }));
            return Ok(());
        }
    };
    let parse_time = parse_start.elapsed();

    info!(
        "ğŸ¯ æ”¶åˆ°TTSè¯·æ±‚: text='{}', voice_id='{:?}'",
        tts_request.text, tts_request.voice_id
    );
    info!(
        "  â±ï¸  è¯·æ±‚è§£æè€—æ—¶: {:.2}ms",
        parse_time.as_secs_f64() * 1000.0
    );

    // 2. è·å–åº”ç”¨çŠ¶æ€å’Œåˆ›å»ºå‚æ•°
    let setup_start = std::time::Instant::now();
    let app_state = get_global_app_state();

    // å¤„ç†éŸ³è‰²IDå‚æ•°
    let (_use_voice_clone, voice_feature, prompt_text_from_voice) =
        if let Some(voice_id) = &tts_request.voice_id {
            if !voice_id.is_empty() {
                // ä½¿ç”¨éŸ³è‰²IDåŠ è½½é¢„å­˜çš„éŸ³è‰²ç‰¹å¾
                match app_state.voice_manager.load_voice_feature(voice_id).await {
                    Ok(voice_feature) => {
                        info!(
                            "ğŸ­ ä½¿ç”¨éŸ³è‰²ID: {}, éŸ³è‰²åç§°: {}",
                            voice_id, voice_feature.name
                        );
                        // ä½¿ç”¨éŸ³è‰²ç‰¹å¾ä¸­çš„tokensï¼Œä¸éœ€è¦å‚è€ƒéŸ³é¢‘æ–‡ä»¶
                        // åŒæ—¶è·å–æç¤ºè¯ï¼Œé¿å…é‡å¤è¯»å–æ–‡ä»¶
                        let prompt_text = voice_feature.prompt_text.clone();
                        (true, Some(voice_feature), Some(prompt_text))
                    }
                    Err(e) => {
                        error!("åŠ è½½éŸ³è‰²ç‰¹å¾å¤±è´¥: {}", e);
                        res.status_code(StatusCode::BAD_REQUEST);
                        res.render(Json(ErrorResponse {
                            success: false,
                            error: format!("éŸ³è‰²ID '{}' ä¸å­˜åœ¨æˆ–åŠ è½½å¤±è´¥: {}", voice_id, e),
                        }));
                        return Ok(());
                    }
                }
            } else {
                // voice_idä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤æ¨¡å¼
                (false, None, None)
            }
        } else {
            // æ²¡æœ‰æä¾›voice_idï¼Œä½¿ç”¨é»˜è®¤æ¨¡å¼
            (false, None, None)
        };

    // ç¡®å®šä½¿ç”¨çš„æç¤ºè¯ï¼šä¼˜å…ˆä½¿ç”¨éŸ³è‰²ç‰¹å¾ä¸­çš„æç¤ºè¯ï¼Œå…¶æ¬¡æ˜¯è¯·æ±‚ä¸­çš„æç¤ºè¯ï¼Œæœ€åæ˜¯é»˜è®¤æç¤ºè¯
    let final_prompt_text = if let Some(prompt_text) = prompt_text_from_voice {
        prompt_text
    } else {
        tts_request.prompt_text.clone().unwrap_or_default()
    };

    // zero-shotæ¨¡å¼åªåŸºäºvoice_idåˆ¤æ–­
    let zero_shot_mode = tts_request.voice_id.is_some();

    let pipeline_args = LightweightTtsPipelineArgs {
        text: tts_request.text.clone(),
        ref_audio_path: String::new(), // ä¸å†æ”¯æŒref_audio_path
        zero_shot: zero_shot_mode,
        temperature: tts_request.temperature.unwrap_or(1.0),
        top_p: tts_request.top_p.unwrap_or(0.90),
        top_k: 100,
        max_tokens: 8000,
        seed: tts_request.seed,
        // æ·»åŠ æ–°çš„é«˜çº§é€‰é¡¹å¹¶è¿›è¡Œç±»å‹è½¬æ¢
        age: tts_request.age.unwrap_or("youth-adult".to_string()),
        gender: tts_request.gender.unwrap_or("male".to_string()),
        emotion: tts_request.emotion.unwrap_or("NEUTRAL".to_string()),
        // éŸ³è°ƒå’Œè¯­é€Ÿéœ€è¦è½¬æ¢ä¸ºæ•°å€¼
        pitch: match tts_request.pitch.as_deref() {
            Some("low_pitch") => 150.0,
            Some("medium_pitch") => 200.0,
            Some("high_pitch") => 250.0,
            Some("very_high_pitch") => 300.0,
            _ => 200.0, // é»˜è®¤ä¸­éŸ³è°ƒ
        },
        speed: 4.2, // é»˜è®¤è¯­é€Ÿ
        // æ·»åŠ æç¤ºè¯
        prompt_text: final_prompt_text,
        // å¦‚æœæœ‰éŸ³è‰²ç‰¹å¾ï¼Œä¼ å…¥tokenså¹¶è½¬æ¢ä¸ºi64ç±»å‹
        voice_global_tokens: voice_feature.as_ref().map(|vf| vf.global_tokens.clone()),
        voice_semantic_tokens: voice_feature.as_ref().map(|vf| vf.semantic_tokens.clone()),
        ..Default::default()
    };
    let setup_time = setup_start.elapsed();
    info!(
        "  â±ï¸  å‚æ•°è®¾ç½®è€—æ—¶: {:.2}ms",
        setup_time.as_secs_f64() * 1000.0
    );

    // 3. TTSç”Ÿæˆï¼ˆä¸»è¦å¤„ç†æ—¶é—´ï¼‰
    let tts_start = std::time::Instant::now();
    let audio_data = match app_state.tts_pipeline.generate_speech(&pipeline_args).await {
        Ok(data) => data,
        Err(e) => {
            error!("ç”ŸæˆTTSéŸ³é¢‘å¤±è´¥: {}", e);
            res.status_code(StatusCode::INTERNAL_SERVER_ERROR);
            res.render(Json(ErrorResponse {
                success: false,
                error: format!("ç”ŸæˆTTSéŸ³é¢‘å¤±è´¥: {}", e),
            }));
            return Ok(());
        }
    };
    let tts_time = tts_start.elapsed();
    info!(
        "  â±ï¸  TTSç”Ÿæˆè€—æ—¶: {:.2}ms",
        tts_time.as_secs_f64() * 1000.0
    );

    // 4. éŸ³é¢‘æ ¼å¼è½¬æ¢
    let convert_start = std::time::Instant::now();
    let wav_data = convert_samples_to_wav(&audio_data, 16000);
    let convert_time = convert_start.elapsed();
    info!(
        "  â±ï¸  WAVè½¬æ¢è€—æ—¶: {:.2}ms",
        convert_time.as_secs_f64() * 1000.0
    );

    // 5. Base64ç¼–ç 
    let encode_start = std::time::Instant::now();
    let base64_audio = base64::engine::general_purpose::STANDARD.encode(&wav_data);
    let encode_time = encode_start.elapsed();
    info!(
        "  â±ï¸  Base64ç¼–ç è€—æ—¶: {:.2}ms",
        encode_time.as_secs_f64() * 1000.0
    );

    // 6. è®¡ç®—æ€»ä½“æ€§èƒ½æŒ‡æ ‡
    let total_time = total_start.elapsed();
    let rtf = calculate_rtf(&audio_data, total_time);
    let audio_duration = audio_data.len() as f64 / 16000.0;

    info!("ğŸ“Š TTSè¯·æ±‚å®Œæˆç»Ÿè®¡:");
    info!("  â±ï¸  æ€»è€—æ—¶: {:.2}ms", total_time.as_secs_f64() * 1000.0);
    info!("  ğŸµ éŸ³é¢‘æ—¶é•¿: {:.2}s", audio_duration);
    info!("  ğŸ“ˆ RTF: {:.3}", rtf);
    info!("  ğŸ“¦ éŸ³é¢‘æ ·æœ¬æ•°: {}", audio_data.len());
    info!("  ğŸ’¾ WAVæ–‡ä»¶å¤§å°: {} bytes", wav_data.len());
    info!("  ğŸ“ Base64å¤§å°: {} chars", base64_audio.len());

    // æ€§èƒ½åˆ†æå’Œä¼˜åŒ–å»ºè®®
    let tts_percentage = tts_time.as_secs_f64() / total_time.as_secs_f64() * 100.0;
    let convert_percentage = convert_time.as_secs_f64() / total_time.as_secs_f64() * 100.0;
    let encode_percentage = encode_time.as_secs_f64() / total_time.as_secs_f64() * 100.0;

    info!("ğŸ” æ€§èƒ½åˆ†æ:");
    info!("  - TTSç”Ÿæˆ: {:.1}%", tts_percentage);
    info!("  - WAVè½¬æ¢: {:.1}%", convert_percentage);
    info!("  - Base64ç¼–ç : {:.1}%", encode_percentage);
    info!(
        "  - å…¶ä»–å¼€é”€: {:.1}%",
        100.0 - tts_percentage - convert_percentage - encode_percentage
    );

    if rtf > 0.3 {
        info!("âš ï¸  æœåŠ¡å™¨æ€§èƒ½æç¤º: RTF > 0.3ï¼Œå»ºè®®ä¼˜åŒ–:");
        if tts_percentage > 90.0 {
            info!(
                "   - TTSç”Ÿæˆå ç”¨{:.1}%æ—¶é—´ï¼Œä¸»è¦ç“¶é¢ˆåœ¨æ¨¡å‹æ¨ç†",
                tts_percentage
            );
        }
        if convert_percentage > 5.0 {
            info!(
                "   - WAVè½¬æ¢å ç”¨{:.1}%æ—¶é—´ï¼Œè€ƒè™‘ä¼˜åŒ–éŸ³é¢‘å¤„ç†",
                convert_percentage
            );
        }
        if encode_percentage > 5.0 {
            info!(
                "   - Base64ç¼–ç å ç”¨{:.1}%æ—¶é—´ï¼Œè€ƒè™‘æµå¼ä¼ è¾“",
                encode_percentage
            );
        }
    }

    // 7. æ„å»ºå“åº”
    let response_start = std::time::Instant::now();
    res.render(Json(TtsResponse {
        success: true,
        message: "TTSç”ŸæˆæˆåŠŸ".to_string(),
        audio_base64: Some(base64_audio),
        duration_ms: Some(total_time.as_millis() as u64),
        rtf: Some(rtf),
    }));
    let response_time = response_start.elapsed();
    info!(
        "  â±ï¸  å“åº”æ„å»ºè€—æ—¶: {:.2}ms",
        response_time.as_secs_f64() * 1000.0
    );

    Ok(())
}

/// æä¾›Web UIç•Œé¢
#[handler]
async fn handle_web_ui(_req: &mut Request, res: &mut Response) {
    match Assets::get("index.html") {
        Some(content) => {
            let html = std::str::from_utf8(content.data.as_ref())
                .unwrap_or("<h1>Error reading embedded HTML</h1>");
            res.render(Text::Html(html.to_string()));
        }
        None => {
            res.render(Text::Html("<h1>Web UI not found</h1>".to_string()));
        }
    }
}

/// å¤„ç†åµŒå…¥çš„é™æ€æ–‡ä»¶
#[handler]
async fn handle_static_files(req: &mut Request, res: &mut Response) {
    let path = req.param::<String>("path").unwrap_or_default();

    // å¤„ç†æ ¹è·¯å¾„è¯·æ±‚ï¼Œè¿”å›index.html
    let file_path = if path.is_empty() || path == "/" {
        "index.html".to_string()
    } else {
        // ç§»é™¤å¼€å¤´çš„æ–œæ ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        path.trim_start_matches('/').to_string()
    };

    // è°ƒè¯•ï¼šæ‰“å°è¯·æ±‚ä¿¡æ¯
    debug!(
        "è¯·æ±‚è·¯å¾„: {}, å‚æ•°path: {}, æ–‡ä»¶è·¯å¾„: {}",
        req.uri().path(),
        path,
        file_path
    );

    // é¦–å…ˆå°è¯•ç›´æ¥æŸ¥æ‰¾æ–‡ä»¶
    if let Some(content) = Assets::get(&file_path) {
        debug!("æ‰¾åˆ°æ–‡ä»¶: {}", file_path);
        // æ ¹æ®æ–‡ä»¶æ‰©å±•åè®¾ç½®Content-Type
        let content_type = match file_path.split('.').next_back() {
            Some("html") => "text/html; charset=utf-8",
            Some("css") => "text/css",
            Some("js") => "application/javascript",
            Some("json") => "application/json",
            Some("png") => "image/png",
            Some("jpg") | Some("jpeg") => "image/jpeg",
            Some("gif") => "image/gif",
            Some("svg") => "image/svg+xml",
            Some("ico") => "image/x-icon",
            _ => "application/octet-stream",
        };
        res.add_header("content-type", content_type, true).unwrap();
        // å¤åˆ¶æ•°æ®ä»¥é¿å…ç”Ÿå‘½å‘¨æœŸé—®é¢˜
        let data = content.data.to_vec();
        res.write_body(data).unwrap();
        debug!("æˆåŠŸè¿”å›æ–‡ä»¶: {}", file_path);
        return;
    }

    // å¦‚æœæ‰¾ä¸åˆ°æ–‡ä»¶ï¼Œä¸”æ˜¯æ ¹è·¯å¾„ï¼Œè¿”å›index.html
    if path.is_empty() || path == "/" {
        if let Some(content) = Assets::get("index.html") {
            res.add_header("content-type", "text/html; charset=utf-8", true)
                .unwrap();
            // å¤åˆ¶æ•°æ®ä»¥é¿å…ç”Ÿå‘½å‘¨æœŸé—®é¢˜
            let data = content.data.to_vec();
            res.write_body(data).unwrap();
            debug!("è¿”å›é»˜è®¤index.html");
            return;
        }
    }

    // æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè¿”å›404
    res.status_code(StatusCode::NOT_FOUND);
    res.render(Text::Plain("File not found"));
    debug!("æ–‡ä»¶æœªæ‰¾åˆ°: {}", file_path);
}

/// å¤„ç†éŸ³è‰²ç‰¹å¾æå–è¯·æ±‚
#[handler]
async fn handle_voice_extract(req: &mut Request, res: &mut Response) -> Result<(), StatusError> {
    // æ£€æŸ¥æ˜¯å¦æ˜¯multipartè¯·æ±‚ï¼ˆæ–‡ä»¶ä¸Šä¼ ï¼‰
    if !req
        .content_type()
        .map(|ct| ct.type_() == "multipart")
        .unwrap_or(false)
    {
        let error_response = VoiceExtractResponse {
            success: false,
            message: "éœ€è¦ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶".to_string(),
            voice_id: None,
        };
        res.render(Json(error_response));
        return Ok(());
    }

    // multipartæ•°æ®ä¼šè‡ªåŠ¨è§£æï¼Œæ— éœ€æ‰‹åŠ¨è°ƒç”¨parse_form

    // æå–å‚æ•°
    let voice_name: String = req.form("voice_name").await.unwrap_or_default();
    let prompt_text: String = req.form("prompt_text").await.unwrap_or_default();
    let _description: Option<String> = req.form("description").await;

    if voice_name.is_empty() {
        let error_response = VoiceExtractResponse {
            success: false,
            message: "éŸ³è‰²åç§°ä¸èƒ½ä¸ºç©º".to_string(),
            voice_id: None,
        };
        res.render(Json(error_response));
        return Ok(());
    }

    if prompt_text.is_empty() {
        let error_response = VoiceExtractResponse {
            success: false,
            message: "æç¤ºè¯ä¸èƒ½ä¸ºç©º".to_string(),
            voice_id: None,
        };
        res.render(Json(error_response));
        return Ok(());
    }

    // è·å–ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶
    let file = match req.file("audio_file").await {
        Some(file) => file,
        None => {
            let error_response = VoiceExtractResponse {
                success: false,
                message: "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶".to_string(),
                voice_id: None,
            };
            res.render(Json(error_response));
            return Ok(());
        }
    };

    // ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•ï¼Œä¿æŒåŸå§‹æ‰©å±•å
    let original_filename = file.name().unwrap_or("audio");
    let extension = std::path::Path::new(original_filename)
        .extension()
        .and_then(|ext| ext.to_str())
        .unwrap_or("wav"); // é»˜è®¤ä¸ºwav

    let temp_dir = PathBuf::from("assets/raf/temp/upload_temp_files");
    let temp_file_path = temp_dir.join(format!("{}.{}", Uuid::new_v4(), extension));

    if let Err(e) = tokio::fs::copy(file.path(), &temp_file_path).await {
        error!("ä¿å­˜ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {}", e);
        let error_response = VoiceExtractResponse {
            success: false,
            message: "ä¿å­˜ä¸´æ—¶æ–‡ä»¶å¤±è´¥".to_string(),
            voice_id: None,
        };
        res.render(Json(error_response));
        return Ok(());
    }

    // è·å–åº”ç”¨çŠ¶æ€
    let app_state = get_global_app_state();

    // å®é™…çš„éŸ³é¢‘ç‰¹å¾æå–é€»è¾‘
    let (global_tokens, semantic_tokens, audio_duration, sample_rate) =
        match extract_audio_features(temp_file_path.to_str().unwrap()).await {
            Ok(features) => features,
            Err(e) => {
                error!("éŸ³é¢‘ç‰¹å¾æå–å¤±è´¥: {}", e);
                // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                let _ = fs::remove_file(&temp_file_path).await;

                let error_response = VoiceExtractResponse {
                    success: false,
                    message: format!("éŸ³é¢‘ç‰¹å¾æå–å¤±è´¥: {}", e),
                    voice_id: None,
                };
                res.render(Json(error_response));
                return Ok(());
            }
        };

    // ä½¿ç”¨éŸ³è‰²ç‰¹å¾ç®¡ç†å™¨æå–å¹¶ä¿å­˜éŸ³è‰²ç‰¹å¾
    match app_state
        .voice_manager
        .save_voice_feature(
            voice_name,
            prompt_text,
            global_tokens,
            semantic_tokens,
            audio_duration,
            sample_rate,
        )
        .await
    {
        Ok(voice_id) => {
            // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            let _ = fs::remove_file(&temp_file_path).await;

            let response = VoiceExtractResponse {
                success: true,
                message: "éŸ³è‰²ç‰¹å¾æå–æˆåŠŸ".to_string(),
                voice_id: Some(voice_id),
            };
            res.render(Json(response));
        }
        Err(e) => {
            error!("éŸ³è‰²ç‰¹å¾æå–å¤±è´¥: {}", e);
            // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            let _ = fs::remove_file(&temp_file_path).await;

            let error_response = VoiceExtractResponse {
                success: false,
                message: format!("éŸ³è‰²ç‰¹å¾æå–å¤±è´¥: {}", e),
                voice_id: None,
            };
            res.render(Json(error_response));
        }
    }

    Ok(())
}

/// å¤„ç†éŸ³è‰²åˆ—è¡¨è¯·æ±‚
#[handler]
async fn handle_voice_list(_req: &mut Request, res: &mut Response) -> Result<(), StatusError> {
    let app_state = get_global_app_state();

    match app_state.voice_manager.list_voices().await {
        Ok(voices) => {
            let response = VoiceListResponse {
                success: true,
                voices,
            };
            res.render(Json(response));
        }
        Err(e) => {
            error!("è·å–éŸ³è‰²åˆ—è¡¨å¤±è´¥: {}", e);
            let error_response = VoiceListResponse {
                success: false,
                voices: vec![],
            };
            res.render(Json(error_response));
        }
    }

    Ok(())
}

/// å¤„ç†éŸ³è‰²åˆ é™¤è¯·æ±‚
#[handler]
async fn handle_voice_delete(req: &mut Request, res: &mut Response) -> Result<(), StatusError> {
    let delete_request: VoiceDeleteRequest = match req.parse_json().await {
        Ok(req) => req,
        Err(e) => {
            error!("è§£æåˆ é™¤è¯·æ±‚å¤±è´¥: {}", e);
            let error_response = VoiceDeleteResponse {
                success: false,
                message: "è¯·æ±‚æ ¼å¼é”™è¯¯".to_string(),
            };
            res.render(Json(error_response));
            return Ok(());
        }
    };

    let app_state = get_global_app_state();

    match app_state
        .voice_manager
        .delete_voice(&delete_request.voice_id)
        .await
    {
        Ok(()) => {
            let response = VoiceDeleteResponse {
                success: true,
                message: "éŸ³è‰²åˆ é™¤æˆåŠŸ".to_string(),
            };
            res.render(Json(response));
        }
        Err(e) => {
            error!("åˆ é™¤éŸ³è‰²å¤±è´¥: {}", e);
            let error_response = VoiceDeleteResponse {
                success: false,
                message: format!("åˆ é™¤éŸ³è‰²å¤±è´¥: {}", e),
            };
            res.render(Json(error_response));
        }
    }

    Ok(())
}

/// CORSä¸­é—´ä»¶
#[handler]
async fn cors_handler(
    req: &mut Request,
    depot: &mut Depot,
    res: &mut Response,
    ctrl: &mut FlowCtrl,
) {
    res.headers_mut()
        .insert("Access-Control-Allow-Origin", "*".parse().unwrap());
    res.headers_mut().insert(
        "Access-Control-Allow-Methods",
        "GET, POST, OPTIONS".parse().unwrap(),
    );
    res.headers_mut().insert(
        "Access-Control-Allow-Headers",
        "Content-Type, Authorization".parse().unwrap(),
    );
    ctrl.call_next(req, depot, res).await;
}

/// ä¸­é—´ä»¶ï¼šè¯·æ±‚æ—¥å¿—
#[handler]
async fn request_logger(
    req: &mut Request,
    depot: &mut Depot,
    res: &mut Response,
    ctrl: &mut FlowCtrl,
) {
    let start = std::time::Instant::now();
    let method = req.method().clone();
    let path = req.uri().path().to_string();

    ctrl.call_next(req, depot, res).await;

    let duration = start.elapsed();
    let status = res.status_code.unwrap_or(StatusCode::OK);

    info!("{} {} {} - {:?}", method, path, status.as_u16(), duration);
}

/// è§£æé‡åŒ–ç±»å‹å­—ç¬¦ä¸²
fn parse_quant_type(s: &str) -> Result<Quant> {
    let quant_type = match s.to_lowercase().as_str() {
        "none" => Quant::None,
        "int8" => Quant::Int8,
        "nf4" => {
            warn!("NF4é‡åŒ–å¯èƒ½åœ¨æŸäº›GPUä¸Šå­˜åœ¨å…¼å®¹æ€§é—®é¢˜ï¼Œå»ºè®®ä½¿ç”¨Int8é‡åŒ–");
            Quant::NF4
        }
        "sf4" => {
            warn!("SF4é‡åŒ–å¯èƒ½åœ¨æŸäº›GPUä¸Šå­˜åœ¨å…¼å®¹æ€§é—®é¢˜ï¼Œå»ºè®®ä½¿ç”¨Int8é‡åŒ–");
            Quant::SF4
        }
        _ => {
            return Err(anyhow::anyhow!(
                "ä¸æ”¯æŒçš„é‡åŒ–ç±»å‹: {}. æ”¯æŒçš„ç±»å‹: none, int8, nf4, sf4",
                s
            ))
        }
    };

    // éªŒè¯é‡åŒ–ç±»å‹å…¼å®¹æ€§
    if matches!(quant_type, Quant::NF4 | Quant::SF4) {
        info!(
            "ä½¿ç”¨å®éªŒæ€§é‡åŒ–ç±»å‹: {:?}ï¼Œå¦‚é‡åˆ°é—®é¢˜è¯·æ”¹ç”¨ int8",
            quant_type
        );
    }

    Ok(quant_type)
}

/// åˆ›å»ºé‡åŒ–é…ç½®
fn create_quant_config(quant_layers: usize, quant_type: Quant) -> Option<HashMap<usize, Quant>> {
    if quant_layers == 0 || matches!(quant_type, Quant::None) {
        return None;
    }

    let mut config = HashMap::new();
    for layer in 0..quant_layers {
        config.insert(layer, quant_type);
    }
    Some(config)
}

/// ä»Hugging Faceä¸‹è½½æ¨¡å‹æ–‡ä»¶
async fn download_models_from_hf() -> Result<()> {
    info!("å¼€å§‹ä»Hugging Faceä¸‹è½½æ¨¡å‹æ–‡ä»¶...");

    // åˆ›å»ºæ¨¡å‹ç›®å½•
    let model_dir = PathBuf::from("assets/model");
    fs::create_dir_all(&model_dir).await?;

    // å®šä¹‰å¤šä¸ªé•œåƒåœ°å€
    let mirrors = [
        "https://huggingface.co", // å®˜æ–¹åœ°å€ï¼Œä¼˜å…ˆä½¿ç”¨
        "https://hf-mirror.com",  // ä¸­å›½é•œåƒï¼Œå¤‡ç”¨
    ];

    // éœ€è¦ä¸‹è½½çš„æ–‡ä»¶åˆ—è¡¨
    let files_to_download = vec![
        "rwkvtts-Int8_22.prefab",
        "tokenizer.json",
        "BiCodecTokenize.onnx",
        "wav2vec2-large-xlsr-53.onnx",
        "BiCodecDetokenize_static_qdq.onnx",
    ];

    for filename in files_to_download {
        let local_path = model_dir.join(filename);

        // å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½
        if local_path.exists() {
            info!("æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {}", filename);
            continue;
        }

        info!("æ­£åœ¨ä¸‹è½½: {}", filename);
        let mut download_success = false;
        let mut last_error = None;

        // å°è¯•æ¯ä¸ªé•œåƒ
        for (index, mirror_url) in mirrors.iter().enumerate() {
            info!("å°è¯•é•œåƒ {}/{}: {}", index + 1, mirrors.len(), mirror_url);

            // æ¸…é™¤ç°æœ‰çš„HF_ENDPOINTç¯å¢ƒå˜é‡
            std::env::remove_var("HF_ENDPOINT");

            // è®¾ç½®ç¯å¢ƒå˜é‡HF_ENDPOINTæ¥é…ç½®é•œåƒ
            std::env::set_var("HF_ENDPOINT", mirror_url);
            info!("è®¾ç½®ç¯å¢ƒå˜é‡ HF_ENDPOINT={}", mirror_url);

            // æ·»åŠ å°å»¶è¿Ÿç¡®ä¿ç¯å¢ƒå˜é‡ç”Ÿæ•ˆ
            tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;

            // éªŒè¯ç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®è®¾ç½®
            if let Ok(current_endpoint) = std::env::var("HF_ENDPOINT") {
                info!("HF_ENDPOINTå·²è®¾ç½®ä¸º: {}", current_endpoint);
            } else {
                warn!("è®¾ç½®HF_ENDPOINTå¤±è´¥: {}", mirror_url);
                continue;
            }

            // ä¸ºæ¯ä¸ªé•œåƒåˆ›å»ºæ–°çš„APIå®¢æˆ·ç«¯
            let api = match hf_hub::api::tokio::ApiBuilder::from_env().build() {
                Ok(api) => api,
                Err(e) => {
                    warn!("åˆå§‹åŒ–APIå®¢æˆ·ç«¯å¤±è´¥ ({}): {}", mirror_url, e);
                    // å¤±è´¥æ—¶æ¸…ç†ç¯å¢ƒå˜é‡
                    std::env::remove_var("HF_ENDPOINT");
                    last_error = Some(e.into());
                    continue;
                }
            };

            let repo = api.model("cgisky/rwkv-tts".to_string());

            // è®¾ç½®è¶…æ—¶æ—¶é—´
            let download_future = repo.get(filename);
            let timeout_duration = std::time::Duration::from_secs(300); // 5åˆ†é’Ÿè¶…æ—¶

            match tokio::time::timeout(timeout_duration, download_future).await {
                Ok(Ok(file_path)) => match fs::copy(&file_path, &local_path).await {
                    Ok(_) => {
                        let file_size = fs::metadata(&local_path).await?.len();
                        info!(
                            "ä¸‹è½½å®Œæˆ: {} ({} bytes) - ä½¿ç”¨é•œåƒ: {}",
                            filename, file_size, mirror_url
                        );
                        download_success = true;
                        break;
                    }
                    Err(e) => {
                        warn!("æ–‡ä»¶å¤åˆ¶å¤±è´¥ ({}): {}", mirror_url, e);
                        last_error = Some(e.into());
                    }
                },
                Ok(Err(e)) => {
                    warn!("ä¸‹è½½å¤±è´¥ ({}): {}", mirror_url, e);
                    last_error = Some(e.into());
                }
                Err(_) => {
                    warn!(
                        "ä¸‹è½½è¶…æ—¶ ({}): è¶…è¿‡{}ç§’",
                        mirror_url,
                        timeout_duration.as_secs()
                    );
                    last_error = Some(anyhow::anyhow!("ä¸‹è½½è¶…æ—¶"));
                }
            }
        }

        if !download_success {
            let error_msg = match last_error {
                Some(e) => format!("æ‰€æœ‰é•œåƒéƒ½å¤±è´¥äº†ï¼Œæœ€åä¸€ä¸ªé”™è¯¯: {}", e),
                None => "æ‰€æœ‰é•œåƒéƒ½å¤±è´¥äº†ï¼ŒæœªçŸ¥é”™è¯¯".to_string(),
            };
            error!("ä¸‹è½½æ–‡ä»¶å¤±è´¥: {} - {}", filename, error_msg);
            return Err(anyhow::anyhow!(
                "ä¸‹è½½æ–‡ä»¶å¤±è´¥: {} - {}",
                filename,
                error_msg
            ));
        }
    }

    // æ¸…ç†ç¯å¢ƒå˜é‡
    std::env::remove_var("HF_ENDPOINT");
    info!("æ‰€æœ‰æ¨¡å‹æ–‡ä»¶ä¸‹è½½å®Œæˆï¼");
    Ok(())
}

#[tokio::main]
async fn main() -> Result<()> {
    // è§£æå‘½ä»¤è¡Œå‚æ•°
    let matches = Command::new("RWKV TTS Server")
        .version(env!("CARGO_PKG_VERSION"))
        .about("åŸºäºRWKVçš„é«˜æ€§èƒ½TTSæœåŠ¡å™¨")
        .arg(
            Arg::new("quant-layers")
                .long("quant-layers")
                .value_name("NUMBER")
                .help("æŒ‡å®šé‡åŒ–å±‚æ•°")
                .default_value("24"),
        )
        .arg(
            Arg::new("quant-type")
                .long("quant-type")
                .value_name("TYPE")
                .help("æŒ‡å®šé‡åŒ–ç±»å‹ (none, int8, nf4, sf4)ã€‚æ¨èä½¿ç”¨ int8 ä»¥è·å¾—æœ€ä½³ç¨³å®šæ€§")
                .default_value("int8"),
        )
        .arg(
            Arg::new("model-path")
                .long("model-path")
                .value_name("PATH")
                .help("æ¨¡å‹æ–‡ä»¶è·¯å¾„")
                .default_value("assets/model/rwkvtts-Int8_22.prefab"),
        )
        .arg(
            Arg::new("vocab-path")
                .long("vocab-path")
                .value_name("PATH")
                .help("è¯æ±‡è¡¨æ–‡ä»¶è·¯å¾„")
                .default_value("assets/model/tokenizer.json"),
        )
        .arg(
            Arg::new("batch-size")
                .long("batch-size")
                .value_name("NUMBER")
                .help("æ‰¹å¤„ç†æœ€å¤§å¤§å°")
                .default_value("10"),
        )
        .arg(
            Arg::new("batch-timeout")
                .long("batch-timeout")
                .value_name("MS")
                .help("æ‰¹å¤„ç†è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰")
                .default_value("20"),
        )
        .arg(
            Arg::new("inference-timeout")
                .long("inference-timeout")
                .value_name("MS")
                .help("æ¨ç†è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰")
                .default_value("120000"),
        )
        .arg(
            Arg::new("port")
                .long("port")
                .value_name("PORT")
                .help("æœåŠ¡å™¨ç›‘å¬ç«¯å£")
                .default_value("3000"),
        )
        .get_matches();

    // åˆå§‹åŒ–æ—¥å¿—ï¼Œè¿‡æ»¤æ‰ortå’Œweb-rwkvçš„è°ƒè¯•è¾“å‡º
    let filter = EnvFilter::new("debug")
        .add_directive("ort=warn".parse().unwrap())
        .add_directive("web_rwkv=warn".parse().unwrap())
        .add_directive("naga=warn".parse().unwrap())
        .add_directive("wgpu=warn".parse().unwrap());

    tracing_subscriber::fmt().with_env_filter(filter).init();

    info!("å¯åŠ¨RWKV TTS HTTPæœåŠ¡å™¨...");

    // è·å–å‘½ä»¤è¡Œå‚æ•°
    let model_path = matches.get_one::<String>("model-path").unwrap();
    let vocab_path = matches.get_one::<String>("vocab-path").unwrap();
    let quant_layers: usize = matches
        .get_one::<String>("quant-layers")
        .unwrap()
        .parse()
        .map_err(|e| anyhow::anyhow!("æ— æ•ˆçš„é‡åŒ–å±‚æ•°: {}", e))?;
    let quant_type_str = matches.get_one::<String>("quant-type").unwrap();
    let quant_type = parse_quant_type(quant_type_str)?;

    // åˆ›å»ºé‡åŒ–é…ç½®
    let quant_config = create_quant_config(quant_layers, quant_type);

    // æ‰“å°é‡åŒ–é…ç½®ä¿¡æ¯
    match &quant_config {
        Some(config) => {
            info!("ğŸ”§ é‡åŒ–é…ç½®: {} å±‚ä½¿ç”¨ {:?} é‡åŒ–", config.len(), quant_type);
        }
        None => {
            info!("ğŸ”§ æœªå¯ç”¨é‡åŒ–");
        }
    }

    // éªŒè¯æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™å°è¯•ä¸‹è½½
    let model_missing = !Path::new(model_path).exists();
    let vocab_missing = !Path::new(vocab_path).exists();
    let onnx_files = [
        "assets/model/BiCodecTokenize.onnx",
        "assets/model/wav2vec2-large-xlsr-53.onnx",
        "assets/model/BiCodecDetokenize.onnx",
    ];
    let onnx_missing = onnx_files.iter().any(|path| !Path::new(path).exists());

    if model_missing || vocab_missing || onnx_missing {
        warn!("æ£€æµ‹åˆ°ç¼ºå¤±çš„æ¨¡å‹æ–‡ä»¶ï¼Œå°è¯•ä»Hugging Faceä¸‹è½½...");
        if model_missing {
            warn!("æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {}", model_path);
        }
        if vocab_missing {
            warn!("è¯æ±‡è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {}", vocab_path);
        }
        if onnx_missing {
            warn!("ONNXæ¨¡å‹æ–‡ä»¶ç¼ºå¤±");
        }

        // å°è¯•ä¸‹è½½æ¨¡å‹
        match download_models_from_hf().await {
            Ok(()) => {
                info!("æ¨¡å‹ä¸‹è½½æˆåŠŸï¼Œç»§ç»­å¯åŠ¨æœåŠ¡å™¨...");
            }
            Err(e) => {
                error!("æ¨¡å‹ä¸‹è½½å¤±è´¥: {}", e);
                return Err(anyhow::anyhow!("æ— æ³•è·å–å¿…è¦çš„æ¨¡å‹æ–‡ä»¶: {}", e));
            }
        }

        // å†æ¬¡éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if !Path::new(model_path).exists() {
            return Err(anyhow::anyhow!("ä¸‹è½½åæ¨¡å‹æ–‡ä»¶ä»ä¸å­˜åœ¨: {}", model_path));
        }
        if !Path::new(vocab_path).exists() {
            return Err(anyhow::anyhow!("ä¸‹è½½åè¯æ±‡è¡¨æ–‡ä»¶ä»ä¸å­˜åœ¨: {}", vocab_path));
        }
        for onnx_path in &onnx_files {
            if !Path::new(onnx_path).exists() {
                return Err(anyhow::anyhow!("ä¸‹è½½åONNXæ–‡ä»¶ä»ä¸å­˜åœ¨: {}", onnx_path));
            }
        }
    }

    info!("æ¨¡å‹è·¯å¾„éªŒè¯æˆåŠŸ: {}", model_path);
    info!("è¯æ±‡è¡¨è·¯å¾„éªŒè¯æˆåŠŸ: {}", vocab_path);

    // æ¶æ„ä¼˜åŒ–ï¼šç§»é™¤å…¨å±€RwkvSamplerç®¡ç†å™¨ï¼Œé¿å…ä¸åŠ¨æ€æ‰¹å¤„ç†ç®¡ç†å™¨çš„é‡å¤åˆå§‹åŒ–
    // åŠ¨æ€æ‰¹å¤„ç†ç®¡ç†å™¨å·²ç»å†…ç½®äº†å…±äº«Runtimeæ¶æ„ï¼Œæ— éœ€é¢å¤–çš„å…¨å±€ç®¡ç†å™¨

    // ä»å‘½ä»¤è¡Œå‚æ•°è·å–æ‰¹å¤„ç†é…ç½®
    let batch_size: usize = matches
        .get_one::<String>("batch-size")
        .unwrap()
        .parse()
        .expect("æ— æ•ˆçš„æ‰¹å¤„ç†å¤§å°");

    info!("åˆå§‹åŒ–ONNXä¼šè¯æ± ï¼ˆä½¿ç”¨åŸå§‹BiCodecæ¨¡å‹ï¼‰...");
    rwkv_tts_rs::onnx_session_pool::init_global_onnx_manager(
        "assets/model/BiCodecTokenize.onnx",
        "assets/model/wav2vec2-large-xlsr-53.onnx",
        "assets/model/BiCodecDetokenize.onnx",
        Some(4),
    )
    .map_err(|e| anyhow::anyhow!("åˆå§‹åŒ–ONNXç®¡ç†å™¨å¤±è´¥: {}", e))?;

    info!("åˆå§‹åŒ–åŠ¨æ€æ‰¹å¤„ç†ç®¡ç†å™¨...");
    // è·å–æ‰¹å¤„ç†è¶…æ—¶é…ç½®
    let batch_timeout: u64 = matches
        .get_one::<String>("batch-timeout")
        .unwrap()
        .parse()
        .expect("æ— æ•ˆçš„æ‰¹å¤„ç†è¶…æ—¶æ—¶é—´");

    // è·å–æ¨ç†è¶…æ—¶é…ç½®
    let inference_timeout: u64 = matches
        .get_one::<String>("inference-timeout")
        .unwrap()
        .parse()
        .expect("æ— æ•ˆçš„æ¨ç†è¶…æ—¶æ—¶é—´");

    // è‡ªåŠ¨è®¡ç®—æœ€å¤§å¹¶å‘æ‰¹æ¬¡æ•°
    let max_concurrent_batches: usize = if batch_size <= 10 {
        10
    } else {
        std::cmp::max(8, batch_size / 10)
    };

    // åˆ›å»ºåŠ¨æ€æ‰¹å¤„ç†é…ç½®
    let dynamic_batch_config = rwkv_tts_rs::batch_types::DynamicBatchConfig {
        min_batch_size: 1,
        max_batch_size: batch_size,              // å¯é…ç½®çš„æ‰¹å¤„ç†å¤§å°
        collect_timeout_ms: batch_timeout,       // å¯é…ç½®çš„è¶…æ—¶æ—¶é—´
        inference_timeout_ms: inference_timeout, // å¯é…ç½®çš„æ¨ç†è¶…æ—¶æ—¶é—´
        max_concurrent_batches,                  // å¯é…ç½®çš„å¹¶å‘æ‰¹æ¬¡æ•°
        semaphore_permits: (max_concurrent_batches * 3 / 4).clamp(1, 8), // ä¿¡å·é‡è®¸å¯æ•°é‡ç•¥å°äºå¹¶å‘æ•°
    };
    info!(
        "åŠ¨æ€æ‰¹å¤„ç†é…ç½®: æœ€å¤§å¤§å°={}, æ”¶é›†è¶…æ—¶={}ms, æ¨ç†è¶…æ—¶={}ms, æœ€å¤§å¹¶å‘æ‰¹æ¬¡={}ï¼ˆè‡ªåŠ¨è®¡ç®—ï¼‰",
        batch_size, batch_timeout, inference_timeout, max_concurrent_batches
    );
    rwkv_tts_rs::dynamic_batch_manager::init_global_dynamic_batch_manager(
        model_path,
        vocab_path,
        dynamic_batch_config,
        quant_config,
    )
    .await
    .map_err(|e| anyhow::anyhow!("åˆå§‹åŒ–åŠ¨æ€æ‰¹å¤„ç†ç®¡ç†å™¨å¤±è´¥: {}", e))?;

    // åˆ›å»ºè½»é‡çº§TTSæµæ°´çº¿
    let tts_pipeline = Arc::new(LightweightTtsPipeline::new());

    // åˆå§‹åŒ–éŸ³è‰²ç‰¹å¾ç®¡ç†å™¨
    let voice_manager = Arc::new(VoiceFeatureManager::new("assets/raf")?);

    let app_state = AppState {
        start_time: std::time::Instant::now(),
        model_path: model_path.to_string(),
        vocab_path: vocab_path.to_string(),
        tts_pipeline,
        voice_manager,
    };

    // åˆå§‹åŒ–å…¨å±€åº”ç”¨çŠ¶æ€
    init_global_app_state(app_state);

    // åˆ›å»ºè·¯ç”±
    let router = Router::new()
        .hoop(cors_handler)
        .push(Router::with_path("/api/tts").post(handle_tts))
        .push(Router::with_path("/api/voice-clone/extract").post(handle_voice_extract))
        .push(Router::with_path("/api/voice-clone/list").get(handle_voice_list))
        .push(Router::with_path("/api/voice-clone/delete").delete(handle_voice_delete))
        .push(Router::with_path("{*path}").get(handle_static_files));

    // æ³¨æ„ï¼šç°åœ¨é™æ€æ–‡ä»¶å·²åµŒå…¥åˆ°äºŒè¿›åˆ¶æ–‡ä»¶ä¸­ï¼Œä¸å†ä¾èµ–å¤–éƒ¨staticç›®å½•

    // åˆ›å»ºæœåŠ¡
    let service = Service::new(router).hoop(request_logger);

    let port: u16 = matches
        .get_one::<String>("port")
        .and_then(|s| s.parse::<u16>().ok())
        .unwrap_or(3000);

    let acceptor = TcpListener::new(format!("0.0.0.0:{port}")).bind().await;

    info!("æœåŠ¡å™¨å¯åŠ¨æˆåŠŸï¼Œç›‘å¬ç«¯å£: http://0.0.0.0:{}", port);
    info!("Web UI: http://localhost:{}", port);
    info!("APIæ–‡æ¡£: http://localhost:{}/api/status", port);
    info!("TTSæœåŠ¡å·²å°±ç»ªï¼Œä½¿ç”¨é¢„åŠ è½½çš„å…¨å±€æ¨¡å‹å®ä¾‹ï¼Œæ”¯æŒé«˜å¹¶å‘è®¿é—®");

    Server::new(acceptor).serve(service).await;

    Ok(())
}
