//! å‚è€ƒéŸ³é¢‘å¤„ç†å·¥å…·æ¨¡å—
//! å®ç°ä¸Pythonç‰ˆæœ¬ref_audio_utilities.pyç›¸åŒçš„åŠŸèƒ½

use anyhow::{anyhow, Result};
use ndarray::{Array1, Array2};
use ort::session::builder::GraphOptimizationLevel;
use ort::session::input::SessionInputValue;
use ort::session::Session;
use ort::value::Value;
use rubato::{
    Resampler, SincFixedIn, SincInterpolationParameters, SincInterpolationType, WindowFunction,
};
use std::path::Path;
use symphonia::core::audio::{AudioBufferRef, Signal};
use symphonia::core::codecs::{DecoderOptions, CODEC_TYPE_NULL};

use symphonia::core::formats::FormatOptions;
use symphonia::core::io::MediaSourceStream;
use symphonia::core::meta::MetadataOptions;
use symphonia::core::probe::Hint;

/// å‚è€ƒéŸ³é¢‘å¤„ç†å·¥å…·ç±»
pub struct RefAudioUtilities {
    ort_session: Option<Session>,
    wav2vec2_session: Option<Session>,
    sample_rate: u32,
    #[allow(dead_code)]
    ref_segment_duration: f32,
    latent_hop_length: u32,
    bicodec_detokenizer_session: Option<Session>,
}

impl RefAudioUtilities {
    /// åˆ›å»ºæ–°çš„å‚è€ƒéŸ³é¢‘å¤„ç†å·¥å…·å®ä¾‹
    pub fn new(
        onnx_model_path: &str,
        wav2vec2_path: &str,
        ref_segment_duration: f32,
        latent_hop_length: u32,
        detokenizer_path: Option<&str>,
    ) -> Result<Self> {
        // æµ‹è¯•æ¨¡å¼ï¼šå¦‚æœè·¯å¾„åŒ…å«"dummy"ï¼Œåˆ™è·³è¿‡å®é™…æ¨¡å‹åŠ è½½
        #[cfg(test)]
        if onnx_model_path.contains("dummy") || wav2vec2_path.contains("dummy") {
            return Ok(Self {
                ort_session: None,
                wav2vec2_session: None,
                sample_rate: 16000,
                ref_segment_duration,
                latent_hop_length,
                bicodec_detokenizer_session: None,
            });
        }

        // æ ¹æ®CPUæ ¸å¿ƒæ•°åŠ¨æ€è®¾ç½®çº¿ç¨‹æ•°ï¼Œæå‡æ€§èƒ½
        let cpu_cores = std::thread::available_parallelism()
            .map(|n| n.get())
            .unwrap_or(4); // é»˜è®¤4æ ¸

        // è®¾ç½®åˆç†çš„çº¿ç¨‹æ•°ï¼šinter_threadsæ§åˆ¶å¹¶è¡Œæ“ä½œæ•°ï¼Œintra_threadsæ§åˆ¶å•ä¸ªæ“ä½œå†…çš„å¹¶è¡Œåº¦
        let inter_threads = std::cmp::min(cpu_cores / 2, 4); // æœ€å¤š4ä¸ªinterçº¿ç¨‹
        let intra_threads = std::cmp::max(cpu_cores / 4, 2); // è‡³å°‘2ä¸ªintraçº¿ç¨‹

        // åˆ›å»ºä¼šè¯æ„å»ºå™¨çš„è¾…åŠ©å‡½æ•°
        let create_session_builder = || -> Result<ort::session::builder::SessionBuilder> {
            let mut builder =
                Session::builder()?.with_optimization_level(GraphOptimizationLevel::Level3)?;

            // åœ¨émacOSç³»ç»Ÿä¸Šè®¾ç½®çº¿ç¨‹æ•°ä»¥æå‡æ€§èƒ½
            #[cfg(not(target_os = "macos"))]
            {
                builder = builder
                    .with_inter_threads(inter_threads)?
                    .with_intra_threads(intra_threads)?;
            }

            // macOSç³»ç»Ÿä¿æŒé»˜è®¤è®¾ç½®ä»¥é¿å…mutexé—®é¢˜
            #[cfg(target_os = "macos")]
            {
                builder = builder.with_inter_threads(1)?;
            }

            Ok(builder)
        };

        // ä½¿ç”¨ ort 2.x çš„ Session::builder() API æ„å»ºä¼šè¯
        let ort_session = create_session_builder()?.commit_from_file(onnx_model_path)?;

        let wav2vec2_session = create_session_builder()?.commit_from_file(wav2vec2_path)?;

        // å¯é€‰çš„detokenizerä¼šè¯
        let bicodec_detokenizer_session = if let Some(detokenizer_path) = detokenizer_path {
            {
                let result = create_session_builder()?.commit_from_file(detokenizer_path);
                if let Err(_e) = &result {
                    // Warning: Failed to load BiCodecDetokenize model
                }
                result.ok()
            }
        } else {
            None
        };

        Ok(Self {
            ort_session: Some(ort_session),
            wav2vec2_session: Some(wav2vec2_session),
            sample_rate: 16000,
            ref_segment_duration,
            latent_hop_length,
            bicodec_detokenizer_session,
        })
    }

    /// åŠ è½½éŸ³é¢‘æ–‡ä»¶å¹¶è¿›è¡Œé¢„å¤„ç† - æ”¯æŒWAVå’ŒMP3æ ¼å¼
    pub fn load_audio(
        &self,
        audio_path: &str,
        target_sr: u32,
        volume_normalize: bool,
    ) -> Result<Array1<f32>> {
        // Loading audio file

        if !Path::new(audio_path).exists() {
            return Err(anyhow!("éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {}", audio_path));
        }

        // æ£€æŸ¥æ–‡ä»¶å¤§å°
        let metadata =
            std::fs::metadata(audio_path).map_err(|e| anyhow!("æ— æ³•è¯»å–æ–‡ä»¶å…ƒæ•°æ®: {}", e))?;
        if metadata.len() == 0 {
            return Err(anyhow!("éŸ³é¢‘æ–‡ä»¶ä¸ºç©º: {}", audio_path));
        }
        if metadata.len() > 100 * 1024 * 1024 {
            // 100MBé™åˆ¶
            return Err(anyhow!("éŸ³é¢‘æ–‡ä»¶è¿‡å¤§ (>100MB): {}", audio_path));
        }

        // æ£€æŸ¥æ–‡ä»¶æ‰©å±•åä»¥ç¡®å®šæ ¼å¼
        let path = Path::new(audio_path);
        let extension = path
            .extension()
            .and_then(|ext| ext.to_str())
            .unwrap_or("")
            .to_lowercase();

        let (audio_samples, sample_rate, channels) = match extension.as_str() {
            "mp3" => {
                // ä½¿ç”¨symphoniaè§£ç MP3æ–‡ä»¶
                self.load_audio_with_symphonia(audio_path)?
            }
            "wav" => self.load_audio_with_hound(audio_path)?,
            _ => {
                // ä½¿ç”¨houndè§£ç WAVæ–‡ä»¶ï¼ˆé»˜è®¤å¤„ç†ï¼‰
                self.load_audio_with_hound(audio_path)?
            }
        };

        // éªŒè¯éŸ³é¢‘æ•°æ®çš„åˆç†æ€§
        if audio_samples.is_empty() {
            return Err(anyhow!("éŸ³é¢‘æ–‡ä»¶ä¸åŒ…å«æœ‰æ•ˆçš„éŸ³é¢‘æ•°æ®"));
        }
        if audio_samples.len() < channels as usize {
            return Err(anyhow!("éŸ³é¢‘æ•°æ®ä¸å®Œæ•´ï¼šæ ·æœ¬æ•°å°‘äºå£°é“æ•°"));
        }

        // æ£€æŸ¥éŸ³é¢‘æœ€å°é•¿åº¦è¦æ±‚ï¼ˆè‡³å°‘0.1ç§’ï¼‰
        let min_samples = (sample_rate as f32 * 0.1) as usize;
        if audio_samples.len() < min_samples {
            return Err(anyhow!(
                "éŸ³é¢‘å¤ªçŸ­ï¼š{:.3}ç§’ï¼ˆæœ€å°‘éœ€è¦0.1ç§’ï¼‰ï¼Œæ ·æœ¬æ•°ï¼š{}",
                audio_samples.len() as f32 / sample_rate as f32,
                audio_samples.len()
            ));
        }

        let mut audio = Array1::from(audio_samples);

        // å¤šå£°é“è½¬å•å£°é“ - ä¸C++å®ç°ä¸€è‡´ï¼ˆå–ç¬¬ä¸€ä¸ªé€šé“ï¼‰
        if channels > 1 {
            // Converting channels to mono
            let len = audio.len() / channels as usize;
            let mut mono_audio = Vec::with_capacity(len);
            for i in 0..len {
                mono_audio.push(audio[i * channels as usize]);
            }
            audio = Array1::from(mono_audio);
        }

        // éªŒè¯è½¬æ¢åçš„éŸ³é¢‘æ•°æ®
        if audio.is_empty() {
            return Err(anyhow!("éŸ³é¢‘å¤„ç†åæ•°æ®ä¸ºç©º"));
        }

        // æ£€æŸ¥éŸ³é¢‘æ•°æ®çš„æ•°å€¼èŒƒå›´
        let max_val = audio.iter().fold(f32::NEG_INFINITY, |a, &b| a.max(b.abs()));
        if max_val > 10.0 {
            // éŸ³é¢‘æ•°æ®å¯èƒ½æœªæ­£ç¡®å½’ä¸€åŒ–
        }

        // é‡é‡‡æ ·åˆ°ç›®æ ‡é‡‡æ ·ç‡ - ä¸C++çš„wav->resample(16000)ä¿æŒä¸€è‡´
        if sample_rate != target_sr {
            // Resampling audio
            audio = self.resample_audio_high_quality(audio, sample_rate, target_sr)?;

            // éªŒè¯é‡é‡‡æ ·ç»“æœ
            if audio.is_empty() {
                return Err(anyhow!("é‡é‡‡æ ·åéŸ³é¢‘æ•°æ®ä¸ºç©º"));
            }
        }

        // éŸ³é‡å½’ä¸€åŒ–
        if volume_normalize {
            // Applying volume normalization
            audio = self.audio_volume_normalize(audio, 0.2);
        }

        // é™éŸ³å¤„ç†ï¼šä»…è£å‰ªå¼€å¤´å’Œç»“å°¾é™éŸ³ï¼Œé¿å…å¼ºåˆ¶å¡«å……å¯¼è‡´å¯¹é½åç§»
        audio = self.trim_silence_only(audio, 0.01);

        // Final audio length processed
        Ok(audio)
    }

    /// ä½¿ç”¨houndåº“åŠ è½½WAVæ–‡ä»¶
    fn load_audio_with_hound(&self, audio_path: &str) -> Result<(Vec<f32>, u32, u16)> {
        let mut reader = hound::WavReader::open(audio_path).map_err(|e| {
            anyhow!(
                "æ— æ³•æ‰“å¼€WAVæ–‡ä»¶ '{}': {}\næç¤ºï¼šè¯·ç¡®ä¿æ–‡ä»¶æœªæŸåä¸”æ ¼å¼æ­£ç¡®",
                audio_path,
                e
            )
        })?;
        let spec = reader.spec();

        // WAV spec loaded

        // éªŒè¯éŸ³é¢‘æ ¼å¼
        if spec.bits_per_sample != 16 && spec.bits_per_sample != 24 && spec.bits_per_sample != 32 {
            return Err(anyhow!(
                "ä¸æ”¯æŒçš„ä½æ·±åº¦: {} (æ”¯æŒ16/24/32ä½)",
                spec.bits_per_sample
            ));
        }

        // éªŒè¯éŸ³é¢‘è§„æ ¼çš„åˆç†æ€§
        if spec.channels == 0 || spec.channels > 8 {
            return Err(anyhow!("ä¸æ”¯æŒçš„å£°é“æ•°: {} (æ”¯æŒ1-8å£°é“)", spec.channels));
        }
        if spec.sample_rate == 0 || spec.sample_rate > 192000 {
            return Err(anyhow!(
                "ä¸æ”¯æŒçš„é‡‡æ ·ç‡: {} Hz (æ”¯æŒ1-192000 Hz)",
                spec.sample_rate
            ));
        }

        // è¯»å–éŸ³é¢‘æ ·æœ¬å¹¶è½¬æ¢ä¸ºf32
        let samples: Result<Vec<f32>, _> = if spec.bits_per_sample == 16 {
            let samples: Result<Vec<i16>, _> = reader.samples().collect();
            Ok(samples?.into_iter().map(|s| s as f32 / 32768.0).collect())
        } else if spec.bits_per_sample == 24 {
            let samples: Result<Vec<i32>, _> = reader.samples().collect();
            Ok(samples?.into_iter().map(|s| s as f32 / 8388608.0).collect())
        } else if spec.bits_per_sample == 32 {
            match spec.sample_format {
                hound::SampleFormat::Float => {
                    let samples: Result<Vec<f32>, _> = reader.samples().collect();
                    samples
                }
                hound::SampleFormat::Int => {
                    let samples: Result<Vec<i32>, _> = reader.samples().collect();
                    Ok(samples?
                        .into_iter()
                        .map(|s| s as f32 / 2147483648.0)
                        .collect())
                }
            }
        } else {
            return Err(anyhow!("ä¸æ”¯æŒçš„ä½æ·±åº¦: {}", spec.bits_per_sample));
        };

        let audio_samples = samples
            .map_err(|e| anyhow!("è¯»å–éŸ³é¢‘æ ·æœ¬å¤±è´¥: {}\næç¤ºï¼šæ–‡ä»¶å¯èƒ½å·²æŸåæˆ–æ ¼å¼ä¸æ­£ç¡®", e))?;

        Ok((audio_samples, spec.sample_rate, spec.channels))
    }

    /// ä½¿ç”¨symphoniaåº“åŠ è½½MP3æ–‡ä»¶
    fn load_audio_with_symphonia(&self, audio_path: &str) -> Result<(Vec<f32>, u32, u16)> {
        // æ‰“å¼€æ–‡ä»¶
        let file = std::fs::File::open(audio_path)
            .map_err(|e| anyhow!("æ— æ³•æ‰“å¼€MP3æ–‡ä»¶ '{}': {}", audio_path, e))?;
        let mss = MediaSourceStream::new(Box::new(file), Default::default());

        // åˆ›å»ºæ ¼å¼æç¤º
        let mut hint = Hint::new();
        hint.with_extension("mp3");

        // æ¢æµ‹æ ¼å¼
        let meta_opts: MetadataOptions = Default::default();
        let fmt_opts: FormatOptions = Default::default();

        let probed = symphonia::default::get_probe()
            .format(&hint, mss, &fmt_opts, &meta_opts)
            .map_err(|e| anyhow!("æ— æ³•æ¢æµ‹MP3æ–‡ä»¶æ ¼å¼: {}", e))?;

        let mut format = probed.format;

        // æŸ¥æ‰¾é»˜è®¤éŸ³é¢‘è½¨é“
        let track = format
            .tracks()
            .iter()
            .find(|t| t.codec_params.codec != CODEC_TYPE_NULL)
            .ok_or_else(|| anyhow!("MP3æ–‡ä»¶ä¸­æœªæ‰¾åˆ°éŸ³é¢‘è½¨é“"))?;

        let track_id = track.id;
        let codec_params = &track.codec_params;

        // è·å–éŸ³é¢‘å‚æ•°
        let sample_rate = codec_params.sample_rate.unwrap_or(44100);
        let channels = codec_params.channels.map(|ch| ch.count()).unwrap_or(2) as u16;

        // MP3 spec loaded

        // åˆ›å»ºè§£ç å™¨
        let dec_opts: DecoderOptions = Default::default();
        let mut decoder = symphonia::default::get_codecs()
            .make(codec_params, &dec_opts)
            .map_err(|e| anyhow!("æ— æ³•åˆ›å»ºMP3è§£ç å™¨: {}", e))?;

        // è§£ç éŸ³é¢‘æ•°æ®
        let mut audio_samples = Vec::new();

        loop {
            // è·å–ä¸‹ä¸€ä¸ªæ•°æ®åŒ…
            let packet = match format.next_packet() {
                Ok(packet) => packet,
                Err(symphonia::core::errors::Error::ResetRequired) => {
                    // è§£ç å™¨éœ€è¦é‡ç½®ï¼Œä½†æˆ‘ä»¬å¯ä»¥ç»§ç»­
                    continue;
                }
                Err(symphonia::core::errors::Error::IoError(ref e))
                    if e.kind() == std::io::ErrorKind::UnexpectedEof =>
                {
                    // æ–‡ä»¶ç»“æŸ
                    break;
                }
                Err(e) => return Err(anyhow!("è¯»å–MP3æ•°æ®åŒ…å¤±è´¥: {}", e)),
            };

            // è·³è¿‡éç›®æ ‡è½¨é“çš„æ•°æ®åŒ…
            if packet.track_id() != track_id {
                continue;
            }

            // è§£ç æ•°æ®åŒ…
            match decoder.decode(&packet) {
                Ok(decoded) => {
                    // è½¬æ¢éŸ³é¢‘ç¼“å†²åŒºä¸ºf32æ ·æœ¬
                    match decoded {
                        AudioBufferRef::F32(buf) => {
                            for &sample in buf.chan(0) {
                                audio_samples.push(sample);
                            }
                            // å¦‚æœæ˜¯ç«‹ä½“å£°ï¼Œäº¤é”™å­˜å‚¨
                            if channels > 1 {
                                for ch in 1..channels as usize {
                                    if ch < buf.spec().channels.count() {
                                        for &sample in buf.chan(ch) {
                                            audio_samples.push(sample);
                                        }
                                    }
                                }
                            }
                        }
                        AudioBufferRef::U8(buf) => {
                            for &sample in buf.chan(0) {
                                audio_samples.push((sample as f32 - 128.0) / 128.0);
                            }
                            if channels > 1 {
                                for ch in 1..channels as usize {
                                    if ch < buf.spec().channels.count() {
                                        for &sample in buf.chan(ch) {
                                            audio_samples.push((sample as f32 - 128.0) / 128.0);
                                        }
                                    }
                                }
                            }
                        }
                        AudioBufferRef::U16(buf) => {
                            for &sample in buf.chan(0) {
                                audio_samples.push((sample as f32 - 32768.0) / 32768.0);
                            }
                            if channels > 1 {
                                for ch in 1..channels as usize {
                                    if ch < buf.spec().channels.count() {
                                        for &sample in buf.chan(ch) {
                                            audio_samples.push((sample as f32 - 32768.0) / 32768.0);
                                        }
                                    }
                                }
                            }
                        }
                        AudioBufferRef::U24(buf) => {
                            for &sample in buf.chan(0) {
                                let val = sample.inner() as f32;
                                audio_samples.push((val - 8388608.0) / 8388608.0);
                            }
                            if channels > 1 {
                                for ch in 1..channels as usize {
                                    if ch < buf.spec().channels.count() {
                                        for &sample in buf.chan(ch) {
                                            let val = sample.inner() as f32;
                                            audio_samples.push((val - 8388608.0) / 8388608.0);
                                        }
                                    }
                                }
                            }
                        }
                        AudioBufferRef::U32(buf) => {
                            for &sample in buf.chan(0) {
                                audio_samples.push((sample as f32 - 2147483648.0) / 2147483648.0);
                            }
                            if channels > 1 {
                                for ch in 1..channels as usize {
                                    if ch < buf.spec().channels.count() {
                                        for &sample in buf.chan(ch) {
                                            audio_samples.push(
                                                (sample as f32 - 2147483648.0) / 2147483648.0,
                                            );
                                        }
                                    }
                                }
                            }
                        }
                        AudioBufferRef::S8(buf) => {
                            for &sample in buf.chan(0) {
                                audio_samples.push(sample as f32 / 128.0);
                            }
                            if channels > 1 {
                                for ch in 1..channels as usize {
                                    if ch < buf.spec().channels.count() {
                                        for &sample in buf.chan(ch) {
                                            audio_samples.push(sample as f32 / 128.0);
                                        }
                                    }
                                }
                            }
                        }
                        AudioBufferRef::S16(buf) => {
                            for &sample in buf.chan(0) {
                                audio_samples.push(sample as f32 / 32768.0);
                            }
                            if channels > 1 {
                                for ch in 1..channels as usize {
                                    if ch < buf.spec().channels.count() {
                                        for &sample in buf.chan(ch) {
                                            audio_samples.push(sample as f32 / 32768.0);
                                        }
                                    }
                                }
                            }
                        }
                        AudioBufferRef::S24(buf) => {
                            for &sample in buf.chan(0) {
                                let val = sample.inner() as f32;
                                audio_samples.push(val / 8388608.0);
                            }
                            if channels > 1 {
                                for ch in 1..channels as usize {
                                    if ch < buf.spec().channels.count() {
                                        for &sample in buf.chan(ch) {
                                            let val = sample.inner() as f32;
                                            audio_samples.push(val / 8388608.0);
                                        }
                                    }
                                }
                            }
                        }
                        AudioBufferRef::S32(buf) => {
                            for &sample in buf.chan(0) {
                                audio_samples.push(sample as f32 / 2147483648.0);
                            }
                            if channels > 1 {
                                for ch in 1..channels as usize {
                                    if ch < buf.spec().channels.count() {
                                        for &sample in buf.chan(ch) {
                                            audio_samples.push(sample as f32 / 2147483648.0);
                                        }
                                    }
                                }
                            }
                        }
                        AudioBufferRef::F64(buf) => {
                            for &sample in buf.chan(0) {
                                audio_samples.push(sample as f32);
                            }
                            if channels > 1 {
                                for ch in 1..channels as usize {
                                    if ch < buf.spec().channels.count() {
                                        for &sample in buf.chan(ch) {
                                            audio_samples.push(sample as f32);
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
                Err(symphonia::core::errors::Error::IoError(_)) => {
                    // å¿½ç•¥IOé”™è¯¯ï¼Œç»§ç»­å¤„ç†
                    continue;
                }
                Err(symphonia::core::errors::Error::DecodeError(_)) => {
                    // å¿½ç•¥è§£ç é”™è¯¯ï¼Œç»§ç»­å¤„ç†
                    continue;
                }
                Err(_e) => {
                    // MP3è§£ç é”™è¯¯
                    continue;
                }
            }
        }

        if audio_samples.is_empty() {
            return Err(anyhow!("MP3æ–‡ä»¶è§£ç åæ— éŸ³é¢‘æ•°æ®"));
        }

        Ok((audio_samples, sample_rate, channels))
    }

    /// é«˜è´¨é‡é‡é‡‡æ ·éŸ³é¢‘æ•°æ® - ä½¿ç”¨rubatoåº“å®ç°ä¸“ä¸šçº§é‡é‡‡æ ·
    pub fn resample_audio_high_quality(
        &self,
        audio: Array1<f32>,
        original_sr: u32,
        target_sr: u32,
    ) -> Result<Array1<f32>> {
        if original_sr == target_sr {
            return Ok(audio);
        }

        // ä½¿ç”¨rubatoåº“è¿›è¡Œé«˜è´¨é‡é‡é‡‡æ ·
        // é…ç½®å‚æ•°ä»¥è·å¾—æœ€ä½³éŸ³è´¨ï¼Œä¸Pythonçš„soxråº“ç›¸å½“
        let params = SincInterpolationParameters {
            sinc_len: 256,  // æ›´é•¿çš„sincé•¿åº¦æä¾›æ›´å¥½çš„é¢‘ç‡å“åº”
            f_cutoff: 0.95, // ç¨å¾®ä¿å®ˆçš„æˆªæ­¢é¢‘ç‡é¿å…æ··å 
            interpolation: SincInterpolationType::Linear,
            oversampling_factor: 256, // é«˜è¿‡é‡‡æ ·å› å­æä¾›æ›´å¥½çš„ç²¾åº¦
            window: WindowFunction::BlackmanHarris2, // ä¼˜ç§€çš„é¢‘åŸŸç‰¹æ€§
        };

        // åˆ›å»ºé‡é‡‡æ ·å™¨
        let mut resampler = SincFixedIn::<f32>::new(
            target_sr as f64 / original_sr as f64,
            2.0, // æœ€å¤§æ¯”ç‡å˜åŒ–
            params,
            audio.len(),
            1, // å•å£°é“
        )
        .map_err(|e| anyhow!("åˆ›å»ºé‡é‡‡æ ·å™¨å¤±è´¥: {}", e))?;

        // å‡†å¤‡è¾“å…¥æ•°æ®ï¼ˆrubatoéœ€è¦Vec<Vec<f32>>æ ¼å¼ï¼‰
        let input_data = vec![audio.to_vec()];

        // æ‰§è¡Œé‡é‡‡æ ·
        let output_data = resampler
            .process(&input_data, None)
            .map_err(|e| anyhow!("é‡é‡‡æ ·å¤„ç†å¤±è´¥: {}", e))?;

        // æå–é‡é‡‡æ ·åçš„æ•°æ®
        if output_data.is_empty() || output_data[0].is_empty() {
            return Err(anyhow!("é‡é‡‡æ ·è¾“å‡ºä¸ºç©º"));
        }

        Ok(Array1::from(output_data[0].clone()))
    }

    /// é‡é‡‡æ ·éŸ³é¢‘æ•°æ®ï¼ˆç°åœ¨ä½¿ç”¨é«˜è´¨é‡rubatoåº“å®ç°ï¼‰
    pub fn resample_audio(
        &self,
        audio: Array1<f32>,
        original_sr: u32,
        target_sr: u32,
    ) -> Result<Array1<f32>> {
        // ç›´æ¥è°ƒç”¨é«˜è´¨é‡é‡é‡‡æ ·æ–¹æ³•ï¼Œç¡®ä¿æ‰€æœ‰é‡é‡‡æ ·éƒ½ä½¿ç”¨ç›¸åŒçš„é«˜è´¨é‡ç®—æ³•
        self.resample_audio_high_quality(audio, original_sr, target_sr)
    }

    /// éŸ³é‡å½’ä¸€åŒ– - ä¸Pythonå®ç°ä¿æŒä¸€è‡´
    pub fn audio_volume_normalize(&self, audio: Array1<f32>, coeff: f32) -> Array1<f32> {
        let mut audio = audio;

        // è·å–éŸ³é¢‘ç»å¯¹å€¼å¹¶æ’åº
        let mut temp: Vec<f32> = audio.iter().map(|&x| x.abs()).collect();
        temp.sort_by(|a, b| a.partial_cmp(b).unwrap());

        // å¦‚æœæœ€å¤§å€¼å°äº0.1ï¼Œç¼©æ”¾åˆ°0.1
        if temp[temp.len() - 1] < 0.1 {
            let scaling_factor = temp[temp.len() - 1].max(1e-3); // é˜²æ­¢é™¤é›¶
            audio = audio.mapv(|x| x / scaling_factor * 0.1);
        }

        // è¿‡æ»¤æ‰å°äº0.01çš„å€¼
        temp.retain(|&x| x > 0.01);
        let l = temp.len();

        // å¦‚æœæœ‰æ•ˆå€¼å°‘äºç­‰äº10ä¸ªï¼Œç›´æ¥è¿”å›
        if l <= 10 {
            return audio;
        }

        // è®¡ç®—90%åˆ°99%èŒƒå›´å†…çš„å¹³å‡å€¼
        let start_idx = (0.9 * l as f32) as usize;
        let end_idx = (0.99 * l as f32) as usize;
        let volume: f32 =
            temp[start_idx..end_idx].iter().sum::<f32>() / (end_idx - start_idx) as f32;

        // å½’ä¸€åŒ–åˆ°ç›®æ ‡ç³»æ•°æ°´å¹³ï¼Œé™åˆ¶ç¼©æ”¾å› å­åœ¨0.1åˆ°10ä¹‹é—´
        let scale_factor = (coeff / volume).clamp(0.1, 10.0);
        audio = audio.mapv(|x| x * scale_factor);

        // ç¡®ä¿æœ€å¤§ç»å¯¹å€¼ä¸è¶…è¿‡1
        let max_value = audio.iter().fold(0.0f32, |acc, &x| acc.max(x.abs()));
        if max_value > 1.0 {
            audio = audio.mapv(|x| x / max_value);
        }

        // Volume normalization applied

        audio
    }

    /// ç®€å•éŸ³é‡å½’ä¸€åŒ–ï¼ˆä¿ç•™ä»¥å…¼å®¹ï¼‰
    pub fn audio_volume_normalize_simple(&self, audio: Array1<f32>, max_val: f32) -> Array1<f32> {
        let max_amp = audio.iter().fold(0.0_f32, |acc, &x| acc.max(x.abs()));
        if max_amp > 0.0 {
            audio.mapv(|x| x * (max_val / max_amp))
        } else {
            audio
        }
    }

    /// é›¶å‡å€¼å•ä½æ–¹å·®å½’ä¸€åŒ– - ä¸C++å®ç°å®Œå…¨ä¸€è‡´ï¼Œå¢å¼ºæ•°å€¼ç¨³å®šæ€§
    /// C++å®ç°ï¼š
    /// float mean = std::accumulate(input_values.begin(), input_values.end(), 0.0f) / input_values.size();
    /// float std = std::sqrt(std::accumulate(input_values.begin(), input_values.end(), 0.0f, [mean](float a, float b) {
    ///     return a + (b - mean) * (b - mean);
    /// }) / input_values.size() + 1e-7f);
    /// for (int i = 0; i < input_values.size(); i++) {
    ///     input_values[i] = (input_values[i] - mean) / std;
    /// }
    pub fn zero_mean_unit_variance_normalize(mut input_values: Vec<f32>) -> Vec<f32> {
        // æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥ï¼šå¤„ç†ç©ºå‘é‡æˆ–æçŸ­å‘é‡
        if input_values.is_empty() {
            return input_values;
        }

        if input_values.len() == 1 {
            // å•ä¸ªå€¼çš„æƒ…å†µï¼Œç›´æ¥è¿”å›é›¶
            input_values[0] = 0.0;
            return input_values;
        }

        // è®¡ç®—å‡å€¼ - ä¸C++å®Œå…¨ä¸€è‡´
        let mean = input_values.iter().sum::<f32>() / input_values.len() as f32;

        // æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å€¼éƒ½ç›¸åŒï¼ˆæ–¹å·®ä¸ºé›¶çš„æƒ…å†µï¼‰
        let all_same = input_values.iter().all(|&x| (x - mean).abs() < 1e-10);
        if all_same {
            // æ‰€æœ‰å€¼éƒ½ç›¸åŒï¼Œç›´æ¥è®¾ä¸ºé›¶
            input_values.fill(0.0);
            return input_values;
        }

        // è®¡ç®—æ ‡å‡†å·® - ä¸C++å®ç°å®Œå…¨ä¸€è‡´ï¼Œä½†å¢åŠ æ›´å¤§çš„epsilonä»¥æé«˜æ•°å€¼ç¨³å®šæ€§
        let variance_sum = input_values
            .iter()
            .fold(0.0f32, |acc, &b| acc + (b - mean) * (b - mean));
        let variance = variance_sum / input_values.len() as f32;

        // ä½¿ç”¨å›ºå®šçš„epsilonå€¼ï¼Œä¸Pythonç‰ˆæœ¬ä¿æŒä¸€è‡´
        let epsilon = 1e-7f32;
        let std = (variance + epsilon).sqrt();

        // å½’ä¸€åŒ– - ä¸C++å®Œå…¨ä¸€è‡´
        for value in input_values.iter_mut() {
            *value = (*value - mean) / std;
        }

        // Zero-mean unit-variance normalize applied with numerical stability

        input_values
    }

    /// æ¢…å°”é¢‘è°±å›¾æå– - ä¸Python librosaå®ç°ä¿æŒä¸€è‡´
    pub fn extract_mel_spectrogram(
        &self,
        wav: &Array1<f32>,
        n_mels: usize,
        n_fft: usize,
        hop_length: usize,
        win_length: usize,
    ) -> Array2<f32> {
        // C++ä»£ç ä¸­center=trueï¼Œéœ€è¦è¿›è¡Œä¸­å¿ƒå¡«å……
        // å¡«å……é•¿åº¦ä¸ºn_fft//2ï¼Œä¸¤ç«¯å„å¡«å……n_fft//2ä¸ªé›¶
        let pad_width = n_fft / 2;
        let mut padded_wav = vec![0.0f32; wav.len() + 2 * pad_width];

        // å¤åˆ¶åŸå§‹éŸ³é¢‘åˆ°ä¸­é—´ä½ç½®
        for (i, &sample) in wav.iter().enumerate() {
            padded_wav[pad_width + i] = sample;
        }

        let wav_len = padded_wav.len();
        // After center padding

        // ä½¿ç”¨ä¸librosaç›¸åŒçš„å¸§æ•°è®¡ç®—æ–¹å¼ï¼ˆåŸºäºå¡«å……åçš„é•¿åº¦ï¼‰
        let n_frames = if wav_len <= n_fft {
            1
        } else {
            (wav_len - n_fft) / hop_length + 1
        };

        // Mel spectrogram extraction parameters

        // åˆ›å»ºæ±‰å®çª— - ä¸librosaé»˜è®¤çª—å£ä¸€è‡´
        let window: Vec<f32> = if win_length == n_fft {
            (0..n_fft)
                .map(|i| {
                    let angle = 2.0 * std::f32::consts::PI * i as f32 / (n_fft - 1) as f32;
                    0.5 * (1.0 - angle.cos())
                })
                .collect()
        } else {
            // å¦‚æœwin_length != n_fftï¼Œéœ€è¦è¿›è¡Œçª—å£å¡«å……
            let mut window = vec![0.0f32; n_fft];
            let start_pad = (n_fft - win_length) / 2;
            for i in 0..win_length {
                let angle = 2.0 * std::f32::consts::PI * i as f32 / (win_length - 1) as f32;
                window[start_pad + i] = 0.5 * (1.0 - angle.cos());
            }
            window
        };

        // åˆ›å»ºæ¢…å°”æ»¤æ³¢å™¨ç»„ - ä½¿ç”¨slaneyå½’ä¸€åŒ–ï¼Œfmin=10ï¼Œfmax=sample_rate/2.0ï¼ˆä¸Pythonç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼‰
        let mel_filters = self.create_mel_filterbank_slaney_with_fmax(
            n_mels,
            n_fft,
            self.sample_rate as f32,
            10.0,
            self.sample_rate as f32 / 2.0,
        );

        let mut mel_spectrogram = Array2::zeros((n_mels, n_frames));

        for frame_idx in 0..n_frames {
            let start = frame_idx * hop_length;
            let end = (start + n_fft).min(wav_len);

            // æå–å¸§å¹¶åº”ç”¨çª—å‡½æ•°ï¼ˆä½¿ç”¨å¡«å……åçš„éŸ³é¢‘ï¼‰
            let mut frame = vec![0.0f32; n_fft];
            for i in 0..(end - start) {
                frame[i] = padded_wav[start + i] * window[i];
            }
            // é›¶å¡«å……å‰©ä½™éƒ¨åˆ†
            for item in frame.iter_mut().take(n_fft).skip(end - start) {
                *item = 0.0;
            }

            // è®¡ç®—åŠŸç‡è°± - ä½¿ç”¨æ›´ç²¾ç¡®çš„FFTå®ç°
            let power_spectrum = self.compute_power_spectrum_accurate(&frame);

            // åº”ç”¨æ¢…å°”æ»¤æ³¢å™¨
            for mel_idx in 0..n_mels {
                let mut mel_energy = 0.0f32;
                for freq_idx in 0..power_spectrum.len() {
                    mel_energy += power_spectrum[freq_idx] * mel_filters[[mel_idx, freq_idx]];
                }
                // ä¸è¿›è¡Œå¯¹æ•°å˜æ¢ï¼Œä½¿ç”¨çº¿æ€§å°ºåº¦ï¼ˆä¸C++çš„melSpectrogramå‡½æ•°ä¸€è‡´ï¼‰
                mel_spectrogram[[mel_idx, frame_idx]] = mel_energy;
            }
        }

        // Mel spectrogram shape processed
        mel_spectrogram
    }

    /// åˆ›å»ºæ¢…å°”æ»¤æ³¢å™¨ç»„ - ä½¿ç”¨slaneyå½’ä¸€åŒ–ï¼Œæ”¯æŒæŒ‡å®šfmax
    fn create_mel_filterbank_slaney_with_fmax(
        &self,
        n_mels: usize,
        n_fft: usize,
        sample_rate: f32,
        fmin: f32,
        fmax: f32,
    ) -> Array2<f32> {
        let n_freqs = n_fft / 2 + 1;
        let mut filterbank = Array2::zeros((n_mels, n_freqs));

        // æ¢…å°”åˆ»åº¦è½¬æ¢å‡½æ•°
        let hz_to_mel = |hz: f32| 2595.0 * (1.0 + hz / 700.0).log10();
        let mel_to_hz = |mel: f32| 700.0 * (10.0_f32.powf(mel / 2595.0) - 1.0);

        let mel_min = hz_to_mel(fmin);
        let mel_max = hz_to_mel(fmax);

        // åˆ›å»ºæ¢…å°”åˆ»åº¦ä¸Šçš„ç­‰é—´è·ç‚¹
        let mel_points: Vec<f32> = (0..=n_mels + 1)
            .map(|i| mel_min + i as f32 * (mel_max - mel_min) / (n_mels + 1) as f32)
            .collect();

        // è½¬æ¢å›Hzå¹¶æ˜ å°„åˆ°FFT bin
        let hz_points: Vec<f32> = mel_points.iter().map(|&mel| mel_to_hz(mel)).collect();
        let bin_points: Vec<f32> = hz_points
            .iter()
            .map(|&hz| hz * n_fft as f32 / sample_rate)
            .collect();

        // æ„å»ºä¸‰è§’æ»¤æ³¢å™¨
        for m in 1..=n_mels {
            let left = bin_points[m - 1];
            let center = bin_points[m];
            let right = bin_points[m + 1];

            for k in 0..n_freqs {
                let k_f = k as f32;
                if k_f >= left && k_f <= right {
                    if k_f <= center {
                        if center > left {
                            filterbank[[m - 1, k]] = (k_f - left) / (center - left);
                        }
                    } else if right > center {
                        filterbank[[m - 1, k]] = (right - k_f) / (right - center);
                    }
                }
            }

            // Slaneyå½’ä¸€åŒ–ï¼šæ¯ä¸ªæ»¤æ³¢å™¨çš„é¢ç§¯å½’ä¸€åŒ–ä¸º2/(fhi-flo)
            let fhi = hz_points[m + 1];
            let flo = hz_points[m - 1];
            let norm_factor = 2.0 / (fhi - flo);
            for k in 0..n_freqs {
                filterbank[[m - 1, k]] *= norm_factor;
            }
        }

        filterbank
    }

    /// åˆ›å»ºæ¢…å°”æ»¤æ³¢å™¨ç»„ - ä½¿ç”¨slaneyå½’ä¸€åŒ–ï¼ˆä¿ç•™åŸæ–¹æ³•ä»¥å…¼å®¹ï¼‰
    #[allow(dead_code)]
    fn create_mel_filterbank_slaney(
        &self,
        n_mels: usize,
        n_fft: usize,
        sample_rate: f32,
        fmin: f32,
    ) -> Array2<f32> {
        let fmax = sample_rate / 2.0;
        self.create_mel_filterbank_slaney_with_fmax(n_mels, n_fft, sample_rate, fmin, fmax)
    }

    /// åˆ›å»ºæ¢…å°”æ»¤æ³¢å™¨ç»„ï¼ˆä¿ç•™åŸæ–¹æ³•ä»¥å…¼å®¹ï¼‰
    #[allow(dead_code)]
    fn create_mel_filterbank(&self, n_mels: usize, n_fft: usize, sample_rate: f32) -> Array2<f32> {
        self.create_mel_filterbank_slaney(n_mels, n_fft, sample_rate, 0.0)
    }

    /// è®¡ç®—åŠŸç‡è°± - æ›´ç²¾ç¡®çš„å®ç°ï¼ŒçœŸæ­£è®¡ç®—åŠŸç‡è°±è€Œéå¹…åº¦è°±
    fn compute_power_spectrum_accurate(&self, frame: &[f32]) -> Vec<f32> {
        let n_fft = frame.len();
        let n_freqs = n_fft / 2 + 1;
        let mut power_spectrum = vec![0.0f32; n_freqs];

        // ä½¿ç”¨æ›´ç²¾ç¡®çš„DFTè®¡ç®—ï¼ŒåŒ…å«é€‚å½“çš„å½’ä¸€åŒ–
        for (k, power) in power_spectrum.iter_mut().enumerate().take(n_freqs) {
            let mut real = 0.0f32;
            let mut imag = 0.0f32;

            for (n, &sample) in frame.iter().enumerate().take(n_fft) {
                let angle = -2.0 * std::f32::consts::PI * k as f32 * n as f32 / n_fft as f32;
                real += sample * angle.cos();
                imag += sample * angle.sin();
            }

            // è®¡ç®—çœŸæ­£çš„åŠŸç‡è°±ï¼šå¹…åº¦çš„å¹³æ–¹
            *power = real * real + imag * imag;

            // å¯¹äºéé›¶é¢‘ç‡å’Œå¥ˆå¥æ–¯ç‰¹é¢‘ç‡ï¼Œéœ€è¦é€‚å½“çš„å½’ä¸€åŒ–
            if k > 0 && k < n_freqs - 1 {
                // å¯¹äºä¸­é—´é¢‘ç‡ï¼Œç”±äºæˆ‘ä»¬åªè®¡ç®—æ­£é¢‘ç‡éƒ¨åˆ†ï¼Œéœ€è¦ä¹˜ä»¥2æ¥è¡¥å¿è´Ÿé¢‘ç‡éƒ¨åˆ†
                *power *= 2.0;
            }

            // å½’ä¸€åŒ–ï¼šé™¤ä»¥N^2ä»¥åŒ¹é…æ ‡å‡†åŠŸç‡è°±å®šä¹‰
            *power /= (n_fft * n_fft) as f32;
        }

        power_spectrum
    }

    /// è®¡ç®—åŠŸç‡è°±ï¼ˆç®€åŒ–å®ç°ï¼Œä¿ç•™ä»¥å…¼å®¹ï¼‰
    #[allow(dead_code)]
    fn compute_power_spectrum(&self, frame: &[f32]) -> Vec<f32> {
        let n_fft = frame.len();
        let n_freqs = n_fft / 2 + 1;
        let mut power_spectrum = vec![0.0f32; n_freqs];

        // ç®€åŒ–çš„DFTè®¡ç®—ï¼ˆä»…è®¡ç®—æ‰€éœ€é¢‘ç‡ï¼‰
        for (k, power) in power_spectrum.iter_mut().enumerate().take(n_freqs) {
            let mut real = 0.0f32;
            let mut imag = 0.0f32;

            for (n, &sample) in frame.iter().enumerate().take(n_fft) {
                let angle = -2.0 * std::f32::consts::PI * k as f32 * n as f32 / n_fft as f32;
                real += sample * angle.cos();
                imag += sample * angle.sin();
            }

            *power = real * real + imag * imag;
        }

        power_spectrum
    }

    /// ä½¿ç”¨ONNX wav2vec2æ¨¡å‹æå–ç‰¹å¾ï¼ˆéœ€è¦å¯å˜å€Ÿç”¨ä»¥å…¼å®¹ort::Session::runçš„APIçº¦æŸï¼‰
    pub fn extract_wav2vec2_features(&mut self, audio_data: &[f32]) -> Result<Array2<f32>> {
        let wav2vec2_session = self
            .wav2vec2_session
            .as_mut()
            .ok_or_else(|| anyhow::anyhow!("wav2vec2 session not initialized"))?;

        // åº”ç”¨é›¶å‡å€¼å•ä½æ–¹å·®å½’ä¸€åŒ–é¢„å¤„ç† - ä¸C++å®ç°ä¿æŒä¸€è‡´
        let normalized_audio = Self::zero_mean_unit_variance_normalize(audio_data.to_vec());

        let input_data = Array1::from(normalized_audio).insert_axis(ndarray::Axis(0));
        let input_dyn = input_data.into_dyn();
        let input_shape: Vec<i64> = input_dyn.shape().iter().map(|&d| d as i64).collect();
        let input_vec = input_dyn.into_raw_vec();

        // wav2vec2 input shapeè°ƒè¯•ä¿¡æ¯

        let input_tensor = Value::from_array((input_shape, input_vec))?;

        let outputs = wav2vec2_session.run(ort::inputs![SessionInputValue::from(input_tensor)])?;
        let (output_shape, data) = outputs[0].try_extract_tensor::<f32>()?;

        // wav2vec2 output shapeè°ƒè¯•ä¿¡æ¯

        // ä¸Pythonç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼šè¾“å‡ºå½¢çŠ¶åº”è¯¥æ˜¯ [1, time_steps, 1024]
        // Python: features = outputs[0][0]  # ç§»é™¤batchç»´åº¦ï¼Œå¾—åˆ° [time_steps, 1024]
        if output_shape.len() == 3 && output_shape[0] == 1 {
            let time_steps = output_shape[1] as usize;
            let feature_dim = output_shape[2] as usize;

            if feature_dim != 1024 {
                return Err(anyhow::anyhow!(
                    "Expected feature dimension 1024, got {}",
                    feature_dim
                ));
            }

            // ç§»é™¤batchç»´åº¦ï¼Œä¸Pythonç‰ˆæœ¬ä¸€è‡´
            let features = Array2::from_shape_vec((time_steps, feature_dim), data.to_vec())?;
            // wav2vec2 features after removing batch dim
            Ok(features)
        } else {
            Err(anyhow::anyhow!(
                "Unexpected wav2vec2 output shape: {:?}",
                output_shape
            ))
        }
    }

    pub fn get_ref_clip(&self, wav: &Array1<f32>) -> Array1<f32> {
        // ä½¿ç”¨ä¸C++å’ŒPythonç‰ˆæœ¬å®Œå…¨ä¸€è‡´çš„è®¡ç®—æ–¹å¼

        let ref_segment_length = ((self.ref_segment_duration * self.sample_rate as f32) as u32
            / self.latent_hop_length
            * self.latent_hop_length) as usize;

        // get_ref_clip parameters calculated

        let wav_length = wav.len();

        // éªŒè¯éŸ³é¢‘é•¿åº¦çš„åˆç†æ€§
        if wav_length == 0 {
            // å¦‚æœéŸ³é¢‘ä¸ºç©ºï¼Œè¿”å›é›¶å¡«å……çš„å‚è€ƒç‰‡æ®µ
            return Array1::zeros(ref_segment_length);
        }

        if ref_segment_length == 0 {
            // å¦‚æœå‚è€ƒé•¿åº¦ä¸º0ï¼Œè¿”å›ç©ºæ•°ç»„
            return Array1::zeros(0);
        }

        if ref_segment_length > wav_length {
            // å¦‚æœéŸ³é¢‘ä¸è¶³æŒ‡å®šé•¿åº¦ï¼Œé‡å¤éŸ³é¢‘ç›´åˆ°è¾¾åˆ°è¦æ±‚
            let repeat_times = ref_segment_length / wav_length + 1;
            let mut repeated = Vec::with_capacity(wav_length * repeat_times);
            for _ in 0..repeat_times {
                repeated.extend(wav.iter());
            }
            Array1::from(repeated)
                .slice(ndarray::s![..ref_segment_length])
                .to_owned()
        } else {
            // æˆªå–æŒ‡å®šé•¿åº¦
            wav.slice(ndarray::s![..ref_segment_length]).to_owned()
        }
    }

    /// ç¡®ä¿éŸ³é¢‘é•¿åº¦çš„ä¸€è‡´æ€§å¤„ç†
    /// ç¡®ä¿éŸ³é¢‘é•¿åº¦çš„ä¸€è‡´æ€§å¤„ç†
    #[allow(dead_code)]
    fn ensure_consistent_length(&self, audio: Array1<f32>) -> Array1<f32> {
        let len = audio.len();
        // ç¡®ä¿é•¿åº¦æ˜¯hop_lengthçš„å€æ•°ï¼Œä»¥ä¿è¯ç‰¹å¾æå–çš„ä¸€è‡´æ€§
        let hop_length = self.latent_hop_length as usize;
        let aligned_len = (len / hop_length) * hop_length;

        if aligned_len == 0 {
            // å¦‚æœéŸ³é¢‘å¤ªçŸ­ï¼Œå¡«å……åˆ°æœ€å°é•¿åº¦
            let min_len = hop_length;
            let mut padded = vec![0.0f32; min_len];
            let copy_len = len.min(min_len);
            padded[..copy_len].copy_from_slice(&audio.as_slice().unwrap()[..copy_len]);
            Array1::from(padded)
        } else if aligned_len < len {
            // æˆªæ–­åˆ°å¯¹é½é•¿åº¦
            audio.slice(ndarray::s![..aligned_len]).to_owned()
        } else {
            audio
        }
    }

    pub fn process_audio(
        &mut self,
        audio_path: &str,
        volume_normalize: bool,
    ) -> Result<(Array1<f32>, Array1<f32>)> {
        let wav = self.load_audio(audio_path, self.sample_rate, volume_normalize)?;
        let ref_wav = self.get_ref_clip(&wav);
        Ok((wav, ref_wav))
    }

    pub fn tokenize(&mut self, audio_path: &str) -> Result<(Vec<i32>, Vec<i32>)> {
        self.tokenize_with_options(audio_path, true)
    }

    /// å¸¦é€‰é¡¹çš„tokenizeæ–¹æ³•ï¼Œå…è®¸é…ç½®éŸ³é‡å½’ä¸€åŒ–
    pub fn tokenize_with_options(
        &mut self,
        audio_path: &str,
        volume_normalize: bool,
    ) -> Result<(Vec<i32>, Vec<i32>)> {
        // Tokenizing audio

        // éŸ³é¢‘é¢„å¤„ç†ï¼šå¯é…ç½®éŸ³é‡å½’ä¸€åŒ–é€‰é¡¹
        let (wav, ref_wav) = self.process_audio(audio_path, volume_normalize)?;

        let feat = self.extract_wav2vec2_features(wav.as_slice().unwrap())?;

        // ä½¿ç”¨ä¸C++å®ç°å®Œå…¨ä¸€è‡´çš„æ¢…å°”é¢‘è°±æå–ï¼Œé¿å…å‚æ•°å·®å¼‚å¯¼è‡´ä¸ç¨³å®š
        let ref_mel =
            crate::tts_pipeline_fixes::TtsPipelineFixes::extract_mel_spectrogram_consistent(
                &ref_wav,
            )?;

        // ç¡®ä¿æ•°æ®æ˜¯è¡Œä¼˜å…ˆå¸ƒå±€ï¼ˆC-orderï¼‰
        let ref_mel_c_order = if ref_mel.is_standard_layout() {
            ref_mel.clone()
        } else {
            // å¦‚æœä¸æ˜¯æ ‡å‡†å¸ƒå±€ï¼Œè½¬æ¢ä¸ºC-order
            // Converting mel_spectrogram to C-order layout
            ref_mel.as_standard_layout().to_owned()
        };

        let ref_mel_input = ref_mel_c_order.insert_axis(ndarray::Axis(0));
        let ref_mel_dyn = ref_mel_input.into_dyn();
        let ref_mel_shape: Vec<i64> = ref_mel_dyn.shape().iter().map(|&d| d as i64).collect();
        let ref_mel_vec = ref_mel_dyn.into_raw_vec();

        let ref_mel_tensor = Value::from_array((ref_mel_shape.clone(), ref_mel_vec))?;

        // å‡†å¤‡featå¼ é‡ï¼šå½¢çŠ¶åº”è¯¥æ˜¯[1, t, 1024]ï¼Œä¸C++å®Œå…¨ä¸€è‡´

        let feat_c_order = if feat.is_standard_layout() {
            feat.clone()
        } else {
            // Converting feat to C-order layout
            feat.as_standard_layout().to_owned()
        };

        let feat_input = feat_c_order.insert_axis(ndarray::Axis(0));
        let feat_dyn = feat_input.into_dyn();
        let feat_shape: Vec<i64> = feat_dyn.shape().iter().map(|&d| d as i64).collect();
        let feat_vec = feat_dyn.into_raw_vec();

        let feat_tensor = Value::from_array((feat_shape.clone(), feat_vec))?;

        // Input tensors prepared

        let ort_session = self
            .ort_session
            .as_mut()
            .ok_or_else(|| anyhow::anyhow!("ort session not initialized"))?;

        let outputs = ort_session.run(ort::inputs![
            "ref_wav_mel" => SessionInputValue::from(ref_mel_tensor),
            "feat" => SessionInputValue::from(feat_tensor)
        ])?;

        let mut semantic_tokens: Vec<i32> = vec![];
        let mut global_tokens: Vec<i32> = vec![];

        // 1) é¦–å…ˆä¸¥æ ¼æŒ‰åç§°è§£æï¼Œé¿å…ä½ç½®é¡ºåºä¸ä¸€è‡´å¯¼è‡´é”™ä½
        for (name, output) in outputs.iter() {
            if name == "semantic_tokens" {
                semantic_tokens = match output.try_extract_tensor::<i64>() {
                    Ok((_s_sem, semantic_tokens_slice)) => {
                        semantic_tokens_slice.iter().map(|&x| x as i32).collect()
                    }
                    Err(_) => {
                        let (_s_sem, semantic_tokens_slice) = output.try_extract_tensor::<i32>()?;
                        semantic_tokens_slice.to_vec()
                    }
                };
            } else if name == "global_tokens" {
                global_tokens = match output.try_extract_tensor::<i64>() {
                    Ok((_s_glb, global_tokens_slice)) => {
                        global_tokens_slice.iter().map(|&x| x as i32).collect()
                    }
                    Err(_) => {
                        let (_s_glb, global_tokens_slice) = output.try_extract_tensor::<i32>()?;
                        global_tokens_slice.to_vec()
                    }
                };
            }
        }

        // 2) å¦‚æœåç§°æœªåŒ¹é…åˆ°ï¼ŒæŒ‰å½¢çŠ¶è¾…åŠ©åˆ¤å®šï¼ˆsemanticä¸º[1, L]ï¼›globalä¸º[1, 1, 32]ï¼‰
        if semantic_tokens.is_empty() || global_tokens.is_empty() {
            for (_name, output) in outputs.iter() {
                let shape = output.shape();
                if semantic_tokens.is_empty() && shape.len() == 2 && shape[0] == 1 {
                    semantic_tokens = match output.try_extract_tensor::<i64>() {
                        Ok((_s_sem, semantic_tokens_slice)) => {
                            semantic_tokens_slice.iter().map(|&x| x as i32).collect()
                        }
                        Err(_) => {
                            let (_s_sem, semantic_tokens_slice) =
                                output.try_extract_tensor::<i32>()?;
                            semantic_tokens_slice.to_vec()
                        }
                    };
                    continue;
                }
                if global_tokens.is_empty() && shape.len() == 3 && shape[0] == 1 && shape[1] == 1 {
                    global_tokens = match output.try_extract_tensor::<i64>() {
                        Ok((_s_glb, global_tokens_slice)) => {
                            global_tokens_slice.iter().map(|&x| x as i32).collect()
                        }
                        Err(_) => {
                            let (_s_glb, global_tokens_slice) =
                                output.try_extract_tensor::<i32>()?;
                            global_tokens_slice.to_vec()
                        }
                    };
                }
            }
        }

        // 3) å…œåº•ï¼šè‹¥ä»æ— æ³•æŒ‰åç§°/å½¢çŠ¶åŒºåˆ†ï¼Œåˆ™æŒ‰ç´¢å¼•[0]=semanticï¼Œ[1]=global
        if (semantic_tokens.is_empty() || global_tokens.is_empty()) && outputs.len() >= 2 {
            if semantic_tokens.is_empty() {
                semantic_tokens = match outputs[0].try_extract_tensor::<i64>() {
                    Ok((_s_sem, semantic_tokens_slice)) => {
                        semantic_tokens_slice.iter().map(|&x| x as i32).collect()
                    }
                    Err(_) => {
                        let (_s_sem, semantic_tokens_slice) =
                            outputs[0].try_extract_tensor::<i32>()?;
                        semantic_tokens_slice.to_vec()
                    }
                };
            }
            if global_tokens.is_empty() {
                global_tokens = match outputs[1].try_extract_tensor::<i64>() {
                    Ok((_s_glb, global_tokens_slice)) => {
                        global_tokens_slice.iter().map(|&x| x as i32).collect()
                    }
                    Err(_) => {
                        let (_s_glb, global_tokens_slice) =
                            outputs[1].try_extract_tensor::<i32>()?;
                        global_tokens_slice.to_vec()
                    }
                };
            }
        }

        // 4) èŒƒå›´æ ¡éªŒä¸ä¿®æ­£æ—¥å¿—ï¼ˆä¿æŒä¸ç”Ÿæˆé˜¶æ®µä¸€è‡´çš„çº¦æŸï¼‰
        // global: [0..4096)
        if !global_tokens.is_empty() {
            let mut out_of_range: Vec<i32> = Vec::new();
            for &t in &global_tokens {
                if !(0..4096).contains(&t) {
                    out_of_range.push(t);
                }
            }
            if !out_of_range.is_empty() {
                log::warn!(
                    "ğŸš¨ å‚è€ƒglobal tokensè¶Šç•Œï¼š{:?}ï¼Œå°†è¿›è¡Œclampåˆ°[0..4095]",
                    out_of_range
                );
                for v in global_tokens.iter_mut() {
                    *v = (*v).clamp(0, 4095);
                }
            } else {
                log::info!("âœ… å‚è€ƒglobal tokensåœ¨è¯è¡¨èŒƒå›´å†…ï¼ˆvocab_size=4096ï¼‰");
            }
        }

        // semantic: [0..=8192]ï¼ˆåŒ…å«EOS=8192ï¼‰ï¼Œä»…è®°å½•è¶Šç•Œå¹¶clampï¼Œä¸ç§»é™¤EOS
        if !semantic_tokens.is_empty() {
            let mut out_of_range: Vec<i32> = Vec::new();
            for &t in &semantic_tokens {
                if !(0..=crate::rwkv_sampler::TTS_EOS_TOKEN).contains(&t) {
                    out_of_range.push(t);
                }
            }
            if !out_of_range.is_empty() {
                log::warn!(
                    "ğŸš¨ å‚è€ƒsemantic tokensè¶Šç•Œï¼š{:?}ï¼Œå°†clampåˆ°[0..={}](å«EOS)",
                    out_of_range,
                    crate::rwkv_sampler::TTS_EOS_TOKEN
                );
                for v in semantic_tokens.iter_mut() {
                    *v = (*v).clamp(0, crate::rwkv_sampler::TTS_EOS_TOKEN);
                }
            } else {
                log::info!(
                    "âœ… å‚è€ƒsemantic tokensåœ¨èŒƒå›´å†…ï¼ˆå«EOS={}ï¼‰",
                    crate::rwkv_sampler::TTS_EOS_TOKEN
                );
            }
        }

        // Global tokens unique values counted
        // Global tokens raw data checked

        // Tokenization completed
        // Semantic tokens sample checked
        // Token range check performed
        // Check for invalid tokens in reference audio processing
        Ok((global_tokens, semantic_tokens))
    }

    pub fn detokenize_audio(
        &mut self,
        global_tokens: &[i32],
        semantic_tokens: &[i32],
    ) -> Result<Vec<f32>> {
        let detokenizer_session = self.bicodec_detokenizer_session.as_mut().ok_or_else(|| {
            anyhow::anyhow!("BiCodecDetokenize ä¼šè¯æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„å’ŒåŠ è½½é€»è¾‘")
        })?;

        // ä¼˜åŒ–ï¼šç›´æ¥è½¬æ¢ä¸ºi64ï¼Œé¿å…ä¸­é—´çš„i32å‘é‡æ‹·è´
        let global_len = global_tokens.len();
        let semantic_len = semantic_tokens.len();

        // é¢„åˆ†é…å®¹é‡ä»¥é¿å…é‡å¤åˆ†é…
        let mut global_vec_i64 = Vec::with_capacity(global_len);
        let mut semantic_vec_i64 = Vec::with_capacity(semantic_len);

        // ç›´æ¥è½¬æ¢ï¼Œé¿å…ä¸­é—´æ‹·è´
        global_vec_i64.extend(global_tokens.iter().map(|&x| x as i64));
        semantic_vec_i64.extend(semantic_tokens.iter().map(|&x| x as i64));

        // ç›´æ¥æ„å»ºtensorï¼Œé¿å…ndarrayçš„ä¸­é—´æ­¥éª¤
        let global_shape = vec![1i64, 1i64, global_len as i64];
        let semantic_shape = vec![1i64, semantic_len as i64];

        let global_tensor = Value::from_array((global_shape, global_vec_i64))?;
        let semantic_tensor = Value::from_array((semantic_shape, semantic_vec_i64))?;

        // æŒ‰åç§°æä¾›è¾“å…¥ä»¥é¿å…é¡ºåºä¸ä¸€è‡´
        let outputs = detokenizer_session.run(ort::inputs![
            // æ³¨æ„ï¼šéƒ¨åˆ†ORTç»‘å®šå®ç°å¯èƒ½æŒ‰ä½ç½®åŒ¹é…ï¼Œè¿™é‡Œå°†é¡ºåºè°ƒæ•´ä¸ºå…ˆæä¾› semantic(2D)ï¼Œå†æä¾› global(3D)
            "semantic_tokens" => SessionInputValue::from(semantic_tensor),
            "global_tokens" => SessionInputValue::from(global_tensor)
        ])?;

        let (_shape, audio_slice) = outputs[0].try_extract_tensor::<f32>()?;
        let audio_vec: Vec<f32> = audio_slice.to_vec();
        Ok(audio_vec)
    }

    /// æ£€æµ‹éŸ³é¢‘å¼€å¤´å’Œç»“å°¾çš„é™éŸ³é•¿åº¦
    /// è¿”å› (å¼€å¤´é™éŸ³æ ·æœ¬æ•°, ç»“å°¾é™éŸ³æ ·æœ¬æ•°)
    fn detect_silence(&self, audio: &Array1<f32>, threshold: f32) -> (usize, usize) {
        let samples = audio.as_slice().unwrap();
        let len = samples.len();

        if len == 0 {
            return (0, 0);
        }

        // æ£€æµ‹å¼€å¤´é™éŸ³
        let mut start_silence = 0;
        for &sample in samples.iter() {
            if sample.abs() > threshold {
                break;
            }
            start_silence += 1;
        }

        // æ£€æµ‹ç»“å°¾é™éŸ³
        let mut end_silence = 0;
        for &sample in samples.iter().rev() {
            if sample.abs() > threshold {
                break;
            }
            end_silence += 1;
        }

        // ç¡®ä¿ä¸ä¼šè¶…è¿‡éŸ³é¢‘æ€»é•¿åº¦
        if start_silence + end_silence >= len {
            // å¦‚æœæ•´ä¸ªéŸ³é¢‘éƒ½æ˜¯é™éŸ³ï¼Œå¹³å‡åˆ†é…
            let half = len / 2;
            return (half, len - half);
        }

        (start_silence, end_silence)
    }

    /// æ™ºèƒ½å¤„ç†éŸ³é¢‘å¼€å¤´å’Œç»“å°¾çš„é™éŸ³ï¼Œç¡®ä¿å„ä¿æŒ0.5ç§’
    /// target_silence_duration: ç›®æ ‡é™éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰
    /// sample_rate: é‡‡æ ·ç‡
    /// ä»…è£å‰ªå¼€å¤´ä¸ç»“å°¾é™éŸ³ï¼Œä¸è¿›è¡Œè¡¥é›¶ï¼Œä¿æŒåŸå§‹æœ‰æ•ˆéŸ³é¢‘æ—¶é•¿
    fn trim_silence_only(&self, audio: Array1<f32>, silence_threshold: f32) -> Array1<f32> {
        let (start_silence, end_silence) = self.detect_silence(&audio, silence_threshold);
        let samples = audio.as_slice().unwrap();
        let total_len = samples.len();

        // è®¡ç®—æœ‰æ•ˆéŸ³é¢‘ç‰‡æ®µèŒƒå›´
        let audio_start = start_silence.min(total_len);
        let audio_end = total_len.saturating_sub(end_silence);

        if audio_start >= audio_end {
            // æ•´æ®µé™éŸ³ï¼Œç›´æ¥è¿”å›åŸé•¿åº¦çš„é›¶ï¼ˆä¿æŒè¡Œä¸ºç®€æ´ã€å¯é¢„æœŸï¼‰
            return Array1::zeros(total_len);
        }

        Array1::from(samples[audio_start..audio_end].to_vec())
    }
}
