//! RWKVæ¨¡å‹æ¨ç†é‡‡æ ·å™¨
//! å®ç°åŸºäºweb-rwkvåº“çš„RWKVæ¨¡å‹æ¨ç†å’Œé‡‡æ ·åŠŸèƒ½

use anyhow::Result;
use memmap2::Mmap;
use rand::Rng;
use rand::SeedableRng;
use rand::rngs::StdRng;
use safetensors::SafeTensors;
use sha2::{Digest, Sha256};
use std::path::Path;
use web_rwkv::{
    context::{ContextBuilder, InstanceExt},
    runtime::{
        infer::{Rnn, RnnInput, RnnInputBatch, RnnOption},
        loader::Loader,
        model::{ContextAutoLimits, ModelBuilder},
        v7, Runtime, TokioRuntime,
    },
    tokenizer::Tokenizer,
};
use wgpu::Instance;

/// é‡‡æ ·å‚æ•°
#[derive(Debug, Clone)]
pub struct SamplerArgs {
    pub temperature: f32,
    pub top_p: f32,
    pub top_k: usize,
    pub max_tokens: usize,
    // å¯é€‰éšæœºç§å­ï¼šæä¾›åˆ™å¯ç”¨ç¡®å®šæ€§é‡‡æ ·
    pub seed: Option<u64>,
}

impl Default for SamplerArgs {
    fn default() -> Self {
        Self {
            temperature: 1.0,
            top_p: 0.85,
            top_k: 0,
            max_tokens: 100,
            seed: None,
        }
    }
}

/// TTSç›¸å…³å¸¸é‡
pub const TTS_EOS_TOKEN: i32 = 8192;
pub const TTS_TAG_0: i32 = 8193;
pub const TTS_TAG_1: i32 = 8194;
pub const TTS_TAG_2: i32 = 8195;
pub const GLOBAL_TOKEN_OFFSET: i32 = 8196;

/// RWKVé‡‡æ ·å™¨ï¼Œç”¨äºç”Ÿæˆæ–‡æœ¬å’ŒTTS tokens
pub struct RwkvSampler {
    runtime: Box<dyn Runtime<Rnn>>, // ä½¿ç”¨TokioRuntimeå°è£…Bundle
    tokenizer: Tokenizer,
    // å¸¦ç§å­çš„RNGï¼ˆå¯é€‰ï¼Œå¯ç”¨åˆ™å®ç°ç¡®å®šæ€§é‡‡æ ·ï¼‰
    rng: Option<StdRng>,
}
impl RwkvSampler {
    /// åˆ›å»ºæ–°çš„RWKVé‡‡æ ·å™¨
    ///
    /// # Arguments
    /// * `model_path` - RWKVæ¨¡å‹ç›®å½•æˆ–æ¨¡å‹æ–‡ä»¶(.safetensors)è·¯å¾„
    /// * `vocab_path` - è¯è¡¨æ–‡ä»¶è·¯å¾„
    ///
    /// # Returns
    /// * `Result<RwkvSampler>` - RWKVé‡‡æ ·å™¨å®ä¾‹æˆ–é”™è¯¯
    pub async fn new(model_path: &str, vocab_path: &str) -> Result<Self> {
        // æ£€æŸ¥æ¨¡å‹ç›®å½•/æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        let model_path_ref = Path::new(model_path);
        if !model_path_ref.exists() {
            return Err(anyhow::anyhow!("æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {}", model_path));
        }

        // æ£€æŸ¥è¯è¡¨æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if !Path::new(vocab_path).exists() {
            return Err(anyhow::anyhow!("è¯è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {}", vocab_path));
        }

        // è§£ææ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼š
        // - è‹¥ä¼ å…¥ç›®å½•ï¼Œåˆ™é»˜è®¤åŠ è½½å…¶ä¸­çš„ "webrwkv.safetensors"
        // - è‹¥ä¼ å…¥æ–‡ä»¶ï¼Œåˆ™ç›´æ¥ä½¿ç”¨è¯¥æ–‡ä»¶
        let model_file_path = if model_path_ref.is_dir() {
            model_path_ref.join("webrwkv.safetensors")
        } else {
            model_path_ref.to_path_buf()
        };
        if !model_file_path.exists() {
            return Err(anyhow::anyhow!(
                "æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {}",
                model_file_path.display()
            ));
        }

        // åŠ è½½å¹¶ååºåˆ—åŒ–SafeTensorsæ¨¡å‹
        let file = std::fs::File::open(&model_file_path)?;
        let file_size = file.metadata()?.len();
        let data = unsafe { Mmap::map(&file)? };

        // æ¨¡å‹å®Œæ•´æ€§æ ¡éªŒï¼šæ‰“å°å¤§å°ä¸SHA256
        let mut hasher = Sha256::new();
        hasher.update(&data[..]);
        let hash_bytes = hasher.finalize();
        let sha256 = hash_bytes.iter().map(|b| format!("{:02x}", b)).collect::<String>();
        println!("ğŸ”’ æ¨¡å‹æ£€éªŒ: {}", model_file_path.display());
        println!("   - å¤§å°: {} bytes", file_size);
        println!("   - SHA256: {}", sha256);

        let model = SafeTensors::deserialize(&data)?;

        // åŸºäºæ¨¡å‹ä¿¡æ¯è‡ªåŠ¨é…ç½® Context çš„ç¡¬ä»¶ limits
        let info = Loader::info(&model)?;
        let instance = Instance::default();
        let adapter = instance
            .adapter(wgpu::PowerPreference::HighPerformance)
            .await?;

        // æ‰“å°é€‚é…å™¨/åç«¯/é©±åŠ¨ä¸ç²¾åº¦
        let adapter_info = adapter.get_info();
        println!("ğŸ–¥ï¸ é€‰ç”¨GPUé€‚é…å™¨: {}", adapter_info.name);
        println!(
            "   - åç«¯: {:?} | ä¾›åº”å•†: {:#06x} è®¾å¤‡: {:#06x} | ç±»å‹: {:?}",
            adapter_info.backend, adapter_info.vendor, adapter_info.device, adapter_info.device_type
        );
        println!(
            "   - é©±åŠ¨: {} | è¯¦æƒ…: {}",
            adapter_info.driver, adapter_info.driver_info
        );
        println!("   - ä½¿ç”¨ FP32 æ¨ç†: true (v7::Bundle::<f32>)");

        let context = ContextBuilder::new(adapter)
            .auto_limits(&info)
            .build()
            .await?;

        // åˆ›å»ºæ¨¡å‹æ„å»ºå™¨å¹¶æ„å»ºv7æ¨¡å‹
        let builder = ModelBuilder::new(&context, model);
        let model = builder.build_v7().await?;

        // åˆ›å»ºBundleä¸TokioRuntimeï¼ˆåˆ‡æ¢ä¸º f32 ä»¥å¯ç”¨ FP32 æ¨ç†ï¼‰
        let bundle = v7::Bundle::<f32>::new(model, 1);
        let runtime: Box<dyn Runtime<Rnn>> = Box::new(TokioRuntime::new(bundle).await);

        // åŠ è½½tokenizer
        let vocab_content = std::fs::read_to_string(vocab_path)?;
        let tokenizer = Tokenizer::new(&vocab_content)?;

        Ok(Self { runtime, tokenizer, rng: None })
    }

    /// è®¾ç½®éšæœºç§å­ï¼ˆå¯ç”¨ç¡®å®šæ€§é‡‡æ ·ï¼‰ã€‚ä¼ Noneåˆ™å…³é—­ç¡®å®šæ€§æ¨¡å¼ã€‚
    pub fn set_seed(&mut self, seed: Option<u64>) {
        self.rng = seed.map(|s| StdRng::seed_from_u64(s));
    }

    /// åªè¯»è®¿é—®å†…éƒ¨tokenizerï¼ˆç”¨äºå¤–éƒ¨æŒ‰ç›¸åŒæ–¹å¼ç¼–ç å±æ€§ï¼‰
    pub fn tokenizer(&self) -> &Tokenizer {
        &self.tokenizer
    }

    /// ç”Ÿæˆæ–‡æœ¬ï¼ˆç¤ºä¾‹ï¼‰
    pub async fn generate_text(&mut self, prompt: &str, args: &SamplerArgs) -> Result<String> {
        // è‹¥æä¾›äº†ç§å­ï¼Œè®¾ç½®ç¡®å®šæ€§é‡‡æ ·
        self.set_seed(args.seed);

        // ç¼–ç prompt
        let prompt_tokens: Vec<u32> = self
            .tokenizer
            .encode(prompt.as_bytes())
            .map_err(|e| anyhow::anyhow!(e.to_string()))?;
        let token_chunk_size = 64usize;
        let prompt_batch = RnnInputBatch::new(prompt_tokens.clone(), RnnOption::Last);
        let mut inference = RnnInput::new(vec![prompt_batch], token_chunk_size);

        // é¢„å¡«å……é˜¶æ®µï¼šå…ˆæŠŠå®Œæ•´ prompt åƒå®Œï¼Œç›´åˆ° runtime å¼€å§‹äº§ç”Ÿè¾“å‡º
        loop {
            let (next_inference, output) = self.runtime.infer(inference).await?;
            inference = next_inference;
            if output[0].0.size() > 0 {
                break;
            }
        }

        // é‡‡æ ·ç”Ÿæˆ
        let mut generated: Vec<u32> = Vec::with_capacity(args.max_tokens);
        for _ in 0..args.max_tokens {
            // æ¯æ­¥ä»…æ¶ˆè€—å½“å‰å‰©ä½™è¾“å…¥ï¼ˆå¯èƒ½ä¸ºç©ºï¼‰ï¼Œå¹¶åŸºäºè¾“å‡ºé‡‡æ ·ä¸€ä¸ªæ–° token
            let (next_inference, output) = self.runtime.infer(inference).await?;
            inference = next_inference;

            // è‹¥ä»åœ¨æ¶ˆè€—è¾“å…¥ï¼ˆsize==0ï¼‰ï¼Œç»§ç»­ç›´åˆ°äº§ç”Ÿè¾“å‡º
            if output[0].0.size() == 0 {
                continue;
            }

            let logits = output[0].0.clone().to_vec();
            let next_id = self.sample_logits(&logits, args, None) as u32;

            // å°†æ–° token è¿½åŠ åˆ°åç»­è¾“å…¥ä¸­ï¼Œå®ç°å¢é‡æ¨ç†
            inference.batches[0].push(next_id);
            generated.push(next_id);
        }

        // è§£ç ï¼ˆprompt + ç”Ÿæˆï¼‰
        let mut all = prompt_tokens;
        all.extend_from_slice(&generated);
        let decoded = self
            .tokenizer
            .decode(&all)
            .map_err(|e| anyhow::anyhow!(e.to_string()))?;
        let text = String::from_utf8_lossy(&decoded).to_string();
        Ok(text)
    }

    pub async fn generate_tts_tokens(
        &mut self,
        text: &str,
        property_tokens: &[i32],
        _ref_global_tokens: Option<&[i32]>,
        _ref_semantic_tokens: Option<&[i32]>,
        args: &SamplerArgs,
    ) -> Result<(Vec<i32>, Vec<i32>)> {
        // è‹¥æä¾›äº†ç§å­ï¼Œè®¾ç½®ç¡®å®šæ€§é‡‡æ ·
        self.set_seed(args.seed);

        // ç¼–ç æ–‡æœ¬ï¼šä½¿ç”¨åŸå§‹æ–‡æœ¬tokenï¼ˆä¸åŠ ä»»ä½•åç§»ï¼‰ä»¥åŒ¹é…å‚è€ƒå®ç°
        let text_tokens_u32: Vec<u32> = self
            .tokenizer
            .encode(text.as_bytes())
            .map_err(|e| anyhow::anyhow!(e.to_string()))?;
        let text_tokens: Vec<i32> = text_tokens_u32.into_iter().map(|t| t as i32).collect();

        // å‚è€ƒå®ç°åœ¨prefillé˜¶æ®µå–‚å…¥å±æ€§tokensï¼ˆåŸå§‹åŸŸï¼‰ã€æ–‡æœ¬tokensä¸é˜¶æ®µæ ‡ç­¾ã€‚
        let mut input_tokens: Vec<i32> = Vec::new();
        input_tokens.extend_from_slice(property_tokens);
        input_tokens.push(TTS_TAG_2);
        input_tokens.extend_from_slice(&text_tokens);
        input_tokens.push(TTS_TAG_0);

        // === Prefill é˜¶æ®µ ===
        let input_tokens_u32: Vec<u32> = input_tokens.iter().map(|&t| t as u32).collect();
        let token_chunk_size = 64usize;
        let prompt_batch = RnnInputBatch::new(input_tokens_u32.clone(), RnnOption::Last);
        let mut inference = RnnInput::new(vec![prompt_batch], token_chunk_size);
        // æ¶ˆåŒ–è¾“å…¥ç›´åˆ°äº§ç”Ÿè¾“å‡ºï¼Œå¹¶ä¿ç•™æœ€åä¸€æ¬¡logits
        let last_logits: Vec<f32> = loop {
            let (next_inference, output) = self.runtime.infer(inference).await?;
            inference = next_inference;
            if output[0].0.size() > 0 {
                break output[0].0.clone().to_vec();
            }
        };

        // === Global é˜¶æ®µ ===
        let mut global_tokens: Vec<i32> = Vec::new();
        let mut semantic_tokens: Vec<i32> = Vec::new();
        let mut args_global = args.clone();
        let mut args_sem = args.clone();
        // è‹¥æœªæŒ‡å®štop_kï¼ˆä¸º0ï¼‰ï¼ŒæŒ‰Pythonç»éªŒå€¼è®¾ç½®ï¼šglobal=20, semantic=80
        if args_global.top_k == 0 {
            args_global.top_k = 20;
        }
        if args_sem.top_k == 0 {
            args_sem.top_k = 80;
        }

        // Pythonå®ç°å›ºå®šç”Ÿæˆ32ä¸ªglobal tokensï¼Œå¹¶ä¸”ä»…åœ¨å‰4096ç»´å†…é‡‡æ ·
        let global_tokens_size: usize = 32;
        for i in 0..global_tokens_size {
            // å–å¾—å½“å‰å¯ç”¨çš„logitsï¼šé¦–æ­¥ä½¿ç”¨prefillå¾—åˆ°çš„logitsï¼Œå…¶åæ¯æ­¥ä»runtimeè·å–
            let logits: Vec<f32> = if i == 0 {
                last_logits.clone()
            } else {
                // ç¡®ä¿æ‹¿åˆ°éç©ºlogits
                loop {
                    let (next_inference, output) = self.runtime.infer(inference).await?;
                    inference = next_inference;
                    if output[0].0.size() > 0 {
                        break output[0].0.clone().to_vec();
                    }
                }
            };

            // ä»…åœ¨[0..4096)èŒƒå›´å†…é‡‡æ ·ï¼ˆGlobalç›¸å¯¹åŸŸï¼‰ï¼Œä¸æ¶‰åŠEOSä¸é˜¶æ®µæ ‡ç­¾
            let vocab_global = if logits.len() < 4096 {
                logits.len()
            } else {
                4096
            };
            let next_id = self.sample_logits(&logits[..vocab_global], &args_global, None);

            // è¿½åŠ åˆ°globalè¾“å‡ºï¼ˆç›¸å¯¹åŸŸ [0..4095]ï¼‰
            global_tokens.push(next_id as i32);
            // åé¦ˆåˆ°æ¨¡å‹ï¼š+8196ï¼ˆGLOBAL_TOKEN_OFFSETï¼‰
            let feed_id = (next_id as i32 + GLOBAL_TOKEN_OFFSET) as u32;
            inference.batches[0].push(feed_id);
        }

        // === åˆ‡æ¢åˆ° Semantic é˜¶æ®µ ===
        inference.batches[0].push(TTS_TAG_1 as u32);
        // è®©æ ‡ç­¾ç”Ÿæ•ˆï¼Œç›´åˆ°äº§ç”Ÿè¾“å‡ºï¼Œå¹¶ä¿ç•™logitsä¾›é¦–æ­¥ä½¿ç”¨
        let last_sem_logits: Vec<f32> = loop {
            let (next_inference, output) = self.runtime.infer(inference).await?;
            inference = next_inference;
            if output[0].0.size() > 0 {
                break output[0].0.clone().to_vec();
            }
        };

        // è¯­ä¹‰é˜¶æ®µï¼šé™åˆ¶æœ€å¤§ç”Ÿæˆæ­¥æ•°ä¸º2048
        let semantic_limit: usize = usize::min(args.max_tokens, 2048);
        for i in 0..semantic_limit {
            // å–å¾—å½“å‰è¯­ä¹‰é˜¶æ®µçš„logitsï¼šé¦–æ­¥ä½¿ç”¨æ³¨å…¥æ ‡ç­¾åçš„logitsï¼Œå…¶åæ¯æ­¥ä»runtimeè·å–
            let logits: Vec<f32> = if i == 0 {
                last_sem_logits.clone()
            } else {
                loop {
                    let (next_inference, output) = self.runtime.infer(inference).await?;
                    inference = next_inference;
                    if output[0].0.size() > 0 {
                        break output[0].0.clone().to_vec();
                    }
                }
            };

            // è¯­ä¹‰é˜¶æ®µä»…é‡‡æ · [0..8192]ï¼ˆåŒ…å«EOSï¼‰ï¼Œå±è”½TTS_TAG_*ä¸å…¶å®ƒåŸŸ
            let mut logits_masked = logits.clone();
            for (i, v) in logits_masked.iter_mut().enumerate() {
                if i > TTS_EOS_TOKEN as usize {
                    *v = f32::NEG_INFINITY;
                }
            }
            for tag in [TTS_TAG_0, TTS_TAG_1, TTS_TAG_2] {
                let idx = tag as usize;
                if idx < logits_masked.len() {
                    logits_masked[idx] = f32::NEG_INFINITY;
                }
            }

            let next_id = self.sample_logits(&logits_masked, &args_sem, None);
            if next_id == TTS_EOS_TOKEN as usize {
                break;
            }

            // è¿½åŠ åˆ°semanticè¾“å‡ºï¼ˆåŸå§‹åŸŸ [0..8191]ï¼‰
            semantic_tokens.push(next_id as i32);
            // è¯­ä¹‰é˜¶æ®µåé¦ˆï¼šç›´æ¥åé¦ˆåŸå§‹idï¼ˆç»éªŒï¼‰
            inference.batches[0].push(next_id as u32);
        }

        Ok((global_tokens, semantic_tokens))
    }

    /// é‡ç½®è¿è¡Œæ—¶çŠ¶æ€ï¼ˆå½“å‰RuntimeæŒ‰æ­¥æ¨ç†ï¼Œæš‚æ— æ˜¾å¼é‡ç½®éœ€æ±‚ï¼Œé¢„ç•™æ¥å£ï¼‰
    pub fn reset(&mut self) {
        // å¦‚æœåç»­Runtimeæä¾›stateé‡ç½®APIï¼Œå¯åœ¨æ­¤è°ƒç”¨ã€‚
        // ç›®å‰æ¯æ¬¡æ¨ç†éƒ½ä¼šé‡æ–°æ„é€ è¾“å…¥æ‰¹æ¬¡ï¼Œæ•…æ­¤å¤„ä¸ºç©ºå®ç°ã€‚
    }

    /// é‡‡æ ·å‡½æ•° - Nucleus(top-p) + top-k + temperature
    /// forbid_token: å¯é€‰ç¦æ­¢é‡‡æ ·çš„tokenï¼ˆå¦‚æŸäº›é˜¶æ®µçš„ç‰¹æ®Šç¬¦å·ï¼‰
    fn sample_logits(
        &mut self,
        logits: &[f32],
        args: &SamplerArgs,
        forbid_token: Option<usize>,
    ) -> usize {
        let vocab_size = logits.len();
        if vocab_size == 0 {
            return 0;
        }

        // å¤åˆ¶ç´¢å¼•å¹¶å¯é€‰è¿‡æ»¤ç¦ç”¨token
        let mut indices: Vec<usize> = (0..vocab_size).collect();
        if let Some(ft) = forbid_token {
            indices.retain(|&i| i != ft);
        }
        if indices.is_empty() {
            return 0;
        }

        let temperature = args.temperature.max(0.1);
        let top_k = if args.top_k == 0 || args.top_k > indices.len() {
            indices.len()
        } else {
            args.top_k
        };
        let top_p = args.top_p.clamp(0.0, 1.0);

        // å¿«é€Ÿè·¯å¾„ï¼štop_k==1æˆ–top_pæå°ï¼Œç›´æ¥å–æœ€å¤§logit
        if top_k == 1 || top_p < 1e-4 {
            let mut best = indices[0];
            let mut best_val = f32::NEG_INFINITY;
            for &i in &indices {
                let v = logits[i];
                if v > best_val {
                    best_val = v;
                    best = i;
                }
            }
            return best;
        }

        // æŒ‰logitsé™åºæ’åºï¼ˆä¸softmaxæ’åºä¸€è‡´ï¼‰
        indices.sort_by(|&a, &b| {
            logits[b]
                .partial_cmp(&logits[a])
                .unwrap_or(std::cmp::Ordering::Equal)
        });
        if top_k < indices.len() {
            indices.truncate(top_k);
        }

        // æ•°å€¼ç¨³å®šçš„ softmaxï¼šå‡å»æœ€å¤§å€¼å¹¶clampæŒ‡æ•°åŒºé—´
        let inv_t = 1.0 / temperature;
        let mut scaled: Vec<f32> = indices.iter().map(|&i| logits[i] * inv_t).collect();
        let mut max_scaled = f32::NEG_INFINITY;
        for &v in &scaled {
            if v > max_scaled {
                max_scaled = v;
            }
        }
        let mut probs: Vec<f32> = scaled
            .into_iter()
            .map(|v| ((v - max_scaled).clamp(-80.0, 80.0)).exp())
            .collect();
        let mut sum: f32 = probs.iter().sum();
        if sum > 0.0 && sum.is_finite() {
            for p in &mut probs {
                *p /= sum;
            }
        } else {
            // é€€åŒ–ä¸ºå‡åŒ€åˆ†å¸ƒï¼ˆæç«¯æ•°å€¼æƒ…å†µä¸‹ï¼‰
            let uniform = 1.0 / (probs.len() as f32).max(1.0);
            for p in &mut probs {
                *p = uniform;
            }
        }

        // top-pæˆªæ–­ï¼ˆåœ¨æ’åºåæ¦‚ç‡ç©ºé—´ä¸­ï¼‰
        if top_p < 1.0 {
            let mut cumsum = 0.0;
            let mut cutoff = probs.len();
            for (i, &p) in probs.iter().enumerate() {
                cumsum += p;
                if cumsum >= top_p {
                    cutoff = i + 1;
                    break;
                }
            }
            if cutoff < probs.len() {
                probs.truncate(cutoff);
                indices.truncate(cutoff);
            }
            // å†å½’ä¸€åŒ–
            sum = probs.iter().sum();
            if sum > 0.0 && sum.is_finite() {
                for p in &mut probs {
                    *p /= sum;
                }
            }
        }

        // æŒ‰æ¦‚ç‡é‡‡æ ·ï¼ˆæ”¯æŒç¡®å®šæ€§RNGï¼‰
        let r: f32 = if let Some(rng) = &mut self.rng {
            rng.gen()
        } else {
            let mut rng = rand::thread_rng();
            rng.gen()
        };
        let mut cumsum = 0.0;
        for (i, &p) in probs.iter().enumerate() {
            cumsum += p;
            if r <= cumsum {
                return indices[i];
            }
        }
        *indices.last().unwrap_or(&0)
    }
}
