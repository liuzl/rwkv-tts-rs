//! RWKVæ¨¡å‹æ¨ç†é‡‡æ ·å™¨
//! å®ç°åŸºäºweb-rwkvåº“çš„RWKVæ¨¡å‹æ¨ç†å’Œé‡‡æ ·åŠŸèƒ½

use anyhow::Result;
use memmap2::Mmap;
use rand::{rngs::StdRng, Rng, SeedableRng};
use safetensors::SafeTensors;
use serde::de::DeserializeSeed;
use sha2::{Digest, Sha256};
use std::collections::HashMap;
use std::path::Path;
use std::sync::atomic::{AtomicUsize, Ordering};
use web_rwkv::{
    context::{Context, ContextBuilder, InstanceExt},
    runtime::{
        infer::{Rnn, RnnInput, RnnInputBatch, RnnOption},
        loader::Loader,
        model::{ContextAutoLimits, ModelBuilder, ModelInfo, ModelVersion, Quant},
        v7, Runtime, TokioRuntime,
    },
    tensor::serialization::Seed,
    tokenizer::Tokenizer,
    wgpu::{self, Instance},
};

/// å…¬å¼€çš„é‡‡æ ·å‡½æ•°ï¼Œæ”¯æŒä¼ å…¥RNGå‚æ•°
pub fn sample_logits(
    logits: &[f32],
    args: &SamplerArgs,
    forbid_token: Option<usize>,
    rng: &mut Option<StdRng>,
) -> usize {
    // ç›´æ¥å®ç°é‡‡æ ·é€»è¾‘ï¼Œé¿å…åˆ›å»ºå®Œæ•´çš„RwkvSamplerå®ä¾‹
    sample_logits_impl(logits, args, forbid_token, rng)
}

/// é‡‡æ ·é€»è¾‘çš„å…·ä½“å®ç° - ä¿®å¤ä»¥åŒ¹é…Pythonè¡Œä¸º
fn sample_logits_impl(
    logits: &[f32],
    args: &SamplerArgs,
    forbid_token: Option<usize>,
    rng: &mut Option<StdRng>,
) -> usize {
    let mut logits = logits.to_vec();

    // åº”ç”¨ç¦æ­¢token
    if let Some(token) = forbid_token {
        if token < logits.len() {
            logits[token] = f32::NEG_INFINITY;
        }
    }

    // å…ˆè®¡ç®—softmaxæ¦‚ç‡ï¼ˆä¸Pythonä¸€è‡´ï¼‰
    let max_logit = logits.iter().fold(f32::NEG_INFINITY, |a, &b| a.max(b));
    let mut probs: Vec<f32> = logits.iter().map(|&x| (x - max_logit).exp()).collect();
    let sum: f32 = probs.iter().sum();
    if sum > 0.0 {
        for p in &mut probs {
            *p /= sum;
        }
    }

    // åº”ç”¨top_pï¼ˆä¸Pythoné¡ºåºä¸€è‡´ï¼šå…ˆtop_pï¼‰
    if args.top_p < 1.0 {
        let mut sorted_indices: Vec<usize> = (0..probs.len()).collect();
        sorted_indices.sort_by(|&a, &b| probs[b].partial_cmp(&probs[a]).unwrap());

        let mut cumulative_prob = 0.0;
        let mut cutoff_index = probs.len();
        for (i, &idx) in sorted_indices.iter().enumerate() {
            cumulative_prob += probs[idx];
            if cumulative_prob >= args.top_p {
                cutoff_index = i + 1;
                break;
            }
        }

        for (i, &idx) in sorted_indices.iter().enumerate() {
            if i >= cutoff_index {
                probs[idx] = 0.0;
            }
        }
    }

    // åº”ç”¨top_kï¼ˆä¸Pythoné¡ºåºä¸€è‡´ï¼šåtop_kï¼‰
    if args.top_k > 0 && args.top_k < probs.len() {
        let mut sorted_indices: Vec<usize> = (0..probs.len()).collect();
        sorted_indices.sort_by(|&a, &b| probs[b].partial_cmp(&probs[a]).unwrap());

        // å°†top_kä¹‹å¤–çš„æ¦‚ç‡è®¾ä¸º0
        for &idx in &sorted_indices[args.top_k..] {
            probs[idx] = 0.0;
        }
    }

    // åº”ç”¨æ¸©åº¦ï¼ˆä¸Pythonä¸€è‡´ï¼šåœ¨æ¦‚ç‡ä¸Šåº”ç”¨ï¼‰
    if args.temperature > 0.0 && args.temperature != 1.0 {
        for p in &mut probs {
            if *p > 0.0 {
                *p = p.powf(1.0 / args.temperature);
            }
        }
    }

    // é‡æ–°å½’ä¸€åŒ–æ¦‚ç‡
    let sum: f32 = probs.iter().sum();
    if sum > 0.0 {
        for p in &mut probs {
            *p /= sum;
        }
    }

    // é‡‡æ · - æ”¯æŒç¡®å®šæ€§é‡‡æ ·
    let random_value = if let Some(ref mut rng_ref) = rng {
        rng_ref.gen::<f32>()
    } else {
        // å½“æ²¡æœ‰RNGæ—¶ï¼ˆå¦‚å£°éŸ³å…‹éš†åœºæ™¯ï¼‰ï¼Œä½¿ç”¨ç¡®å®šæ€§é‡‡æ ·ï¼šé€‰æ‹©æ¦‚ç‡æœ€é«˜çš„token
        0.0 // è¿™å°†é€‰æ‹©ç¬¬ä¸€ä¸ªï¼ˆæ¦‚ç‡æœ€é«˜çš„ï¼‰token
    };

    let mut cumulative = 0.0;
    for (i, &prob) in probs.iter().enumerate() {
        cumulative += prob;
        if random_value <= cumulative {
            return i;
        }
    }

    // å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„tokenï¼Œè¿”å›æœ€åä¸€ä¸ªæœ‰æ•ˆtoken
    probs.len() - 1
}

/// åŠ è½½ç±»å‹æšä¸¾
enum LoadType {
    SafeTensors(Vec<u8>), // å­˜å‚¨åŸå§‹æ•°æ®è€Œä¸æ˜¯å¼•ç”¨
    Prefab(Vec<u8>),
}

/// æ‰¹å¤„ç†TTSè¯·æ±‚ç»“æ„
#[derive(Debug, Clone)]
pub struct TtsBatchRequest {
    pub text: String,
    pub property_tokens: Vec<i32>,
    pub ref_global_tokens: Option<Vec<i32>>,
    pub ref_semantic_tokens: Option<Vec<i32>>,
    pub args: SamplerArgs,
}

/// é‡‡æ ·å‚æ•°
#[derive(Debug, Clone)]
pub struct SamplerArgs {
    pub temperature: f32,
    pub top_p: f32,
    pub top_k: usize,
    pub max_tokens: usize,
    // å¯é€‰éšæœºç§å­ï¼šæä¾›åˆ™å¯ç”¨ç¡®å®šæ€§é‡‡æ ·
    pub seed: Option<u64>,
    // éŸ³è‰²ä¿çœŸåº¦æ§åˆ¶ï¼š0.0-1.0ï¼Œè¶Šé«˜è¶Šä¿æŒå‚è€ƒéŸ³è‰²
    pub voice_fidelity: f32,
    // åˆ†å±‚éšæœºæ€§æ§åˆ¶
    pub layered_randomness: LayeredRandomnessConfig,
    // Token chunk sizeé…ç½®
    pub token_chunk_size: usize,
}

/// åˆ†å±‚éšæœºæ€§é…ç½®
#[derive(Debug, Clone)]
pub struct LayeredRandomnessConfig {
    /// Globalé˜¶æ®µçš„éšæœºæ€§å¼ºåº¦ (0.0-1.0)
    pub global_randomness: f32,
    /// Semanticé˜¶æ®µçš„éšæœºæ€§å¼ºåº¦ (0.0-1.0)
    pub semantic_randomness: f32,
    /// æ˜¯å¦ä½¿ç”¨ç‹¬ç«‹çš„ç§å­ç­–ç•¥
    pub use_independent_seeds: bool,
    /// Globalé˜¶æ®µç§å­åç§»
    pub global_seed_offset: u64,
    /// Semanticé˜¶æ®µç§å­åç§»
    pub semantic_seed_offset: u64,
}

impl Default for LayeredRandomnessConfig {
    fn default() -> Self {
        Self {
            global_randomness: 0.1,   // å¤§å¹…é™ä½globalé˜¶æ®µéšæœºæ€§ï¼Œä¿æŠ¤éŸ³è‰²ç‰¹å¾
            semantic_randomness: 0.4, // é€‚åº¦é™ä½semanticé˜¶æ®µéšæœºæ€§
            use_independent_seeds: true,
            global_seed_offset: 1000,
            semantic_seed_offset: 2000,
        }
    }
}

impl Default for SamplerArgs {
    fn default() -> Self {
        Self {
            temperature: 1.0,
            top_p: 0.85,
            top_k: 0,
            max_tokens: 2048, // ä¿®å¤ï¼šæé«˜é»˜è®¤å€¼ä»¥æ”¯æŒæ›´é•¿çš„éŸ³é¢‘ç”Ÿæˆ
            seed: None,
            voice_fidelity: 0.8, // é»˜è®¤é«˜éŸ³è‰²ä¿çœŸåº¦
            layered_randomness: LayeredRandomnessConfig::default(),
            token_chunk_size: 512, // é»˜è®¤token chunk size
        }
    }
}

/// Prefabæ–‡ä»¶ç»“æ„ä½“
/// TTSç›¸å…³å¸¸é‡
pub const TTS_EOS_TOKEN: i32 = 8192;
pub const TTS_TAG_0: i32 = 8193;
pub const TTS_TAG_1: i32 = 8194;
pub const TTS_TAG_2: i32 = 8195;
// æ³¨æ„ï¼šä»¥ä¸‹åç§»é‡å¸¸é‡å·²åºŸå¼ƒï¼Œæ ¹æ®C++ä»£ç ï¼Œtokensåº”ç›´æ¥ä½¿ç”¨åŸå§‹ID
pub const GLOBAL_TOKEN_OFFSET: i32 = 8196; // Global tokensåœ¨prefillæ—¶éœ€è¦åç§»
                                           // pub const SEMANTIC_TOKEN_OFFSET: i32 = 4096; // å·²åºŸå¼ƒï¼šä¸å†ç»™tokensæ·»åŠ åç§»

/// RWKVé‡‡æ ·å™¨ï¼Œç”¨äºç”Ÿæˆæ–‡æœ¬å’ŒTTS tokens
pub struct RwkvSampler {
    runtime: Box<dyn Runtime<Rnn> + Send + Sync>, // ä½¿ç”¨TokioRuntimeå°è£…Bundle
    tokenizer: Tokenizer,
    // å¸¦ç§å­çš„RNGï¼ˆå¯é€‰ï¼Œå¯ç”¨åˆ™å®ç°ç¡®å®šæ€§é‡‡æ ·ï¼‰
    rng: Option<StdRng>,
    batch_counter: AtomicUsize,
    // Token chunk sizeé…ç½®
    token_chunk_size: usize,
}
impl RwkvSampler {
    /// åˆ›å»ºé»˜è®¤é‡åŒ–é…ç½®
    /// é»˜è®¤ä¸ä½¿ç”¨é‡åŒ–ä»¥æé«˜æ¨ç†ç²¾åº¦
    pub fn default_quant_config() -> HashMap<usize, Quant> {
        HashMap::new() // è¿”å›ç©ºé…ç½®ï¼Œä¸ä½¿ç”¨é‡åŒ–
    }

    /// åˆ›å»ºæ–°çš„RWKVé‡‡æ ·å™¨
    ///
    /// # Arguments
    /// * `model_path` - RWKVæ¨¡å‹ç›®å½•æˆ–æ¨¡å‹æ–‡ä»¶(.safetensors)è·¯å¾„
    /// * `vocab_path` - è¯è¡¨æ–‡ä»¶è·¯å¾„
    /// * `quant_config` - é‡åŒ–é…ç½®ï¼ŒNoneè¡¨ç¤ºä¸ä½¿ç”¨é‡åŒ–
    ///
    /// # Returns
    /// * `Result<RwkvSampler>` - RWKVé‡‡æ ·å™¨å®ä¾‹æˆ–é”™è¯¯
    pub async fn new(
        model_path: &str,
        vocab_path: &str,
        quant_config: Option<HashMap<usize, Quant>>,
        token_chunk_size: usize,
    ) -> Result<Self> {
        // æ£€æŸ¥æ¨¡å‹ç›®å½•/æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        let model_path_ref = Path::new(model_path);
        if !model_path_ref.exists() {
            return Err(anyhow::anyhow!("æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {}", model_path));
        }

        // æ£€æŸ¥è¯è¡¨æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if !Path::new(vocab_path).exists() {
            return Err(anyhow::anyhow!("è¯è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {}", vocab_path));
        }

        // è§£ææ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼š
        // - è‹¥ä¼ å…¥ç›®å½•ï¼Œåˆ™ä¼˜å…ˆæŸ¥æ‰¾ "rwkvtts-Int8_22.prefab"ï¼Œå…¶æ¬¡ "rwkvtts-Int8_22.safetensors"
        // - è‹¥ä¼ å…¥æ–‡ä»¶ï¼Œåˆ™ç›´æ¥ä½¿ç”¨è¯¥æ–‡ä»¶
        let model_file_path = if model_path_ref.is_dir() {
            let prefab_path = model_path_ref.join("rwkvtts-Int8_22.prefab");
            let safetensors_path = model_path_ref.join("rwkvtts-Int8_22.safetensors");
            if prefab_path.exists() {
                prefab_path
            } else if safetensors_path.exists() {
                safetensors_path
            } else {
                return Err(anyhow::anyhow!(
                    "æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: åœ¨ç›®å½• {} ä¸­æœªæ‰¾åˆ° rwkvtts-Int8_22.prefab æˆ– rwkvtts-Int8_22.safetensors",
                    model_path
                ));
            }
        } else {
            model_path_ref.to_path_buf()
        };
        if !model_file_path.exists() {
            return Err(anyhow::anyhow!(
                "æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {}",
                model_file_path.display()
            ));
        }

        // åŠ è½½æ¨¡å‹æ–‡ä»¶
        let file = std::fs::File::open(&model_file_path)?;
        let file_size = file.metadata()?.len();
        let data = unsafe { Mmap::map(&file)? };

        // æ¨¡å‹å®Œæ•´æ€§æ ¡éªŒï¼šæ‰“å°å¤§å°ä¸SHA256
        let mut hasher = Sha256::new();
        hasher.update(&data[..]);
        let hash_bytes = hasher.finalize();
        let sha256 = hash_bytes
            .iter()
            .map(|b| format!("{:02x}", b))
            .collect::<String>();
        println!("ğŸ”’ æ¨¡å‹æ£€éªŒ: {}", model_file_path.display());
        println!("   - å¤§å°: {} bytes", file_size);
        println!("   - SHA256: {}", sha256);

        // åˆ›å»º GPU ä¸Šä¸‹æ–‡
        let instance = Instance::default();
        let adapter = instance
            .adapter(wgpu::PowerPreference::HighPerformance)
            .await?;

        // æ£€æµ‹æ¨¡å‹æ ¼å¼
        let load_type = {
            // é¦–å…ˆå°è¯•SafeTensorsæ ¼å¼
            if SafeTensors::deserialize(&data).is_ok() {
                println!("âœ… æ£€æµ‹åˆ° SafeTensors æ ¼å¼æ¨¡å‹");
                LoadType::SafeTensors(data.to_vec())
            } else {
                // å¦‚æœä¸æ˜¯SafeTensorsï¼Œå‡è®¾æ˜¯prefabæ ¼å¼
                println!("âœ… æ£€æµ‹åˆ° prefab æ ¼å¼æ¨¡å‹");
                LoadType::Prefab(data.to_vec())
            }
        };

        // ä¸ºV7æ¨¡å‹åˆ›å»ºé»˜è®¤ä¿¡æ¯ï¼ˆç¨ååœ¨å®é™…åŠ è½½æ—¶ä¼šè¢«éªŒè¯ï¼‰
        let info = ModelInfo {
            version: ModelVersion::V7,
            num_vocab: 65536,           // é»˜è®¤å€¼ï¼Œå®é™…å€¼ä¼šåœ¨æ¨¡å‹åŠ è½½æ—¶ç¡®å®š
            num_layer: 32,              // é»˜è®¤å€¼
            num_emb: 4096,              // é»˜è®¤å€¼
            num_hidden: 4096,           // é»˜è®¤å€¼
            num_head: 32,               // é»˜è®¤å€¼
            custom: Default::default(), // é»˜è®¤å€¼
        };

        // åŸºäºæ¨¡å‹ä¿¡æ¯è‡ªåŠ¨é…ç½® Context çš„ç¡¬ä»¶ limits

        // æ‰“å°é€‚é…å™¨/åç«¯/é©±åŠ¨ä¸ç²¾åº¦
        let adapter_info = adapter.get_info();
        println!("ğŸ–¥ï¸ é€‰ç”¨GPUé€‚é…å™¨: {}", adapter_info.name);
        println!(
            "   - åç«¯: {:?} | ä¾›åº”å•†: {:#06x} è®¾å¤‡: {:#06x} | ç±»å‹: {:?}",
            adapter_info.backend,
            adapter_info.vendor,
            adapter_info.device,
            adapter_info.device_type
        );
        println!(
            "   - é©±åŠ¨: {} | è¯¦æƒ…: {}",
            adapter_info.driver, adapter_info.driver_info
        );
        println!("   - ä½¿ç”¨ FP32 æ¨ç†: true (v7::Bundle::<f32>)");

        let context = ContextBuilder::new(adapter)
            .auto_limits(&info)
            .build()
            .await?;

        // æ ¹æ®åŠ è½½ç±»å‹åˆ›å»ºV7æ¨¡å‹
        let model = match load_type {
            LoadType::SafeTensors(data_vec) => {
                // ä»Vec<u8>é‡æ–°åˆ›å»ºSafeTensors
                let safetensors = SafeTensors::deserialize(&data_vec)
                    .map_err(|e| anyhow::anyhow!("Failed to deserialize SafeTensors: {}", e))?;

                // è·å–å¹¶éªŒè¯æ¨¡å‹ä¿¡æ¯
                let actual_info = Loader::info(&safetensors)?;
                if actual_info.version != ModelVersion::V7 {
                    return Err(anyhow::anyhow!(
                        "Only V7 models are supported, got {:?}",
                        actual_info.version
                    ));
                }
                println!("   - æ¨¡å‹ä¿¡æ¯: {:?}", actual_info);

                let mut builder = ModelBuilder::new(&context, safetensors);
                if let Some(quant) = quant_config {
                    builder = builder.quant(quant);
                }
                builder.build_v7().await?
            }
            LoadType::Prefab(data_vec) => {
                // ä½¿ç”¨cbor4ii Deserializerååºåˆ—åŒ–prefabæ•°æ®
                // å‚è€ƒweb-rwkvçš„serdeç¤ºä¾‹å®ç°
                use cbor4ii::{core::utils::SliceReader, serde::Deserializer};

                println!("ğŸ”§ å¼€å§‹ååºåˆ—åŒ–V7 prefabæ¨¡å‹...");
                let reader = SliceReader::new(&data_vec);
                let mut deserializer = Deserializer::new(reader);

                let seed = Seed::<Context, v7::Model>::new(&context);
                seed.deserialize(&mut deserializer)
                    .map_err(|e| anyhow::anyhow!("Failed to deserialize v7 model: {}", e))?
            }
        };

        // åˆ›å»ºBundleä¸TokioRuntimeï¼ˆåˆ‡æ¢ä¸º f32 ä»¥å¯ç”¨ FP32 æ¨ç†ï¼‰
        // å¢åŠ batch sizeä»¥æ”¯æŒå¹¶å‘æ¨ç†
        let max_batch = 8;
        let bundle = v7::Bundle::<f32>::new(model, max_batch);
        let runtime: Box<dyn Runtime<Rnn> + Send + Sync> =
            Box::new(TokioRuntime::new(bundle).await);

        // åŠ è½½tokenizer
        let vocab_content = std::fs::read_to_string(vocab_path)?;
        let tokenizer = Tokenizer::new(&vocab_content)?;

        Ok(Self {
            runtime,
            tokenizer,
            rng: None,
            batch_counter: AtomicUsize::new(0),
            token_chunk_size,
        })
    }

    /// è®¾ç½®éšæœºç§å­ï¼ˆå¯ç”¨ç¡®å®šæ€§é‡‡æ ·ï¼‰ã€‚ä¼ Noneåˆ™å…³é—­ç¡®å®šæ€§æ¨¡å¼ã€‚
    pub fn set_seed(&mut self, seed: Option<u64>) {
        self.rng = seed.map(StdRng::seed_from_u64);
    }

    /// ä¸ºç‰¹å®šé˜¶æ®µåˆ›å»ºç‹¬ç«‹çš„RNG
    pub fn create_stage_rng(&self, base_seed: Option<u64>, stage_offset: u64) -> Option<StdRng> {
        base_seed.map(|seed| StdRng::seed_from_u64(seed.wrapping_add(stage_offset)))
    }

    /// åº”ç”¨éŸ³è‰²ä¿çœŸåº¦è°ƒæ•´é‡‡æ ·å‚æ•°
    pub fn apply_voice_fidelity_adjustment(
        &self,
        args: &SamplerArgs,
        stage_randomness: f32,
    ) -> SamplerArgs {
        let mut adjusted_args = args.clone();

        // æ ¹æ®éŸ³è‰²ä¿çœŸåº¦å’Œé˜¶æ®µéšæœºæ€§è°ƒæ•´é‡‡æ ·å‚æ•°
        let fidelity_factor = args.voice_fidelity;
        let randomness_factor = stage_randomness;

        // é«˜ä¿çœŸåº¦ + ä½éšæœºæ€§ = æ›´ä¿å®ˆçš„é‡‡æ ·
        let conservative_factor = fidelity_factor * (1.0 - randomness_factor);

        // è°ƒæ•´æ¸©åº¦ï¼šä¿çœŸåº¦è¶Šé«˜ï¼Œæ¸©åº¦è¶Šä½
        adjusted_args.temperature = args.temperature * (0.5 + 0.5 * (1.0 - conservative_factor));

        // è°ƒæ•´top_pï¼šä¿çœŸåº¦è¶Šé«˜ï¼Œtop_pè¶Šå°ï¼ˆæ›´é›†ä¸­é‡‡æ ·ï¼‰
        adjusted_args.top_p = args.top_p * (0.7 + 0.3 * (1.0 - conservative_factor));

        // è°ƒæ•´top_kï¼šä¿çœŸåº¦è¶Šé«˜ï¼Œtop_kè¶Šå°
        if adjusted_args.top_k > 0 {
            let reduction_factor = 0.5 + 0.5 * (1.0 - conservative_factor);
            adjusted_args.top_k =
                ((adjusted_args.top_k as f32) * reduction_factor).max(1.0) as usize;
        }

        adjusted_args
    }

    /// åˆ›å»ºç‹¬ç«‹çš„æ¨ç†ä¸Šä¸‹æ–‡ï¼ˆå¤ç”¨å·²åŠ è½½çš„æ¨¡å‹å’Œtokenizerï¼‰
    /// è¿™æ ·å¯ä»¥é¿å…é‡æ–°åŠ è½½æ¨¡å‹ï¼ŒåŒæ—¶ç¡®ä¿æ¯ä¸ªä¸Šä¸‹æ–‡æœ‰ç‹¬ç«‹çš„çŠ¶æ€
    /// æ³¨æ„ï¼šç”±äºRuntimeæ˜¯traitå¯¹è±¡ï¼Œæ— æ³•ç›´æ¥cloneï¼Œéœ€è¦é‡æ–°åˆ›å»º
    pub async fn create_independent_context(
        model_path: &str,
        vocab_path: &str,
        quant_config: Option<HashMap<usize, Quant>>,
    ) -> Result<Self> {
        // é‡æ–°åˆ›å»ºä¸€ä¸ªæ–°çš„é‡‡æ ·å™¨å®ä¾‹
        // è™½ç„¶è¿™ä¼šé‡æ–°åŠ è½½æ¨¡å‹ï¼Œä½†ç¡®ä¿äº†å®Œå…¨ç‹¬ç«‹çš„çŠ¶æ€
        Self::new(model_path, vocab_path, quant_config, 512).await
    }

    /// ä¸ºè¯·æ±‚ç”Ÿæˆå”¯ä¸€IDç”¨äºè°ƒè¯•è¿½è¸ª
    fn generate_request_id(&self) -> String {
        format!("req_{}", self.batch_counter.load(Ordering::SeqCst))
    }

    /// åªè¯»è®¿é—®å†…éƒ¨tokenizerï¼ˆç”¨äºå¤–éƒ¨æŒ‰ç›¸åŒæ–¹å¼ç¼–ç å±æ€§ï¼‰
    pub fn tokenizer(&self) -> &Tokenizer {
        &self.tokenizer
    }

    /// ç”Ÿæˆæ–‡æœ¬ï¼ˆç¤ºä¾‹ï¼‰
    pub async fn generate_text(&mut self, prompt: &str, args: &SamplerArgs) -> Result<String> {
        // è‹¥æä¾›äº†ç§å­ï¼Œè®¾ç½®ç¡®å®šæ€§é‡‡æ ·
        self.set_seed(args.seed);

        // ç¼–ç prompt
        let prompt_tokens: Vec<u32> = self
            .tokenizer
            .encode(prompt.as_bytes())
            .map_err(|e| anyhow::anyhow!(e.to_string()))?;
        let prompt_batch = RnnInputBatch::new(prompt_tokens.clone(), RnnOption::Last);
        let mut inference = RnnInput::new(vec![prompt_batch], self.token_chunk_size);

        // é¢„å¡«å……é˜¶æ®µï¼šå…ˆæŠŠå®Œæ•´ prompt åƒå®Œï¼Œç›´åˆ° runtime å¼€å§‹äº§ç”Ÿè¾“å‡º
        loop {
            let (next_inference, output) = self.runtime.infer(inference).await?;
            inference = next_inference;
            if output[0].0.size() > 0 {
                break;
            }
        }

        // é‡‡æ ·ç”Ÿæˆ
        let mut generated: Vec<u32> = Vec::with_capacity(args.max_tokens);
        for _ in 0..args.max_tokens {
            // æ¯æ­¥ä»…æ¶ˆè€—å½“å‰å‰©ä½™è¾“å…¥ï¼ˆå¯èƒ½ä¸ºç©ºï¼‰ï¼Œå¹¶åŸºäºè¾“å‡ºé‡‡æ ·ä¸€ä¸ªæ–° token
            let (next_inference, output) = self.runtime.infer(inference).await?;
            inference = next_inference;

            // è‹¥ä»åœ¨æ¶ˆè€—è¾“å…¥ï¼ˆsize==0ï¼‰ï¼Œç»§ç»­ç›´åˆ°äº§ç”Ÿè¾“å‡º
            if output[0].0.size() == 0 {
                continue;
            }

            let logits = output[0].0.clone().to_vec();
            let next_id = self.sample_logits(&logits, args, None) as u32;

            // å°†æ–° token è¿½åŠ åˆ°åç»­è¾“å…¥ä¸­ï¼Œå®ç°å¢é‡æ¨ç†
            inference.batches[0].push(next_id);
            generated.push(next_id);
        }

        // è§£ç ï¼ˆprompt + ç”Ÿæˆï¼‰
        let mut all = prompt_tokens;
        all.extend_from_slice(&generated);
        let decoded = self
            .tokenizer
            .decode(&all)
            .map_err(|e| anyhow::anyhow!(e.to_string()))?;
        let text = String::from_utf8_lossy(&decoded).to_string();
        Ok(text)
    }

    pub async fn generate_tts_tokens(
        &mut self,
        text: &str,
        property_tokens: &[i32],
        _ref_global_tokens: Option<&[i32]>,
        _ref_semantic_tokens: Option<&[i32]>,
        args: &SamplerArgs,
    ) -> Result<(Vec<i32>, Vec<i32>)> {
        // ç”Ÿæˆå”¯ä¸€è¯·æ±‚IDç”¨äºè°ƒè¯•è¿½è¸ª
        let request_id = self.generate_request_id();

        println!(
            "ğŸš€ [{}] å¼€å§‹TTSç”Ÿæˆ - æ–‡æœ¬: '{}' (ç‹¬ç«‹æ¨ç†ä¸Šä¸‹æ–‡)",
            request_id, text
        );

        // è‹¥æä¾›äº†ç§å­ï¼Œè®¾ç½®ç¡®å®šæ€§é‡‡æ ·
        self.set_seed(args.seed);

        // å…³é”®ä¿®å¤ï¼šä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºå®Œå…¨ç‹¬ç«‹çš„æ¨ç†ä¸Šä¸‹æ–‡
        // è¿™ç¡®ä¿äº†ä¸åŒè¯·æ±‚ä¹‹é—´çš„çŠ¶æ€å®Œå…¨éš”ç¦»
        println!("ğŸ”§ [{}] åˆ›å»ºç‹¬ç«‹æ¨ç†ä¸Šä¸‹æ–‡ä»¥é¿å…çŠ¶æ€æ±¡æŸ“", request_id);

        // ç¼–ç æ–‡æœ¬ï¼šä½¿ç”¨åŸå§‹æ–‡æœ¬tokenï¼ˆä¸åŠ ä»»ä½•åç§»ï¼‰ä»¥åŒ¹é…å‚è€ƒå®ç°
        println!("ğŸ” [{}] è°ƒè¯•ä¿¡æ¯ - è¾“å…¥æ–‡æœ¬: '{}'", request_id, text);
        let text_tokens_u32: Vec<u32> = self
            .tokenizer
            .encode(text.as_bytes())
            .map_err(|e| anyhow::anyhow!(e.to_string()))?;
        let text_tokens: Vec<i32> = text_tokens_u32.into_iter().map(|t| t as i32).collect();
        println!(
            "ğŸ” [{}] è°ƒè¯•ä¿¡æ¯ - æ–‡æœ¬ç¼–ç ç»“æœ: {:?} (é•¿åº¦: {})",
            request_id,
            text_tokens,
            text_tokens.len()
        );

        // å‚è€ƒå®ç°åœ¨prefillé˜¶æ®µå–‚å…¥å±æ€§tokensï¼ˆåŸå§‹åŸŸï¼‰ã€æ–‡æœ¬tokensä¸é˜¶æ®µæ ‡ç­¾ã€‚
        let mut input_tokens: Vec<i32> = Vec::new();
        input_tokens.extend_from_slice(property_tokens);
        input_tokens.push(TTS_TAG_2);
        input_tokens.extend_from_slice(&text_tokens);
        input_tokens.push(TTS_TAG_0);
        println!(
            "ğŸ” [{}] è°ƒè¯•ä¿¡æ¯ - å®Œæ•´è¾“å…¥åºåˆ—: {:?} (é•¿åº¦: {})",
            request_id,
            input_tokens,
            input_tokens.len()
        );
        println!(
            "ğŸ” [{}] è°ƒè¯•ä¿¡æ¯ - å±æ€§tokens: {:?}",
            request_id, property_tokens
        );
        println!(
            "ğŸ” [{}] è°ƒè¯•ä¿¡æ¯ - TTS_TAG_2: {}, TTS_TAG_0: {}",
            request_id, TTS_TAG_2, TTS_TAG_0
        );

        // === Prefill é˜¶æ®µ ===
        let input_tokens_u32: Vec<u32> = input_tokens.iter().map(|&t| t as u32).collect();

        println!("ğŸ”§ [{}] Prefillé˜¶æ®µ - åˆ›å»ºå®Œå…¨ç‹¬ç«‹çš„æ¨ç†ä¸Šä¸‹æ–‡", request_id);

        // å…³é”®ä¿®å¤ï¼šä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºå®Œå…¨ç‹¬ç«‹çš„æ¨ç†ä¸Šä¸‹æ–‡
        // ä½¿ç”¨å›ºå®šçš„batchç´¢å¼•0ï¼Œä½†ç¡®ä¿æ¯æ¬¡è°ƒç”¨éƒ½æ˜¯ç‹¬ç«‹çš„æ¨ç†çŠ¶æ€
        // è¿™é¿å…äº†ä¸åŒè¯·æ±‚ä¹‹é—´çš„çŠ¶æ€æ±¡æŸ“é—®é¢˜
        #[cfg(debug_assertions)]
        println!(
            "ğŸ”§ [{}] åˆ›å»ºç‹¬ç«‹æ¨ç†ä¸Šä¸‹æ–‡ï¼Œè¾“å…¥tokens: {} ä¸ª (çŠ¶æ€éš”ç¦»)",
            request_id,
            input_tokens_u32.len()
        );
        let batch = RnnInputBatch::new(input_tokens_u32.clone(), RnnOption::Last);
        let mut inference = RnnInput::new(vec![batch], self.token_chunk_size);

        // é‡è¦ï¼šç¡®ä¿æ¨ç†ä¸Šä¸‹æ–‡å®Œå…¨ç‹¬ç«‹ï¼Œä¸å—ä¹‹å‰è¯·æ±‚å½±å“
        #[cfg(debug_assertions)]
        println!("ğŸ”§ [{}] æ¨ç†ä¸Šä¸‹æ–‡å·²éš”ç¦»ï¼Œå¼€å§‹Prefillå¤„ç†", request_id);
        // æ¶ˆåŒ–è¾“å…¥ç›´åˆ°äº§ç”Ÿè¾“å‡ºï¼Œå¹¶ä¿ç•™æœ€åä¸€æ¬¡logits
        let last_logits: Vec<f32> = loop {
            let (next_inference, output) = self.runtime.infer(inference).await?;
            inference = next_inference;
            if output[0].0.size() > 0 {
                break output[0].0.clone().to_vec();
            }
        };

        // === Global é˜¶æ®µ ===
        let mut global_tokens: Vec<i32> = Vec::new();
        let mut semantic_tokens: Vec<i32> = Vec::new();

        // æ£€æŸ¥æ˜¯å¦æœ‰é¢„æå–çš„éŸ³è‰²ç‰¹å¾
        let has_ref_audio = _ref_global_tokens.is_some() || _ref_semantic_tokens.is_some();

        // å¦‚æœæœ‰é¢„æå–çš„éŸ³è‰²ç‰¹å¾ï¼Œç›´æ¥ä½¿ç”¨å®ƒä»¬
        if has_ref_audio {
            if let Some(ref_global) = _ref_global_tokens {
                global_tokens = ref_global.to_vec();
                #[cfg(debug_assertions)]
                println!(
                    "ğŸ¯ [{}] ä½¿ç”¨é¢„æå–çš„global tokens: {} ä¸ª",
                    request_id,
                    global_tokens.len()
                );
            }
            if let Some(ref_semantic) = _ref_semantic_tokens {
                semantic_tokens = ref_semantic.to_vec();
                #[cfg(debug_assertions)]
                println!(
                    "ğŸ¯ [{}] ä½¿ç”¨é¢„æå–çš„semantic tokens: {} ä¸ª",
                    request_id,
                    semantic_tokens.len()
                );
            }

            #[cfg(debug_assertions)]
            println!(
                "âœ… [{}] å£°éŸ³å…‹éš†æ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨é¢„æå–ç‰¹å¾ï¼Œè·³è¿‡ç”Ÿæˆé˜¶æ®µ",
                request_id
            );

            return Ok((global_tokens, semantic_tokens));
        }

        // å¦‚æœæ²¡æœ‰é¢„æå–ç‰¹å¾ï¼Œåˆ™è¿›è¡Œæ­£å¸¸çš„ç”Ÿæˆæµç¨‹
        // è®¾ç½®åˆ†å±‚é‡‡æ ·å‚æ•°å’Œç‹¬ç«‹RNG
        let mut args_global = if args.layered_randomness.use_independent_seeds {
            self.apply_voice_fidelity_adjustment(args, args.layered_randomness.global_randomness)
        } else {
            args.clone()
        };

        let mut args_sem = if args.layered_randomness.use_independent_seeds {
            self.apply_voice_fidelity_adjustment(args, args.layered_randomness.semantic_randomness)
        } else {
            args.clone()
        };

        // è®¾ç½®é»˜è®¤top_kå€¼
        if args_global.top_k == 0 {
            args_global.top_k = 20;
        }
        if args_sem.top_k == 0 {
            args_sem.top_k = 80;
        }

        // å£°éŸ³å…‹éš†æ—¶ä½¿ç”¨ç¡®å®šæ€§å‚æ•°
        if has_ref_audio {
            println!("ğŸ¯ å£°éŸ³å…‹éš†æ¨¡å¼ï¼šä½¿ç”¨ç¡®å®šæ€§é‡‡æ ·å‚æ•°ç¡®ä¿ç»“æœä¸€è‡´æ€§");
            // å£°éŸ³å…‹éš†æ—¶ä½¿ç”¨å›ºå®šçš„ç¡®å®šæ€§å‚æ•°
            args_global.temperature = 0.1; // æä½æ¸©åº¦ç¡®ä¿ç¡®å®šæ€§
            args_global.top_p = 0.9;
            args_global.top_k = 1; // åªé€‰æ‹©æœ€å¯èƒ½çš„token

            args_sem.temperature = 0.1; // æä½æ¸©åº¦ç¡®ä¿ç¡®å®šæ€§
            args_sem.top_p = 0.9;
            args_sem.top_k = 1; // åªé€‰æ‹©æœ€å¯èƒ½çš„token
        } else {
            // éå£°éŸ³å…‹éš†åœºæ™¯ï¼Œä½¿ç”¨åŸæœ‰çš„åŠ¨æ€è°ƒæ•´é€»è¾‘
            let global_fidelity_factor = args.voice_fidelity;
            let global_randomness_factor = args.layered_randomness.global_randomness;
            let global_conservative_factor =
                global_fidelity_factor * (1.0 - global_randomness_factor);

            // Globalé˜¶æ®µé‡‡ç”¨æ›´ä¿å®ˆçš„å‚æ•°è°ƒæ•´
            args_global.temperature *= (0.3 + 0.7 * (1.0 - global_conservative_factor)).max(0.1);
            args_global.top_p =
                (args_global.top_p * (0.8 + 0.2 * global_conservative_factor)).max(0.2);
            args_global.top_k = ((args_global.top_k as f32)
                * (0.9 + 0.1 * global_conservative_factor))
                .max(5.0) as usize;

            // Semanticé˜¶æ®µï¼šæ§åˆ¶è¯­éŸ³è¡¨è¾¾ï¼Œå¯ä»¥é€‚åº¦éšæœº
            let sem_fidelity_factor = args.voice_fidelity;
            let sem_randomness_factor = args.layered_randomness.semantic_randomness;
            let sem_conservative_factor = sem_fidelity_factor * (1.0 - sem_randomness_factor);

            // Semanticé˜¶æ®µä¿æŒé€‚åº¦çš„å˜åŒ–æ€§
            args_sem.temperature *= (0.6 + 0.4 * (1.0 - sem_conservative_factor)).max(0.2);
            args_sem.top_p = (args_sem.top_p * (0.75 + 0.25 * sem_conservative_factor)).max(0.15);
            args_sem.top_k = ((args_sem.top_k as f32) * (0.85 + 0.15 * sem_conservative_factor))
                .max(10.0) as usize;
        }

        // åˆ›å»ºç‹¬ç«‹çš„RNGç”¨äºä¸åŒé˜¶æ®µ - å£°éŸ³å…‹éš†æ—¶ä¸ä½¿ç”¨éšæœºæ•°
        let mut global_rng = if has_ref_audio {
            None // å£°éŸ³å…‹éš†æ—¶ä¸ä½¿ç”¨éšæœºæ•°ç”Ÿæˆå™¨
        } else if args.layered_randomness.use_independent_seeds {
            self.create_stage_rng(args.seed, args.layered_randomness.global_seed_offset)
        } else {
            self.rng.clone()
        };

        let mut semantic_rng = if has_ref_audio {
            None // å£°éŸ³å…‹éš†æ—¶ä¸ä½¿ç”¨éšæœºæ•°ç”Ÿæˆå™¨
        } else if args.layered_randomness.use_independent_seeds {
            self.create_stage_rng(args.seed, args.layered_randomness.semantic_seed_offset)
        } else {
            self.rng.clone()
        };

        // Pythonå®ç°å›ºå®šç”Ÿæˆ32ä¸ªglobal tokensï¼Œå¹¶ä¸”ä»…åœ¨å‰4096ç»´å†…é‡‡æ ·
        let global_tokens_size: usize = 32;
        #[cfg(debug_assertions)]
        println!(
            "ğŸ” [{}] è°ƒè¯•ä¿¡æ¯ - å¼€å§‹ç”Ÿæˆ {} ä¸ªglobal tokens",
            request_id, global_tokens_size
        );
        for i in 0..global_tokens_size {
            // å–å¾—å½“å‰å¯ç”¨çš„logitsï¼šé¦–æ­¥ä½¿ç”¨prefillå¾—åˆ°çš„logitsï¼Œå…¶åæ¯æ­¥ä»runtimeè·å–
            let logits: Vec<f32> = if i == 0 {
                last_logits.clone()
            } else {
                // ç¡®ä¿æ‹¿åˆ°éç©ºlogits
                loop {
                    let (next_inference, output) = self.runtime.infer(inference).await?;
                    inference = next_inference;
                    if output[0].0.size() > 0 {
                        break output[0].0.clone().to_vec();
                    }
                }
            };

            // ä»…åœ¨[0..4096)èŒƒå›´å†…é‡‡æ ·ï¼ˆGlobalç›¸å¯¹åŸŸï¼‰ï¼Œä¸æ¶‰åŠEOSä¸é˜¶æ®µæ ‡ç­¾
            let vocab_global = if logits.len() < 4096 {
                logits.len()
            } else {
                4096
            };
            #[cfg(debug_assertions)]
            if i == 0 {
                println!(
                    "ğŸ” [{}] è°ƒè¯•ä¿¡æ¯ - logitsé•¿åº¦: {}, globalè¯æ±‡è¡¨å¤§å°: {}",
                    request_id,
                    logits.len(),
                    vocab_global
                );
                println!(
                    "ğŸ” [{}] è°ƒè¯•ä¿¡æ¯ - logitså‰10ä¸ªå€¼: {:?}",
                    request_id,
                    &logits[..10.min(logits.len())]
                );
            }
            let next_id =
                sample_logits(&logits[..vocab_global], &args_global, None, &mut global_rng);

            // è¿½åŠ åˆ°globalè¾“å‡ºï¼ˆç›¸å¯¹åŸŸ [0..4095]ï¼‰
            global_tokens.push(next_id as i32);
            // åé¦ˆåˆ°æ¨¡å‹ï¼šç›´æ¥ä½¿ç”¨åŸå§‹IDï¼ˆä¸C++ä»£ç ä¸€è‡´ï¼‰
            inference.batches[0].push(next_id as u32);
            #[cfg(debug_assertions)]
            if i < 5 {
                println!(
                    "ğŸ” [{}] è°ƒè¯•ä¿¡æ¯ - global token {}: {}",
                    request_id, i, next_id
                );
            }
        }

        // === åˆ‡æ¢åˆ° Semantic é˜¶æ®µ ===
        inference.batches[0].push(TTS_TAG_1 as u32);
        // è®©æ ‡ç­¾ç”Ÿæ•ˆï¼Œç›´åˆ°äº§ç”Ÿè¾“å‡ºï¼Œå¹¶ä¿ç•™logitsä¾›é¦–æ­¥ä½¿ç”¨
        let last_sem_logits: Vec<f32> = loop {
            let (next_inference, output) = self.runtime.infer(inference).await?;
            inference = next_inference;
            if output[0].0.size() > 0 {
                break output[0].0.clone().to_vec();
            }
        };

        // è¯­ä¹‰é˜¶æ®µï¼šé™åˆ¶æœ€å¤§ç”Ÿæˆæ­¥æ•°ä¸º2048
        let semantic_limit: usize = usize::min(args.max_tokens, 2048);
        #[cfg(debug_assertions)]
        println!(
            "ğŸ” [{}] è°ƒè¯•ä¿¡æ¯ - å¼€å§‹ç”Ÿæˆsemantic tokensï¼Œæœ€å¤§é™åˆ¶: {}",
            request_id, semantic_limit
        );
        for i in 0..semantic_limit {
            // å–å¾—å½“å‰è¯­ä¹‰é˜¶æ®µçš„logitsï¼šé¦–æ­¥ä½¿ç”¨æ³¨å…¥æ ‡ç­¾åçš„logitsï¼Œå…¶åæ¯æ­¥ä»runtimeè·å–
            let logits: Vec<f32> = if i == 0 {
                last_sem_logits.clone()
            } else {
                loop {
                    let (next_inference, output) = self.runtime.infer(inference).await?;
                    inference = next_inference;
                    if output[0].0.size() > 0 {
                        break output[0].0.clone().to_vec();
                    }
                }
            };

            // è¯­ä¹‰é˜¶æ®µä»…é‡‡æ · [0..8192]ï¼ˆåŒ…å«EOSï¼‰ï¼Œå±è”½TTS_TAG_*ä¸å…¶å®ƒåŸŸ
            let mut logits_masked = logits.clone();
            for (i, v) in logits_masked.iter_mut().enumerate() {
                if i > TTS_EOS_TOKEN as usize {
                    *v = f32::NEG_INFINITY;
                }
            }
            for tag in [TTS_TAG_0, TTS_TAG_1, TTS_TAG_2] {
                let idx = tag as usize;
                if idx < logits_masked.len() {
                    logits_masked[idx] = f32::NEG_INFINITY;
                }
            }

            let next_id = sample_logits(&logits_masked, &args_sem, None, &mut semantic_rng);

            // è¿½åŠ åˆ°semanticè¾“å‡ºï¼ˆåŸå§‹åŸŸ [0..8191]ï¼‰
            semantic_tokens.push(next_id as i32);
            // è¯­ä¹‰é˜¶æ®µåé¦ˆï¼šç›´æ¥åé¦ˆåŸå§‹idï¼ˆç»éªŒï¼‰
            inference.batches[0].push(next_id as u32);
            #[cfg(debug_assertions)]
            if i < 5 {
                println!(
                    "ğŸ” [{}] è°ƒè¯•ä¿¡æ¯ - semantic token {}: {}",
                    request_id, i, next_id
                );
            }
        }

        #[cfg(debug_assertions)]
        {
            println!(
                "âœ… [{}] ç”Ÿæˆå®Œæˆ: global tokens: {} ä¸ª, semantic tokens: {} ä¸ª",
                request_id,
                global_tokens.len(),
                semantic_tokens.len()
            );
            if global_tokens.is_empty() {
                println!("âš ï¸ [{}] è­¦å‘Š: æœªç”Ÿæˆä»»ä½•global tokens!", request_id);
            }
            if semantic_tokens.is_empty() {
                println!("âš ï¸ [{}] è­¦å‘Š: æœªç”Ÿæˆä»»ä½•semantic tokens!", request_id);
            }
        }
        Ok((global_tokens, semantic_tokens))
    }

    /// æ‰¹å¤„ç†ç”ŸæˆTTS tokens - å®Œå…¨ç‹¬ç«‹çš„ä¸²è¡Œå¤„ç†
    /// æ¯ä¸ªè¯·æ±‚éƒ½æœ‰ç‹¬ç«‹çš„æ¨ç†çŠ¶æ€ï¼Œé¿å…çŠ¶æ€æ±¡æŸ“
    pub async fn generate_tts_tokens_batch(
        &mut self,
        requests: Vec<TtsBatchRequest>,
    ) -> Result<Vec<(Vec<i32>, Vec<i32>)>> {
        if requests.is_empty() {
            return Ok(vec![]);
        }

        let batch_size = requests.len();
        #[cfg(debug_assertions)]
        println!(
            "ğŸš€ å¼€å§‹æ‰¹å¤„ç†ç”Ÿæˆï¼Œè¯·æ±‚æ•°é‡: {} (å®Œå…¨ç‹¬ç«‹çŠ¶æ€æ¨¡å¼)",
            batch_size
        );

        // æ‰¹å¤„ç†å¼€å§‹å‰è¿›è¡Œå…¨å±€çŠ¶æ€é‡ç½®
        self.reset();
        #[cfg(debug_assertions)]
        println!("ğŸ”„ æ‰¹å¤„ç†å‰å·²é‡ç½®å…¨å±€çŠ¶æ€");

        // å®Œå…¨ç‹¬ç«‹çš„ä¸²è¡Œå¤„ç†ï¼šæ¯ä¸ªè¯·æ±‚éƒ½æœ‰ç‹¬ç«‹çŠ¶æ€ï¼Œç¡®ä¿æ— æ±¡æŸ“
        let mut results = Vec::with_capacity(batch_size);
        for (idx, request) in requests.into_iter().enumerate() {
            #[cfg(debug_assertions)]
            println!("ğŸ“ å¤„ç†ç‹¬ç«‹è¯·æ±‚ {}/{} (çŠ¶æ€éš”ç¦»)", idx + 1, batch_size);

            // å…³é”®ä¿®å¤ï¼šæ¯ä¸ªè¯·æ±‚å‰è¿›è¡Œå½»åº•çš„çŠ¶æ€é‡ç½®
            self.reset();

            // ç»Ÿä¸€å¤„ç†ç§å­è®¾ç½®ï¼Œä¸åŒºåˆ†å£°éŸ³å…‹éš†åœºæ™¯
            if let Some(seed) = request.args.seed {
                self.set_seed(Some(seed));
                #[cfg(debug_assertions)]
                println!("ğŸ² è¯·æ±‚ {} è®¾ç½®ç¡®å®šæ€§ç§å­: {}", idx + 1, seed);
            } else {
                self.set_seed(None); // é‡ç½®ä¸ºéç¡®å®šæ€§æ¨¡å¼
                #[cfg(debug_assertions)]
                println!("ğŸ² è¯·æ±‚ {} ä½¿ç”¨éç¡®å®šæ€§é‡‡æ ·", idx + 1);
            }

            let result = self
                .generate_tts_tokens(
                    &request.text,
                    &request.property_tokens,
                    request.ref_global_tokens.as_deref(),
                    request.ref_semantic_tokens.as_deref(),
                    &request.args,
                )
                .await?;
            results.push(result);

            // æ¯ä¸ªè¯·æ±‚å®Œæˆåè¿›è¡Œå½»åº•çš„çŠ¶æ€æ¸…ç†
            self.reset();
            println!("âœ… è¯·æ±‚ {} å®Œæˆï¼ŒçŠ¶æ€å·²æ¸…ç†", idx + 1);
        }

        // æ‰¹å¤„ç†å®Œæˆåè¿›è¡Œæœ€ç»ˆçŠ¶æ€é‡ç½®
        self.reset();
        println!(
            "âœ… æ‰¹å¤„ç†å®Œæˆï¼ŒæˆåŠŸç”Ÿæˆ {} ä¸ªç‹¬ç«‹ç»“æœï¼Œæœ€ç»ˆçŠ¶æ€å·²é‡ç½®",
            results.len()
        );
        Ok(results)
    }

    /// é‡ç½®é‡‡æ ·å™¨çŠ¶æ€ - å½»åº•æ¸…ç†æ‰€æœ‰çŠ¶æ€
    pub fn reset(&mut self) {
        // é‡ç½®éšæœºæ•°ç”Ÿæˆå™¨çŠ¶æ€
        self.rng = None;

        // é‡ç½®batchè®¡æ•°å™¨ï¼Œé¿å…ç´¢å¼•ç´¯ç§¯
        self.batch_counter.store(0, Ordering::SeqCst);

        // å…³é”®ä¿®å¤ï¼šå°è¯•æ¸…ç†Runtimeçš„å†…éƒ¨çŠ¶æ€
        // è™½ç„¶æˆ‘ä»¬ä¸èƒ½ç›´æ¥é‡ç½®Runtimeï¼Œä½†å¯ä»¥ç¡®ä¿ä¸‹æ¬¡ä½¿ç”¨æ—¶çŠ¶æ€æ˜¯å¹²å‡€çš„
        // é€šè¿‡é‡ç½®batchç´¢å¼•ï¼Œç¡®ä¿ä½¿ç”¨ä¸åŒçš„æ¨ç†ä¸Šä¸‹æ–‡

        println!("ğŸ”„ é‡‡æ ·å™¨çŠ¶æ€å·²å½»åº•é‡ç½® (RNG + batchç´¢å¼•)");
    }

    /// é‡‡æ ·å‡½æ•° - Nucleus(top-p) + top-k + temperature
    /// forbid_token: å¯é€‰ç¦æ­¢é‡‡æ ·çš„tokenï¼ˆå¦‚æŸäº›é˜¶æ®µçš„ç‰¹æ®Šç¬¦å·ï¼‰
    pub fn sample_logits(
        &mut self,
        logits: &[f32],
        args: &SamplerArgs,
        forbid_token: Option<usize>,
    ) -> usize {
        let mut rng_ref = self.rng.clone();
        self.sample_logits_with_rng(logits, args, forbid_token, &mut rng_ref)
    }

    /// ä½¿ç”¨æŒ‡å®šRNGçš„é‡‡æ ·å‡½æ•°
    pub fn sample_logits_with_rng(
        &self,
        logits: &[f32],
        args: &SamplerArgs,
        forbid_token: Option<usize>,
        rng: &mut Option<StdRng>,
    ) -> usize {
        let vocab_size = logits.len();
        if vocab_size == 0 {
            return 0;
        }

        // å¤åˆ¶ç´¢å¼•å¹¶å¯é€‰è¿‡æ»¤ç¦ç”¨token
        let mut indices: Vec<usize> = (0..vocab_size).collect();
        if let Some(ft) = forbid_token {
            indices.retain(|&i| i != ft);
        }
        if indices.is_empty() {
            return 0;
        }

        let temperature = args.temperature.max(0.1);
        let top_k = if args.top_k == 0 || args.top_k > indices.len() {
            indices.len()
        } else {
            args.top_k
        };
        let top_p = args.top_p.clamp(0.0, 1.0);

        // å¿«é€Ÿè·¯å¾„ï¼štop_k==1æˆ–top_pæå°ï¼Œç›´æ¥å–æœ€å¤§logitï¼ˆç¡®å®šæ€§é‡‡æ ·ï¼‰
        if top_k == 1 || top_p < 1e-4 {
            let mut best = indices[0];
            let mut best_val = f32::NEG_INFINITY;
            for &i in &indices {
                let v = logits[i];
                if v > best_val {
                    best_val = v;
                    best = i;
                }
            }
            return best;
        }

        // æŒ‰logitsé™åºæ’åºï¼ˆä¸softmaxæ’åºä¸€è‡´ï¼‰
        indices.sort_by(|&a, &b| {
            logits[b]
                .partial_cmp(&logits[a])
                .unwrap_or(std::cmp::Ordering::Equal)
        });
        if top_k < indices.len() {
            indices.truncate(top_k);
        }

        // æ•°å€¼ç¨³å®šçš„ softmaxï¼šå‡å»æœ€å¤§å€¼å¹¶clampæŒ‡æ•°åŒºé—´
        let inv_t = 1.0 / temperature;
        let scaled: Vec<f32> = indices.iter().map(|&i| logits[i] * inv_t).collect();
        let mut max_scaled = f32::NEG_INFINITY;
        for &v in &scaled {
            if v > max_scaled {
                max_scaled = v;
            }
        }
        let mut probs: Vec<f32> = scaled
            .into_iter()
            .map(|v| ((v - max_scaled).clamp(-80.0, 80.0)).exp())
            .collect();
        let mut sum: f32 = probs.iter().sum();
        if sum > 0.0 && sum.is_finite() {
            for p in &mut probs {
                *p /= sum;
            }
        } else {
            // é€€åŒ–ä¸ºå‡åŒ€åˆ†å¸ƒï¼ˆæç«¯æ•°å€¼æƒ…å†µä¸‹ï¼‰
            let uniform = 1.0 / (probs.len() as f32).max(1.0);
            probs.fill(uniform);
        }

        // top-pæˆªæ–­ï¼ˆåœ¨æ’åºåæ¦‚ç‡ç©ºé—´ä¸­ï¼‰
        if top_p < 1.0 {
            let mut cumsum = 0.0;
            let mut cutoff = probs.len();
            for (i, &p) in probs.iter().enumerate() {
                cumsum += p;
                if cumsum >= top_p {
                    cutoff = i + 1;
                    break;
                }
            }
            if cutoff < probs.len() {
                probs.truncate(cutoff);
                indices.truncate(cutoff);
            }
            // å†å½’ä¸€åŒ–
            sum = probs.iter().sum();
            if sum > 0.0 && sum.is_finite() {
                for p in &mut probs {
                    *p /= sum;
                }
            }
        }

        // æŒ‰æ¦‚ç‡é‡‡æ ·ï¼ˆæ”¯æŒç¡®å®šæ€§RNGï¼‰
        let r: f32 = if let Some(rng_ref) = rng {
            rng_ref.gen()
        } else {
            // å¦‚æœæ²¡æœ‰RNGï¼Œåˆ›å»ºä¸´æ—¶RNGè¿›è¡Œéšæœºé‡‡æ ·
            StdRng::from_entropy().gen()
        };
        let mut cumsum = 0.0;
        for (i, &p) in probs.iter().enumerate() {
            cumsum += p;
            if r <= cumsum {
                return indices[i];
            }
        }
        *indices.last().unwrap_or(&0)
    }
}
