use anyhow::Result;
use rand::rngs::StdRng;
use rand::SeedableRng;
use tracing::{debug, info, warn};
use web_rwkv::runtime::infer::{RnnInput, RnnInputBatch, RnnOption};

use crate::shared_runtime::TtsInferContext;

/// æ‰§è¡ŒZero-shotæ¨ç†ï¼ˆå¤åˆ¶æ™®é€šæ¨¡å¼ç»“æ„ä½†è·³è¿‡Global tokensç”Ÿæˆï¼‰
pub async fn execute_zero_shot_inference(
    infer_context: &TtsInferContext,
    request: crate::rwkv_sampler::TtsBatchRequest,
    text_tokens: Vec<i32>,
    rng: Option<rand::rngs::StdRng>,
) -> Result<(Vec<i32>, Vec<i32>)> {
    let request_id = &infer_context.request_id;
    info!("ğŸ¯ [{}] å¼€å§‹Zero-shotæ¨ç†ï¼ˆå¤åˆ¶æ™®é€šæ¨¡å¼ç»“æ„ï¼‰", request_id);

    // è·å–runtime
    let runtime = &infer_context.runtime;
    let state = &infer_context.state;
    let token_chunk_size = request.args.token_chunk_size;

    // === éªŒè¯å’Œè¯»å–é¢„æå–çš„éŸ³è‰²ç‰¹å¾ ===
    let ref_global = request
        .ref_global_tokens
        .as_ref()
        .ok_or_else(|| anyhow::anyhow!("Zero-shotæ¨¡å¼éœ€è¦é¢„æå–çš„global tokens"))?;
    let ref_semantic = request
        .ref_semantic_tokens
        .as_ref()
        .ok_or_else(|| anyhow::anyhow!("Zero-shotæ¨¡å¼éœ€è¦é¢„æå–çš„semantic tokens"))?;

    info!(
        "ğŸ¯ [{}] é¢„æå–éŸ³è‰²ç‰¹å¾: global tokens {} ä¸ª, semantic tokens {} ä¸ª",
        request_id,
        ref_global.len(),
        ref_semantic.len()
    );

    // ä¿®æ­£tokensèŒƒå›´ï¼Œç¡®ä¿åœ¨æœ‰æ•ˆèŒƒå›´å†…
    let corrected_global: Vec<i32> = ref_global.iter().map(|&t| t.clamp(0, 4095)).collect();
    let _corrected_semantic: Vec<i32> = ref_semantic.iter().map(|&t| t.clamp(0, 8192)).collect();

    if corrected_global != *ref_global {
        warn!("ğŸ”§ [{}] å·²ä¿®æ­£global tokensèŒƒå›´åˆ°[0..4096)", request_id);
    }
    if _corrected_semantic != *ref_semantic {
        warn!("ğŸ”§ [{}] å·²ä¿®æ­£semantic tokensèŒƒå›´åˆ°[0..8192]", request_id);
    }

    // === æ„å»ºè¾“å…¥åºåˆ—ï¼ˆåŒ…å«é¢„è¯»å–çš„semantic_tokensï¼‰===
    // æ„å»ºè¾“å…¥åºåˆ—ï¼šå±æ€§tokens + TTS_TAG_2 + æ–‡æœ¬tokens + TTS_TAG_0 + global_tokens + TTS_TAG_1 + semantic_tokens
    let mut input_tokens: Vec<i32> = Vec::new();
    input_tokens.push(crate::rwkv_sampler::TTS_TAG_2);
    input_tokens.extend_from_slice(&text_tokens);
    input_tokens.push(crate::rwkv_sampler::TTS_TAG_0);
    // åŠ å…¥é¢„è¯»å–çš„global tokensï¼ˆæ·»åŠ åç§»ï¼‰
    for &token in &corrected_global {
        input_tokens.push(token + crate::rwkv_sampler::GLOBAL_TOKEN_OFFSET);
    }
    input_tokens.push(crate::rwkv_sampler::TTS_TAG_1);
    // åŠ å…¥é¢„è¯»å–çš„semantic tokens
    input_tokens.extend_from_slice(&_corrected_semantic);

    // === Prefill é˜¶æ®µï¼ˆå¤åˆ¶æ™®é€šæ¨¡å¼ï¼‰===
    let input_tokens_u32: Vec<u32> = input_tokens.iter().map(|&t| t as u32).collect();

    info!("ğŸ”§ [{}] Prefillé˜¶æ®µ - åˆå§‹åŒ–ç‹¬ç«‹çŠ¶æ€", request_id);

    // åˆ›å»ºç‹¬ç«‹çš„æ¨ç†ä¸Šä¸‹æ–‡
    let batch = RnnInputBatch::new(input_tokens_u32.clone(), RnnOption::Last);
    let mut inference = RnnInput::new(vec![batch], token_chunk_size);

    // ä¸ºæ‰¹å¤„ç†æ§½ä½0åŠ è½½åˆå§‹çŠ¶æ€ï¼Œç¡®ä¿çŠ¶æ€éš”ç¦»
    {
        let initial_state = state.lock().await.init();
        state.lock().await.load(initial_state, 0)?;
        info!("ğŸ”§ [{}] å·²ä¸ºæ‰¹å¤„ç†æ§½ä½0åŠ è½½åˆå§‹çŠ¶æ€", request_id);
    }

    // æ¶ˆåŒ–è¾“å…¥ç›´åˆ°äº§ç”Ÿè¾“å‡º
    let _last_logits: Vec<f32> = loop {
        let (remaining_input, output) = runtime.infer(inference.clone()).await?;
        inference = remaining_input;
        if !output.is_empty() && output[0].0.size() > 0 {
            break output[0].0.clone().to_vec();
        }
    };

    // === Global é˜¶æ®µï¼šè·³è¿‡ç”Ÿæˆï¼Œç›´æ¥ä½¿ç”¨é¢„æå–çš„tokens ===
    let global_tokens: Vec<i32> = corrected_global.clone();
    let mut semantic_tokens: Vec<i32> = Vec::new();

    info!(
        "âœ… [{}] è·³è¿‡Global tokensç”Ÿæˆï¼Œç›´æ¥ä½¿ç”¨é¢„æå–çš„tokens: {:?} (å…±{}ä¸ª)",
        request_id,
        global_tokens,
        global_tokens.len()
    );

    // å°†é¢„æå–çš„global tokensåé¦ˆåˆ°æ¨¡å‹ï¼ˆä¸åŠ åç§»é‡ï¼Œä¸æ™®é€šæ¨¡å¼ä¸€è‡´ï¼‰
    for &token in &global_tokens {
        inference.batches[0].push(token as u32);
    }

    info!("ğŸ”§ [{}] å·²å°†é¢„æå–çš„global tokensåé¦ˆåˆ°æ¨¡å‹", request_id);

    // === åˆ‡æ¢åˆ° Semantic é˜¶æ®µï¼ˆå¤åˆ¶æ™®é€šæ¨¡å¼ç»“æ„ï¼‰===
    inference.batches[0].push(crate::rwkv_sampler::TTS_TAG_1 as u32);
    info!(
        "ğŸ” [{}] åˆ‡æ¢åˆ°Semanticé˜¶æ®µï¼Œæ¨å…¥TTS_TAG_1={}",
        request_id,
        crate::rwkv_sampler::TTS_TAG_1
    );

    // è®©æ ‡ç­¾ç”Ÿæ•ˆï¼Œç›´åˆ°äº§ç”Ÿè¾“å‡ºï¼Œå¹¶ä¿ç•™logitsä¾›é¦–æ­¥ä½¿ç”¨
    let last_sem_logits: Vec<f32> = loop {
        let (next_inference, output) = runtime.infer(inference).await?;
        inference = next_inference;
        if output[0].0.size() > 0 {
            break output[0].0.clone().to_vec();
        }
    };

    // === Semantic tokens ç”Ÿæˆé˜¶æ®µï¼ˆå¤åˆ¶æ™®é€šæ¨¡å¼å‚æ•°å’Œé€»è¾‘ï¼‰===
    let semantic_limit: usize = usize::min(request.args.max_tokens, 2048);
    let mut args_semantic = request.args.clone();

    // Semanticé˜¶æ®µä½¿ç”¨å›ºå®šå‚æ•°ï¼Œä¸Pythonä»£ç ä¿æŒä¸¥æ ¼ä¸€è‡´
    args_semantic.temperature = 1.0;
    args_semantic.top_p = 0.95;
    args_semantic.top_k = 80;

    info!(
        "ğŸ” [{}] å¼€å§‹ç”Ÿæˆsemantic tokensï¼Œæœ€å¤§é™åˆ¶: {}",
        request_id, semantic_limit
    );
    info!(
        "ğŸ” [{}] Semanticé˜¶æ®µé‡‡æ ·å‚æ•°: temperature={:.2}, top_p={:.2}, top_k={} (å›ºå®šå‚æ•°ï¼Œä¸Pythonä¸€è‡´)",
        request_id, args_semantic.temperature, args_semantic.top_p, args_semantic.top_k
    );

    // åˆ›å»ºç‹¬ç«‹çš„RNGç”¨äºsemanticé˜¶æ®µ
    // å£°éŸ³å…‹éš†åœºæ™¯ä¹Ÿæ”¯æŒéšæœºé‡‡æ ·ï¼Œæ ¹æ®seedå‚æ•°å†³å®šé‡‡æ ·æ–¹å¼
    let mut semantic_rng = if let Some(rng_instance) = rng {
        if request.args.layered_randomness.use_independent_seeds {
            if let Some(seed) = request.args.seed {
                // ç”¨æˆ·æä¾›äº†seedï¼Œä½¿ç”¨ç¡®å®šæ€§é‡‡æ ·
                Some(StdRng::seed_from_u64(seed.wrapping_add(
                    request.args.layered_randomness.semantic_seed_offset,
                )))
            } else {
                // æ²¡æœ‰seedï¼Œä½¿ç”¨ä¼ å…¥çš„RNG
                Some(rng_instance)
            }
        } else {
            Some(rng_instance)
        }
    } else {
        // å³ä½¿rngä¸ºNoneï¼Œä¹Ÿåˆ›å»ºæ–°çš„RNGç”¨äºéšæœºé‡‡æ ·ï¼ˆé™¤éç”¨æˆ·æ˜ç¡®æŒ‡å®šseedï¼‰
        if let Some(seed) = request.args.seed {

            Some(StdRng::seed_from_u64(seed.wrapping_add(
                request.args.layered_randomness.semantic_seed_offset,
            )))
        } else {

            Some(StdRng::from_entropy())
        }
    };

    for i in 0..semantic_limit {
        let logits: Vec<f32> = if i == 0 {
            last_sem_logits.clone()
        } else {
            loop {
                let (next_inference, output) = runtime.infer(inference.clone()).await?;
                inference = next_inference;
                if output[0].0.size() > 0 {
                    break output[0].0.clone().to_vec();
                }
            }
        };

        // è¯­ä¹‰é˜¶æ®µä»…é‡‡æ · [0..8192]ï¼ˆåŒ…å«EOSï¼‰ï¼Œå±è”½TTS_TAG_*ä¸å…¶å®ƒåŸŸ
        let mut logits_masked = logits.clone();
        // ä¿®å¤ï¼šä¸å±è”½EOS tokenï¼Œåªå±è”½å¤§äºEOS tokençš„éƒ¨åˆ†
        for (j, v) in logits_masked.iter_mut().enumerate() {
            if j > crate::rwkv_sampler::TTS_EOS_TOKEN as usize {
                *v = f32::NEG_INFINITY;
            }
        }
        // å±è”½TTS_TAG tokensï¼Œä½†ä¿ç•™EOS token
        for tag in [
            crate::rwkv_sampler::TTS_TAG_0,
            crate::rwkv_sampler::TTS_TAG_1,
            crate::rwkv_sampler::TTS_TAG_2,
        ] {
            let idx = tag as usize;
            if idx < logits_masked.len() {
                logits_masked[idx] = f32::NEG_INFINITY;
            }
        }


        // ç›´æ¥ä½¿ç”¨å±è”½åçš„logitsè¿›è¡Œé‡‡æ ·
        let next_id = crate::rwkv_sampler::sample_logits(
            &logits_masked,
            &args_semantic,
            None,
            &mut semantic_rng,
        );


        // æ£€æŸ¥æ˜¯å¦é‡åˆ°EOS tokenï¼ˆå¿…é¡»åœ¨èŒƒå›´æ£€æŸ¥ä¹‹å‰ï¼‰
        if next_id == crate::rwkv_sampler::TTS_EOS_TOKEN as usize {
            break;
        }

        // é¢å¤–æ£€æŸ¥ï¼šç¡®ä¿tokenåœ¨semanticèŒƒå›´å†… [0..8192)ï¼ˆä¿®å¤ï¼šåº”è¯¥æ˜¯>8192è€Œä¸æ˜¯>=8192ï¼‰
        if next_id > crate::rwkv_sampler::TTS_EOS_TOKEN as usize {
            warn!(
                "ğŸš¨ [{}] Token {} è¶…å‡ºsemanticèŒƒå›´[0..8192]ï¼Œè·³è¿‡æ­¤token",
                request_id, next_id
            );
            continue;
        }

        semantic_tokens.push(next_id as i32);

        // åé¦ˆåˆ°æ¨¡å‹ï¼šè¯­ä¹‰é˜¶æ®µç›´æ¥ä½¿ç”¨åŸå§‹tokenï¼ˆä¸åŠ åç§»ï¼‰
        inference.batches[0].push(next_id as u32);
    }
    // è¿”å›é¢„æå–çš„global tokenså’Œæ–°ç”Ÿæˆçš„semantic tokensï¼ˆå·²æ’é™¤é¢„è¯»å–çš„semantic tokensï¼‰
    Ok((global_tokens, semantic_tokens))
}
