use anyhow::Result;
use rand::rngs::StdRng;
use rand::SeedableRng;
use tracing::warn;
use web_rwkv::runtime::infer::{RnnInput, RnnInputBatch, RnnOption};

use crate::shared_runtime::TtsInferContext;

/// æ‰§è¡ŒZero-shotæ¨ç†
pub async fn execute_zero_shot_inference(
    infer_context: TtsInferContext,
    text_tokens: Vec<i32>,
    property_tokens: Vec<i32>,
    rng: rand::rngs::StdRng,
    request: &crate::rwkv_sampler::TtsBatchRequest,
) -> Result<(Vec<i32>, Vec<i32>)> {
    let request_id = &infer_context.request_id;
    // å¼€å§‹Zero-shotæ¨ç†

    // Acquire runtime semaphore for the entire inference to ensure isolation
    let _runtime_permit = infer_context
        .runtime_semaphore
        .acquire()
        .await
        .map_err(|e| anyhow::anyhow!("æ— æ³•è·å–è¿è¡Œæ—¶ä¿¡å·é‡: {}", e))?;

    // å·²è·å–ä¿¡å·é‡è®¸å¯ï¼Œå¼€å§‹æ¨ç†

    // è·å–runtime
    let runtime = &infer_context.runtime;
    let state = &infer_context.state;
    let token_chunk_size = infer_context.options.token_chunk_size;

    // === éªŒè¯å’Œè¯»å–é¢„æå–çš„éŸ³è‰²ç‰¹å¾ ===
    let ref_global = request
        .ref_global_tokens
        .as_ref()
        .ok_or_else(|| anyhow::anyhow!("Zero-shotæ¨¡å¼éœ€è¦é¢„æå–çš„global tokens"))?;
    let ref_semantic = request
        .ref_semantic_tokens
        .as_ref()
        .ok_or_else(|| anyhow::anyhow!("Zero-shotæ¨¡å¼éœ€è¦é¢„æå–çš„semantic tokens"))?;

    // æ–‡æœ¬tokensä¿¡æ¯

    // ä¿®æ­£tokensèŒƒå›´ï¼Œç¡®ä¿åœ¨æœ‰æ•ˆèŒƒå›´å†…
    let corrected_global: Vec<i32> = ref_global.iter().map(|&t| t.clamp(0, 4095)).collect();
    let mut _corrected_semantic: Vec<i32> =
        ref_semantic.iter().map(|&t| t.clamp(0, 8192)).collect();

    // ä¿®å¤ï¼šç§»é™¤å‚è€ƒè¯­ä¹‰tokensæœ«å°¾çš„EOSï¼Œé¿å…æ¨¡å‹åœ¨ç”Ÿæˆé˜¶æ®µç«‹å³ç»“æŸ
    let original_sem_len = _corrected_semantic.len();
    while let Some(&last) = _corrected_semantic.last() {
        if last == crate::rwkv_sampler::TTS_EOS_TOKEN {
            _corrected_semantic.pop();
        } else {
            break;
        }
    }
    let trimmed_count = original_sem_len.saturating_sub(_corrected_semantic.len());
    if trimmed_count > 0 {
        warn!(
            "ğŸ”§ [{}] å‚è€ƒsemanticæœ«å°¾EOSå·²ç§»é™¤ {} ä¸ªï¼Œé˜²æ­¢æ—©åœ",
            request_id, trimmed_count
        );
    }

    if corrected_global != *ref_global {
        warn!("ğŸ”§ [{}] å·²ä¿®æ­£global tokensèŒƒå›´åˆ°[0..4096)", request_id);
    }
    if _corrected_semantic != *ref_semantic {
        warn!("ğŸ”§ [{}] å·²ä¿®æ­£semantic tokensèŒƒå›´åˆ°[0..8192]", request_id);
    }

    // æ„å»ºè¾“å…¥åºåˆ—ï¼šå±æ€§tokens + TTS_TAG_2 + æ–‡æœ¬tokens + TTS_TAG_0
    let mut input_tokens: Vec<i32> = Vec::new();
    input_tokens.extend_from_slice(&property_tokens);
    input_tokens.push(crate::rwkv_sampler::TTS_TAG_2);
    input_tokens.extend_from_slice(&text_tokens);
    input_tokens.push(crate::rwkv_sampler::TTS_TAG_0);
    // åŠ å…¥é¢„è¯»å–çš„global tokensï¼ˆæ·»åŠ åç§»ï¼‰
    for &token in &corrected_global {
        input_tokens.push(token + crate::rwkv_sampler::GLOBAL_TOKEN_OFFSET);
    }
    input_tokens.push(crate::rwkv_sampler::TTS_TAG_1);
    // è·¨è¯­è¨€å…‹éš†ï¼šè·³è¿‡å‚è€ƒè¯­ä¹‰é¢„å¡«ï¼Œä»…ä¿ç•™global tokenså½±å“éŸ³è‰²
    // è¯´æ˜ï¼šå‚è€ƒè¯­ä¹‰é€šå¸¸å¼ºç»‘å®šåŸè¯­è¨€å†…å®¹ï¼Œé¢„å¡«ä¼šå¯¼è‡´ç»§ç»­åŸè¯­ç§ï¼Œä¸åˆ©äºè·¨è¯­è¨€
    log::info!(
        "ğŸŒ [{}] è·¨è¯­è¨€å…‹éš†æ¨¡å¼ï¼šç¦ç”¨å‚è€ƒsemanticé¢„å¡«ï¼Œä»…ä½¿ç”¨global tokensç»´æŒéŸ³è‰²",
        request_id
    );

    // === Prefill é˜¶æ®µï¼ˆå¤åˆ¶æ™®é€šæ¨¡å¼ï¼‰===
    let input_tokens_u32: Vec<u32> = input_tokens.iter().map(|&t| t as u32).collect();

    // Prefillé˜¶æ®µ - åˆå§‹åŒ–ç‹¬ç«‹çŠ¶æ€

    // åˆ›å»ºç‹¬ç«‹çš„æ¨ç†ä¸Šä¸‹æ–‡
    let batch = RnnInputBatch::new(input_tokens_u32.clone(), RnnOption::Last);
    let mut inference = RnnInput::new(vec![batch], token_chunk_size);

    // ä¸ºæ‰¹å¤„ç†æ§½ä½0åŠ è½½åˆå§‹çŠ¶æ€ï¼Œç¡®ä¿çŠ¶æ€éš”ç¦»ï¼ˆä¼˜åŒ–ï¼šåˆå¹¶äºŒæ¬¡é”æ“ä½œï¼‰
    {
        let state_guard = state.lock().await;
        let initial_state = state_guard.init();
        state_guard.load(initial_state, 0)?;
        drop(state_guard); // æ˜¾å¼é‡Šæ”¾é”
                           // å·²ä¸ºæ‰¹å¤„ç†æ§½ä½0åŠ è½½åˆå§‹çŠ¶æ€
    }

    // æ¶ˆåŒ–è¾“å…¥ç›´åˆ°äº§ç”Ÿè¾“å‡º
    let last_sem_logits_prefill: Vec<f32> = loop {
        let (remaining_input, output) = runtime.infer(inference.clone()).await?;
        inference = remaining_input;
        if !output.is_empty() && output[0].0.size() > 0 {
            break output[0].0.clone().to_vec();
        }
    };

    // é¢„å¡«å®Œæˆåï¼Œç›´æ¥åœ¨è¯­ä¹‰åŸŸç»§ç»­é‡‡æ ·ï¼ˆä¸å†é‡å¤æ³¨å…¥globalæˆ–æ ‡ç­¾ï¼‰
    let global_tokens: Vec<i32> = corrected_global.clone();
    let mut semantic_tokens: Vec<i32> = Vec::new();
    let last_sem_logits: Vec<f32> = last_sem_logits_prefill;

    // === Semantic tokens ç”Ÿæˆé˜¶æ®µï¼ˆå¤åˆ¶æ™®é€šæ¨¡å¼å‚æ•°å’Œé€»è¾‘ï¼‰===
    let semantic_limit: usize = usize::min(2048, 2048);
    // åŠ å…¥æœ€å°ç”Ÿæˆé•¿åº¦çº¦æŸï¼ˆåŠ¨æ€ï¼‰ï¼šæŒ‰æ–‡æœ¬é•¿åº¦è‡ªé€‚åº”ï¼Œé¿å…é¦–æ­¥é‡‡åˆ°EOSå¯¼è‡´è¯­ä¹‰åºåˆ—ä¸ºç©º
    let min_semantic_len: usize = {
        let tlen = text_tokens.len();
        // ç»éªŒï¼šè¯­ä¹‰tokençº¦ä¸ºæ–‡æœ¬tokençš„1/4ï½1/2ï¼Œè¿™é‡Œå–ä¿å®ˆçš„1/4
        // ä¸‹é™8ï¼Œä¸Šé™64ï¼Œå…¼é¡¾çŸ­æ–‡æœ¬ä¸é•¿æ–‡æœ¬
        tlen.saturating_div(4).clamp(8, 64)
    };
    // åŸºäºæ–‡æœ¬é•¿åº¦çš„â€œç¡¬ä¸‹é™â€ï¼Œåœ¨è¾¾åˆ°è¯¥é•¿åº¦å‰ä¸€å¾‹ç¦æ­¢EOS
    // ç»éªŒåˆå€¼ï¼šè¯­ä¹‰è‡³å°‘ä¸ºæ–‡æœ¬tokençš„1.8å€ï¼Œé¿å…è¿˜æ²¡è¯»å®Œå°±æ—©åœ
    let hard_min_semantic_len: usize = {
        let tlen = text_tokens.len();
        let est = ((tlen as f32) * 1.8).ceil() as usize;
        // ä¸è¶…è¿‡è¯­ä¹‰ä¸Šé™çš„90%ï¼Œé¿å…è¿‡é•¿
        let upper = (semantic_limit as f32 * 0.9).floor() as usize;
        std::cmp::min(upper, std::cmp::max(min_semantic_len, est))
    };
    log::info!(
        "ğŸ›¡ï¸ [{}] Zero-shotæœ€å°è¯­ä¹‰é•¿åº¦: åŠ¨æ€={}ï¼Œç¡¬ä¸‹é™={} (text_tokens={})",
        request_id,
        min_semantic_len,
        hard_min_semantic_len,
        text_tokens.len()
    );

    // Zero-shotæ¨¡å¼ï¼šè·³è¿‡Globalé˜¶æ®µï¼Œç›´æ¥ä½¿ç”¨é¢„æå–çš„global_tokens
    // è®¾ç½®Semanticé˜¶æ®µé‡‡æ ·å‚æ•°
    let args_semantic = crate::rwkv_sampler::SamplerArgs {
        temperature: 1.0, // Semanticé˜¶æ®µä½¿ç”¨å›ºå®šå‚æ•°
        top_p: 0.95,
        top_k: 80,
        seed: infer_context.options.seed,
        max_tokens: 2048,
        voice_fidelity: infer_context.options.voice_fidelity,
        layered_randomness: infer_context.options.layered_randomness.clone(),
        token_chunk_size: infer_context.options.token_chunk_size,
    };

    // å‚æ•°å¯¹æ¯”æ‰“å°ï¼šPython vs Rust (Zero-shotæ¨¡å¼)
    log::info!(
        "ğŸ” [{}] Zero-shotæ¨¡å¼é‡‡æ ·å‚æ•°å¯¹æ¯” (Python vs Rust):",
        request_id
    );
    log::info!("   ğŸ“Š Semanticé˜¶æ®µ:");
    log::info!("      Python: temperature=1.0, top_p=0.95, top_k=80");
    log::info!(
        "      Rust:   temperature={:.1}, top_p={:.2}, top_k={}",
        args_semantic.temperature,
        args_semantic.top_p,
        args_semantic.top_k
    );

    // éªŒè¯å‚æ•°ä¸€è‡´æ€§
    let semantic_match = (args_semantic.temperature - 1.0).abs() < 0.001
        && (args_semantic.top_p - 0.95).abs() < 0.001
        && args_semantic.top_k == 80;

    if semantic_match {
        log::info!(
            "âœ… [{}] Zero-shot Semanticå‚æ•°å®Œå…¨åŒ¹é…Pythonç‰ˆæœ¬ï¼",
            request_id
        );
    } else {
        log::warn!(
            "âš ï¸ [{}] Zero-shot Semanticå‚æ•°ä¸Pythonç‰ˆæœ¬ä¸åŒ¹é…ï¼",
            request_id
        );
    }

    // å¼€å§‹ç”Ÿæˆsemantic tokens
    println!(
        "ğŸ¯ [{}] Zero-shotæ¨¡å¼å¼€å§‹ç”ŸæˆSemantic tokensï¼Œæœ€å¤§æ•°é‡: {}",
        request_id, semantic_limit
    );

    // ç®€åŒ–é‡‡æ ·ï¼Œç§»é™¤ä¼˜åŒ–ç»„ä»¶

    // åˆ›å»ºç‹¬ç«‹çš„RNGç”¨äºsemanticé˜¶æ®µ
    let semantic_rng = if args_semantic.layered_randomness.use_independent_seeds {
        if let Some(seed) = args_semantic.seed {
            // ç”¨æˆ·æä¾›äº†seedï¼Œä½¿ç”¨ç¡®å®šæ€§é‡‡æ ·
            StdRng::seed_from_u64(
                seed.wrapping_add(args_semantic.layered_randomness.semantic_seed_offset),
            )
        } else {
            // ç”¨æˆ·æ²¡æœ‰æä¾›seedï¼Œä½¿ç”¨éšæœºé‡‡æ ·
            StdRng::from_rng(rand::thread_rng()).expect("failed to seed StdRng")
        }
    } else {
        rng
    };

    let mut semantic_rng_opt = Some(semantic_rng);
    // EOSå…è®¸é˜ˆå€¼åˆ¤å®šï¼šæœ€è¿‘Næ­¥éEOSæ¯”ä¾‹è¾¾åˆ°é˜ˆå€¼æ‰å…è®¸EOS
    let eos_window: usize = 12;
    let eos_ratio_threshold: f32 = 0.7;
    let mut recent_non_eos: Vec<bool> = Vec::with_capacity(eos_window);
    for i in 0..semantic_limit {
        let logits: Vec<f32> = if i == 0 {
            last_sem_logits.clone()
        } else {
            loop {
                let (next_inference, output) = runtime.infer(inference.clone()).await?;
                inference = next_inference;
                if output[0].0.size() > 0 {
                    break output[0].0.clone().to_vec();
                }
            }
        };

        // è¯­ä¹‰é˜¶æ®µä»…é‡‡æ · [0..8192]ï¼ˆåŒ…å«EOSï¼‰ï¼Œå±è”½TTS_TAG_*ä¸å…¶å®ƒåŸŸ
        let mut logits_masked = logits.clone();
        // ä¿®å¤ï¼šä¸å±è”½EOS tokenï¼Œåªå±è”½å¤§äºEOS tokençš„éƒ¨åˆ†
        for (j, v) in logits_masked.iter_mut().enumerate() {
            if j > crate::rwkv_sampler::TTS_EOS_TOKEN as usize {
                *v = f32::NEG_INFINITY;
            }
        }
        // å±è”½TTS_TAG tokensï¼Œä½†ä¿ç•™EOS token
        for tag in [
            crate::rwkv_sampler::TTS_TAG_0,
            crate::rwkv_sampler::TTS_TAG_1,
            crate::rwkv_sampler::TTS_TAG_2,
        ] {
            let idx = tag as usize;
            if idx < logits_masked.len() {
                logits_masked[idx] = f32::NEG_INFINITY;
            }
        }

        // åœ¨æœ€å°é•¿åº¦å†…ç¦æ­¢EOSï¼Œç¡®ä¿è‡³å°‘ç”Ÿæˆè‹¥å¹²è¯­ä¹‰tokens
        let eos_idx = crate::rwkv_sampler::TTS_EOS_TOKEN as usize;
        // è¾¾åˆ°â€œç¡¬ä¸‹é™â€ä¹‹å‰ä¸€å¾‹ç¦æ­¢EOS
        if i < hard_min_semantic_len && eos_idx < logits_masked.len() {
            logits_masked[eos_idx] = f32::NEG_INFINITY;
        }

        // ä½¿ç”¨ç®€å•é‡‡æ ·å™¨é‡‡æ ·
        let mut next_id = crate::rwkv_sampler::sample_logits(
            &logits_masked,
            &args_semantic,
            None, // forbid_token
            &mut semantic_rng_opt,
        );

        // æ£€æŸ¥æ˜¯å¦é‡åˆ°EOS tokenï¼ˆå¿…é¡»åœ¨èŒƒå›´æ£€æŸ¥ä¹‹å‰ï¼‰
        if next_id == crate::rwkv_sampler::TTS_EOS_TOKEN as usize {
            // é˜ˆå€¼åˆ¤å®šï¼šæœ€è¿‘Næ­¥éEOSæ¯”ä¾‹è¾¾åˆ°é˜ˆå€¼æ‰å…è®¸EOS
            let window_len = recent_non_eos.len();
            let non_eos_count = recent_non_eos.iter().filter(|&&b| b).count();
            let ratio = if window_len > 0 {
                non_eos_count as f32 / window_len as f32
            } else {
                0.0
            };
            let allow_eos = window_len >= eos_window && ratio >= eos_ratio_threshold;
            if allow_eos {
                log::info!(
                    "ğŸ›‘ [{}] å…è®¸EOSç»“æŸï¼šrecent_non_eos_ratio={:.2}, window={}",
                    request_id,
                    ratio,
                    window_len
                );
                break;
            } else {
                log::info!(
                    "â­ï¸ [{}] é˜»æ­¢EOSï¼šrecent_non_eos_ratio={:.2}, window={}ï¼›ç»§ç»­é‡‡æ ·",
                    request_id,
                    ratio,
                    window_len
                );
                // å±è”½EOSåé‡æ–°é‡‡æ ·
                let eos_idx2 = crate::rwkv_sampler::TTS_EOS_TOKEN as usize;
                if eos_idx2 < logits_masked.len() {
                    logits_masked[eos_idx2] = f32::NEG_INFINITY;
                }
                next_id = crate::rwkv_sampler::sample_logits(
                    &logits_masked,
                    &args_semantic,
                    None,
                    &mut semantic_rng_opt,
                );
            }
        }

        // é¢å¤–æ£€æŸ¥ï¼šç¡®ä¿tokenåœ¨semanticèŒƒå›´å†… [0..8192)ï¼ˆä¿®å¤ï¼šåº”è¯¥æ˜¯>8192è€Œä¸æ˜¯>=8192ï¼‰
        if next_id > crate::rwkv_sampler::TTS_EOS_TOKEN as usize {
            warn!(
                "ğŸš¨ [{}] Token {} è¶…å‡ºsemanticèŒƒå›´[0..8192]ï¼Œåœæ­¢ç”Ÿæˆä»¥ç¡®ä¿ç¨³å®šæ€§",
                request_id, next_id
            );
            break;
        }

        // ç»´æŠ¤æœ€è¿‘Næ­¥éEOSæ¯”ä¾‹çª—å£
        let is_non_eos = next_id != crate::rwkv_sampler::TTS_EOS_TOKEN as usize;
        recent_non_eos.push(is_non_eos);
        if recent_non_eos.len() > eos_window {
            // ç§»é™¤æœ€æ—©çš„ä¸€é¡¹ï¼ˆçª—å£å›ºå®šé•¿åº¦ï¼‰
            recent_non_eos.remove(0);
        }

        semantic_tokens.push(next_id as i32);

        // åé¦ˆåˆ°æ¨¡å‹ï¼šè¯­ä¹‰é˜¶æ®µç›´æ¥ä½¿ç”¨åŸå§‹tokenï¼ˆä¸åŠ åç§»ï¼‰
        inference.batches[0].push(next_id as u32);

        // æ‰“å°å½“å‰ç”Ÿæˆè¿›åº¦
        if (i + 1) % 16 == 0 || i == semantic_limit - 1 {
            println!(
                "ğŸ“Š [{}] Zero-shot Semanticé˜¶æ®µ: å·²ç”Ÿæˆ {}/{} tokens",
                request_id,
                i + 1,
                semantic_limit
            );
        }
    }
    // å›é€€é€»è¾‘ï¼šå¦‚æœè¯­ä¹‰ä¸ºç©ºï¼ˆå¯èƒ½é¦–æ­¥é‡‡åˆ°äº†EOSï¼‰ï¼Œå¼ºåˆ¶ä»prefillçš„logitsé‡‡æ ·è‡³å°‘1ä¸ªtoken
    if semantic_tokens.is_empty() {
        warn!(
            "âš ï¸ [{}] Zero-shotè¯­ä¹‰åºåˆ—ä¸ºç©ºï¼Œåº”ç”¨å›é€€é‡‡æ ·ç¡®ä¿è‡³å°‘1ä¸ªtoken",
            request_id
        );
        let mut logits_masked = last_sem_logits.clone();
        let eos_idx = crate::rwkv_sampler::TTS_EOS_TOKEN as usize;
        if eos_idx < logits_masked.len() {
            logits_masked[eos_idx] = f32::NEG_INFINITY;
        }
        let next_id = crate::rwkv_sampler::sample_logits(
            &logits_masked,
            &args_semantic,
            None,
            &mut semantic_rng_opt,
        );
        if next_id <= crate::rwkv_sampler::TTS_EOS_TOKEN as usize {
            semantic_tokens.push(next_id as i32);
            inference.batches[0].push(next_id as u32);
        }
    }
    // TTS tokensç”Ÿæˆå®Œæˆ
    println!(
        "âœ… [{}] Zero-shot TTSç”Ÿæˆå®Œæˆ - Global tokens: {}, Semantic tokens: {}",
        request_id,
        global_tokens.len(),
        semantic_tokens.len()
    );
    Ok((global_tokens, semantic_tokens))
}
