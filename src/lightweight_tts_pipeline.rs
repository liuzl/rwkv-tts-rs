//! è½»é‡çº§TTSæµæ°´çº¿
//! å¤ç”¨å…¨å±€èµ„æºï¼Œä¸å†æ¯æ¬¡åˆ›å»ºæ–°çš„æ¨¡å‹å®ä¾‹

use crate::{
    dynamic_batch_manager::get_global_dynamic_batch_manager,
    onnx_session_pool::get_global_onnx_manager,
    properties_util,
    rwkv_sampler::{SamplerArgs, TtsBatchRequest},
};
use anyhow::Result;
use ndarray::{Array1, Array2, Array3};
use ort::{session::SessionInputValue, value::Value};
use std::path::Path;

/// è½»é‡çº§TTSæµæ°´çº¿å‚æ•°
#[derive(Debug, Clone)]
pub struct LightweightTtsPipelineArgs {
    pub text: String,
    pub temperature: f32,
    pub top_p: f32,
    pub top_k: usize,
    pub max_tokens: usize,
    pub age: String,
    pub gender: String,
    pub emotion: String,
    pub pitch: f32,
    pub speed: f32,
    pub zero_shot: bool,
    pub ref_audio_path: String,
    pub prompt_text: String,
    pub output_path: String,
    pub validate: bool,
    pub seed: Option<u64>,
}

impl Default for LightweightTtsPipelineArgs {
    fn default() -> Self {
        Self {
            text: String::new(),
            temperature: 1.0,
            top_p: 0.90,
            top_k: 0,
            max_tokens: 8000,
            age: "youth-adult".to_string(),
            gender: "female".to_string(),
            emotion: "NEUTRAL".to_string(),
            pitch: 200.0,
            speed: 4.2,
            zero_shot: false,
            ref_audio_path: String::new(),
            prompt_text: String::new(),
            output_path: String::from("./output"),
            validate: false,
            seed: None,
        }
    }
}

/// è½»é‡çº§TTSæµæ°´çº¿ï¼Œå¤ç”¨å…¨å±€èµ„æº
#[derive(Debug)]
pub struct LightweightTtsPipeline {}

impl LightweightTtsPipeline {
    /// åˆ›å»ºæ–°çš„è½»é‡çº§TTSæµæ°´çº¿
    pub fn new() -> Self {
        Self {}
    }

    /// å¤„ç†æ–‡æœ¬
    fn process_text(&self, text: &str) -> String {
        text.to_string()
    }

    /// ç”ŸæˆTTSå±æ€§tokens
    fn generate_property_tokens(&self, args: &LightweightTtsPipelineArgs) -> Vec<i32> {
        if args.zero_shot {
            vec![] // Zero-shotæ¨¡å¼ä¸‹ç”±å‚è€ƒéŸ³é¢‘å¤„ç†
        } else {
            let age_num = args.age.parse::<u8>().unwrap_or(25);
            properties_util::convert_properties_to_tokens(
                args.speed,
                args.pitch,
                age_num,
                &args.gender,
                &args.emotion,
            )
        }
    }

    /// å¤„ç†å‚è€ƒéŸ³é¢‘ï¼ˆZero-shotæ¨¡å¼ï¼‰
    async fn process_reference_audio(&self, ref_audio_path: &str) -> Result<(Vec<i32>, Vec<i32>)> {
        if ref_audio_path.is_empty() || !Path::new(ref_audio_path).exists() {
            return Err(anyhow::anyhow!("å‚è€ƒéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {}", ref_audio_path));
        }

        let onnx_manager = get_global_onnx_manager()?;

        // åŠ è½½éŸ³é¢‘æ–‡ä»¶
        let audio_data = self.load_audio_file(ref_audio_path).await?;

        // ä½¿ç”¨BiCodec Tokenizeä¼šè¯
        let bicodec_session = onnx_manager.acquire_bicodec_tokenize_session().await?;
        let (global_tokens, semantic_tokens) = self
            .tokenize_audio_with_session(&audio_data, bicodec_session)
            .await?;

        Ok((global_tokens, semantic_tokens))
    }

    /// åŠ è½½éŸ³é¢‘æ–‡ä»¶
    async fn load_audio_file(&self, audio_path: &str) -> Result<Vec<f32>> {
        use hound::WavReader;
        use std::path::Path;

        if !Path::new(audio_path).exists() {
            return Err(anyhow::anyhow!("éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {}", audio_path));
        }

        let audio_path = audio_path.to_string();
        let result = tokio::task::spawn_blocking(move || -> Result<Vec<f32>> {
            let mut reader = WavReader::open(&audio_path)?;
            let spec = reader.spec();

            // è¯»å–éŸ³é¢‘æ ·æœ¬å¹¶è½¬æ¢ä¸ºf32
            let samples: Result<Vec<f32>, _> = reader
                .samples::<i16>()
                .map(|s| s.map(|sample| sample as f32 / i16::MAX as f32))
                .collect();
            let mut audio = samples?;

            // è½¬æ¢ä¸ºå•å£°é“
            if spec.channels > 1 {
                let len = audio.len() / spec.channels as usize;
                let mut mono_audio = Vec::with_capacity(len);
                for i in 0..len {
                    mono_audio.push(audio[i * spec.channels as usize]);
                }
                audio = mono_audio;
            }

            // é‡é‡‡æ ·åˆ°16kHzï¼ˆç®€åŒ–å®ç°ï¼‰
            if spec.sample_rate != 16000 {
                let original_len = audio.len();
                let target_len = (original_len as f32 * 16000.0 / spec.sample_rate as f32) as usize;
                let mut resampled = Vec::with_capacity(target_len);
                for i in 0..target_len {
                    let idx = i * original_len / target_len;
                    resampled.push(audio[idx]);
                }
                audio = resampled;
            }

            Ok(audio)
        })
        .await??;

        Ok(result)
    }

    /// ä½¿ç”¨ONNXä¼šè¯è¿›è¡ŒéŸ³é¢‘tokenize
    async fn tokenize_audio_with_session(
        &self,
        audio_data: &[f32],
        mut session_guard: crate::onnx_session_pool::SessionGuard,
    ) -> Result<(Vec<i32>, Vec<i32>)> {
        let audio_data = audio_data.to_vec();
        let result = tokio::task::spawn_blocking(move || -> Result<(Vec<i32>, Vec<i32>)> {
            // è½¬æ¢éŸ³é¢‘æ•°æ®ä¸ºndarray
            let wav = Array1::from(audio_data);

            // æå–wav2vec2ç‰¹å¾ï¼ˆè¿™é‡Œéœ€è¦wav2vec2ä¼šè¯ï¼Œæš‚æ—¶ä½¿ç”¨ç®€åŒ–å¤„ç†ï¼‰
            let feature_dim = 1024;
            let t = wav.len() / 320; // å‡è®¾hop_length=320
            let feat = Array2::<f32>::zeros((t, feature_dim));

            // æå–å‚è€ƒéŸ³é¢‘çš„melé¢‘è°±å›¾ï¼ˆç®€åŒ–å¤„ç†ï¼‰
            let ref_segment_length = 16000 * 6; // 6ç§’å‚è€ƒéŸ³é¢‘
            let _ref_wav = if wav.len() >= ref_segment_length {
                wav.slice(ndarray::s![..ref_segment_length]).to_owned()
            } else {
                // é‡å¤éŸ³é¢‘åˆ°è¶³å¤Ÿé•¿åº¦
                let repeat_times = ref_segment_length / wav.len() + 1;
                let mut repeated = Vec::with_capacity(wav.len() * repeat_times);
                for _ in 0..repeat_times {
                    repeated.extend(wav.iter());
                }
                Array1::from(repeated)
                    .slice(ndarray::s![..ref_segment_length])
                    .to_owned()
            };

            let ref_mel = Array2::<f32>::zeros((128, 301)); // ç®€åŒ–çš„melé¢‘è°±å›¾

            // å‡†å¤‡ONNXè¾“å…¥
            let ref_mel_input = ref_mel.insert_axis(ndarray::Axis(0));
            let feat_input = feat.insert_axis(ndarray::Axis(0));

            let ref_mel_dyn = ref_mel_input.into_dyn();
            let feat_dyn = feat_input.into_dyn();

            let ref_mel_shape: Vec<i64> = ref_mel_dyn.shape().iter().map(|&d| d as i64).collect();
            let ref_mel_vec: Vec<f32> = ref_mel_dyn.into_raw_vec();
            let ref_mel_tensor = Value::from_array((ref_mel_shape, ref_mel_vec))?;

            let feat_shape: Vec<i64> = feat_dyn.shape().iter().map(|&d| d as i64).collect();
            let feat_vec: Vec<f32> = feat_dyn.into_raw_vec();
            let feat_tensor = Value::from_array((feat_shape, feat_vec))?;

            // è¿è¡ŒONNXæ¨ç†
            let outputs = session_guard.session_mut().run(ort::inputs![
                "ref_wav_mel" => SessionInputValue::from(ref_mel_tensor),
                "feat" => SessionInputValue::from(feat_tensor)
            ])?;

            let (_s_sem, semantic_tokens_slice) = outputs[0].try_extract_tensor::<i64>()?;
            let (_s_glb, global_tokens_slice) = outputs[1].try_extract_tensor::<i64>()?;

            let semantic_tokens: Vec<i32> =
                semantic_tokens_slice.iter().map(|&x| x as i32).collect();
            let global_tokens: Vec<i32> = global_tokens_slice.iter().map(|&x| x as i32).collect();

            Ok((global_tokens, semantic_tokens))
        })
        .await??;

        Ok(result)
    }

    /// è§£ç éŸ³é¢‘
    async fn decode_audio(
        &self,
        global_tokens: &[i32],
        semantic_tokens: &[i32],
    ) -> Result<Vec<f32>> {
        let onnx_manager = get_global_onnx_manager()?;

        // è·å–BiCodec Detokenizeä¼šè¯
        let detokenize_session = onnx_manager.acquire_bicodec_detokenize_session().await?;

        // æ‰§è¡Œè§£ç 
        let audio = self
            .detokenize_audio_with_session(global_tokens, semantic_tokens, detokenize_session)
            .await?;

        Ok(audio)
    }

    /// ä½¿ç”¨ONNXä¼šè¯è¿›è¡ŒéŸ³é¢‘è§£ç 
    async fn detokenize_audio_with_session(
        &self,
        global_tokens: &[i32],
        semantic_tokens: &[i32],
        mut session_guard: crate::onnx_session_pool::SessionGuard,
    ) -> Result<Vec<f32>> {
        let global_tokens = global_tokens.to_vec();
        let semantic_tokens = semantic_tokens.to_vec();

        let result = tokio::task::spawn_blocking(move || -> Result<Vec<f32>> {
            // è½¬æ¢tokensä¸ºi64
            let global_i64: Vec<i64> = global_tokens.iter().map(|&v| v as i64).collect();
            let semantic_i64: Vec<i64> = semantic_tokens.iter().map(|&v| v as i64).collect();

            // æŒ‰ç…§BiCodecæ¨¡å‹çš„è¾“å…¥æ ¼å¼å‡†å¤‡æ•°æ®
            // global_tokens: (1, 1, Lg)
            let global_tokens_array = Array3::from_shape_vec((1, 1, global_i64.len()), global_i64)?;
            // semantic_tokens: (1, Ls)
            let semantic_tokens_array =
                Array2::from_shape_vec((1, semantic_i64.len()), semantic_i64)?;

            // è½¬æ¢ä¸ºåŠ¨æ€æ•°ç»„
            let global_dyn = global_tokens_array.into_dyn();
            let semantic_dyn = semantic_tokens_array.into_dyn();

            let global_shape: Vec<i64> = global_dyn.shape().iter().map(|&d| d as i64).collect();
            let global_vec: Vec<i64> = global_dyn.into_raw_vec();
            let global_tensor = Value::from_array((global_shape, global_vec))?;

            let semantic_shape: Vec<i64> = semantic_dyn.shape().iter().map(|&d| d as i64).collect();
            let semantic_vec: Vec<i64> = semantic_dyn.into_raw_vec();
            let semantic_tensor = Value::from_array((semantic_shape, semantic_vec))?;

            // è¿è¡ŒONNXæ¨ç†
            let outputs = session_guard.session_mut().run(ort::inputs![
                "semantic_tokens" => SessionInputValue::from(semantic_tensor),
                "global_tokens" => SessionInputValue::from(global_tensor)
            ])?;

            let (_shape, audio_slice) = outputs[0].try_extract_tensor::<f32>()?;
            let audio_vec: Vec<f32> = audio_slice.to_vec();

            Ok(audio_vec)
        })
        .await??;

        Ok(result)
    }

    /// ç”Ÿæˆè¯­éŸ³ï¼ˆä½¿ç”¨æ‰¹å¤„ç†è°ƒåº¦å™¨ï¼‰
    pub async fn generate_speech(&self, args: &LightweightTtsPipelineArgs) -> Result<Vec<f32>> {
        let total_start = std::time::Instant::now();

        println!("ğŸš€ å¼€å§‹è½»é‡çº§TTSç”Ÿæˆæµç¨‹");
        println!("  æ–‡æœ¬: {}", args.text);
        println!("  Zero-shotæ¨¡å¼: {}", args.zero_shot);

        // 1. å¤„ç†æ–‡æœ¬
        let text_start = std::time::Instant::now();
        let processed_text = self.process_text(&args.text);
        let text_time = text_start.elapsed();
        println!(
            "  â±ï¸  æ–‡æœ¬å¤„ç†è€—æ—¶: {:.2}ms",
            text_time.as_secs_f64() * 1000.0
        );

        // 2. å¤„ç†å±æ€§tokensæˆ–å‚è€ƒéŸ³é¢‘
        let ref_start = std::time::Instant::now();
        let (property_tokens, ref_global_tokens, ref_semantic_tokens) = if args.zero_shot {
            let (global, semantic) = self.process_reference_audio(&args.ref_audio_path).await?;
            (vec![], Some(global), Some(semantic))
        } else {
            let tokens = self.generate_property_tokens(args);
            (tokens, None, None)
        };
        let ref_time = ref_start.elapsed();
        if args.zero_shot {
            println!(
                "  â±ï¸  å‚è€ƒéŸ³é¢‘å¤„ç†è€—æ—¶: {:.2}ms",
                ref_time.as_secs_f64() * 1000.0
            );
        } else {
            println!(
                "  â±ï¸  å±æ€§tokensç”Ÿæˆè€—æ—¶: {:.2}ms",
                ref_time.as_secs_f64() * 1000.0
            );
        }

        // 3. åˆ›å»ºé‡‡æ ·å‚æ•°
        let sampler_args = SamplerArgs {
            temperature: args.temperature,
            top_p: args.top_p,
            top_k: args.top_k,
            max_tokens: args.max_tokens,
            seed: args.seed,
        };

        // 4. åˆ›å»ºæ‰¹å¤„ç†è¯·æ±‚
        let request = TtsBatchRequest {
            text: processed_text,
            property_tokens,
            ref_global_tokens,
            ref_semantic_tokens,
            args: sampler_args,
        };

        // 5. æäº¤åˆ°åŠ¨æ€æ‰¹å¤„ç†ç®¡ç†å™¨å¹¶ç­‰å¾…RWKVæ¨ç†
        let inference_start = std::time::Instant::now();
        let manager = get_global_dynamic_batch_manager()?;
        let (global_tokens, semantic_tokens) = manager
            .generate_tts(
                request.text,
                request.property_tokens,
                request.ref_global_tokens,
                request.ref_semantic_tokens,
                request.args,
            )
            .await?;
        let inference_time = inference_start.elapsed();
        println!(
            "  â±ï¸  RWKVæ¨¡å‹æ¨ç†è€—æ—¶: {:.2}ms",
            inference_time.as_secs_f64() * 1000.0
        );

        println!(
            "  ç”Ÿæˆglobal tokens: {} ä¸ª, semantic tokens: {} ä¸ª",
            global_tokens.len(),
            semantic_tokens.len()
        );

        // 6. è§£ç éŸ³é¢‘
        if global_tokens.is_empty() && semantic_tokens.is_empty() {
            println!("  æœªç”Ÿæˆä»»ä½•TTS tokensï¼Œè¿”å›é™éŸ³å ä½");
            return Ok(vec![0.0; 16000]);
        }

        let decode_start = std::time::Instant::now();
        let audio = self.decode_audio(&global_tokens, &semantic_tokens).await?;
        let decode_time = decode_start.elapsed();
        println!(
            "  â±ï¸  éŸ³é¢‘è§£ç è€—æ—¶: {:.2}ms",
            decode_time.as_secs_f64() * 1000.0
        );

        let total_time = total_start.elapsed();
        let audio_duration = audio.len() as f64 / 16000.0; // å‡è®¾16kHzé‡‡æ ·ç‡
        let rtf = total_time.as_secs_f64() / audio_duration;

        println!(
            "  â±ï¸  æ€»è€—æ—¶: {:.2}ms, éŸ³é¢‘æ—¶é•¿: {:.2}s, RTF: {:.3}",
            total_time.as_secs_f64() * 1000.0,
            audio_duration,
            rtf
        );

        // æ€§èƒ½ä¼˜åŒ–å»ºè®®
        if rtf > 0.3 {
            println!("  âš ï¸  æ€§èƒ½æç¤º: RTF > 0.3ï¼Œå»ºè®®ä¼˜åŒ–:");
            if inference_time.as_secs_f64() > total_time.as_secs_f64() * 0.6 {
                println!(
                    "     - RWKVæ¨ç†å ç”¨{:.1}%æ—¶é—´ï¼Œè€ƒè™‘ä½¿ç”¨æ›´æ¿€è¿›çš„é‡åŒ–æˆ–æ›´å°çš„æ¨¡å‹",
                    inference_time.as_secs_f64() / total_time.as_secs_f64() * 100.0
                );
            }
            if decode_time.as_secs_f64() > total_time.as_secs_f64() * 0.3 {
                println!(
                    "     - éŸ³é¢‘è§£ç å ç”¨{:.1}%æ—¶é—´ï¼Œè€ƒè™‘ä¼˜åŒ–BiCodecæ¨¡å‹æˆ–ä½¿ç”¨GPUåŠ é€Ÿ",
                    decode_time.as_secs_f64() / total_time.as_secs_f64() * 100.0
                );
            }
            if args.zero_shot && ref_time.as_secs_f64() > total_time.as_secs_f64() * 0.2 {
                println!(
                    "     - å‚è€ƒéŸ³é¢‘å¤„ç†å ç”¨{:.1}%æ—¶é—´ï¼Œè€ƒè™‘ç¼“å­˜æˆ–é¢„å¤„ç†å‚è€ƒéŸ³é¢‘",
                    ref_time.as_secs_f64() / total_time.as_secs_f64() * 100.0
                );
            }
        }

        println!("  è½»é‡çº§TTSç”Ÿæˆå®Œæˆï¼ŒéŸ³é¢‘é•¿åº¦: {} æ ·æœ¬", audio.len());
        Ok(audio)
    }

    /// ä¿å­˜éŸ³é¢‘åˆ°WAVæ–‡ä»¶
    pub fn save_audio(
        &self,
        audio_samples: &[f32],
        output_path: &str,
        sample_rate: u32,
    ) -> Result<()> {
        println!("  ä¿å­˜éŸ³é¢‘åˆ°: {}", output_path);

        let spec = hound::WavSpec {
            channels: 1,
            sample_rate,
            bits_per_sample: 32,
            sample_format: hound::SampleFormat::Float,
        };

        let mut writer = hound::WavWriter::create(output_path, spec)?;
        for &sample in audio_samples {
            writer.write_sample(sample)?;
        }
        writer.finalize()?;

        println!("  éŸ³é¢‘ä¿å­˜å®Œæˆ");
        Ok(())
    }
}

impl Default for LightweightTtsPipeline {
    fn default() -> Self {
        Self::new()
    }
}
